{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "099f0b78",
   "metadata": {},
   "source": [
    "# 使用 4o-mini 模拟 OpenAI One 的推理过程\n",
    "\n",
    "\n",
    "我们的目标是创建一个 AI 助手，能够像 OpenAI One 一样，**逐步展示推理过程**，最终给出答案。**4o-mini** 是一个轻量级的大型语言模型。虽然它的性能不及 OpenAI One，但通过巧妙的提示设计和代码实现，我们可以让它模拟类似的推理过程。\n",
    "\n",
    "### COT设计思路\n",
    "\n",
    "- **逐步推理**：助手将问题分解为多个步骤，每个步骤都有标题和详细内容。\n",
    "- **动态决策**：在每一步，助手决定是继续推理还是给出最终答案。\n",
    "- **JSON 格式**：为了方便解析和展示，助手的每个响应都采用 JSON 格式。\n",
    "\n",
    "---\n",
    "\n",
    "### 局限性\n",
    "\n",
    "1、o1并不是简单通过提示工程就升级出来的，而是加入了后训练推理阶段：\n",
    "\n",
    "- 例如MCTS等算法被用作一个工具来构建细粒度的奖励信号\n",
    "- 这些奖励信号可以指导模型的后训练训练推理过程\n",
    "\n",
    "![image](https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/LingYi/28777116_249bd793-3578-4a05-874a-bf391f1b3abd.png)\n",
    "\n",
    "MCTS(Monte Carlo Tree Search, 蒙特卡洛树搜索)，扩展之前的算法不只是传统意义上的不是传统的决策树搜索工具，而是用来引导和生成合理的推理过程树搜索的层次结构被用来模拟推理的层次结构，从而帮助模型学习如何进行更有条理的思考。这些推理过程可以被转化为token序列，进而产生细粒度（token级，句子级）的奖励信号。\n",
    "\n",
    "\n",
    "\n",
    "2、除此之外，CoT 虽然也能生成中间推理步骤，但没有教会模型\"如何从内部深入思考问题的关联\"\n",
    "\n",
    "STAR (STaR) 是一个利用语言模型进行推理的框架，通过 Bootstrap 方式生成推理过程(Rationales)，将推理过程融入到训练过程中，让模型学会进行推理\n",
    "\n",
    "1. 核心思路：\n",
    "- 利用大语言模型(LLM)已有的推理能力\n",
    "- 通过 Bootstrap 方式生成推理过程(Rationales)\n",
    "- 将推理过程融入到训练过程中，让模型学会进行推理\n",
    "\n",
    "2. 工作流程：\n",
    "- 输入问题(Question)\n",
    "- 语言模型生成推理过程(Rationale)和答案(Answer)\n",
    "- 系统会验证答案的正确性\n",
    "- 如果答案错误，会提供提示(Hint)进行修正\n",
    "\n",
    "这个框架的名称来源于论文 \"STaR: Bootstrapping Reasoning With Reasoning\"，主要创新点在于通过自举(Bootstrapping)方式来增强模型的推理能力。\n",
    "\n",
    "当然，以上都是猜测，o1并没有官方解释说明\n",
    "### 环境准备\n",
    "\n",
    "首先，确保安装了必要的库和模型。\n",
    "- 知识准备 希望大家先完成4o的OPENAI API基本调用的学习，因为这是个小实战项目"
   ]
  },
  {
   "cell_type": "code",
   "id": "122fd661",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T07:26:30.748818Z",
     "start_time": "2024-10-25T07:26:28.131913Z"
    }
   },
   "source": [
    "!pip install openai pydantic"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in d:\\pycharmproject\\openai_series\\.venv\\lib\\site-packages (1.51.2)\n",
      "Requirement already satisfied: pydantic in d:\\pycharmproject\\openai_series\\.venv\\lib\\site-packages (2.9.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\pycharmproject\\openai_series\\.venv\\lib\\site-packages (from openai) (4.6.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\pycharmproject\\openai_series\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\pycharmproject\\openai_series\\.venv\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\pycharmproject\\openai_series\\.venv\\lib\\site-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: sniffio in d:\\pycharmproject\\openai_series\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\pycharmproject\\openai_series\\.venv\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in d:\\pycharmproject\\openai_series\\.venv\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\pycharmproject\\openai_series\\.venv\\lib\\site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in d:\\pycharmproject\\openai_series\\.venv\\lib\\site-packages (from pydantic) (2.23.4)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\pycharmproject\\openai_series\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\pycharmproject\\openai_series\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in d:\\pycharmproject\\openai_series\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\pycharmproject\\openai_series\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\pycharmproject\\openai_series\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: colorama in d:\\pycharmproject\\openai_series\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "1a614acd",
   "metadata": {},
   "source": [
    "### 导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "id": "8ad8ae4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T07:26:38.455110Z",
     "start_time": "2024-10-25T07:26:38.001464Z"
    }
   },
   "source": [
    "from enum import Enum\n",
    "import openai\n",
    "import json\n",
    "import time\n",
    "from pydantic import BaseModel"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "55ace345",
   "metadata": {},
   "source": [
    "### 设置 OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "id": "020d9e26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T07:27:36.483772Z",
     "start_time": "2024-10-25T07:27:36.439772Z"
    }
   },
   "source": [
    "# 设置 OpenAI API 密钥（请替换为您的实际密钥）\n",
    "# client = openai.OpenAI(api_key=\"YOUR_API_KEY\")\n",
    "client = openai.OpenAI()"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 定义JSON格式及大模型的行为\n",
    "\n",
    "我们需要定义助手的行动类型和响应为JSON格式从而方便在上下游传输数据流。使用4o大模型的定义结构的response_format参数。\n",
    "\n",
    "`response_format` 告诉 OpenAI 模型以特定的结构输出它的回复，就像填写一个表格一样。它避免了模型随意发挥，确保你得到的数据格式正确，可以直接使用，即我们常说的Json结构。\n",
    "\n",
    "**简单来说，`response_format`  就像一个模具，让模型的回复符合你的要求。**\n",
    "\n",
    "**`response_format` 怎么用？**\n",
    "\n",
    "1. **定义结构：** 你需要先定义你想要的输出结构，就像设计一个表格，包括字段名称和数据类型（例如：姓名-字符串，年龄-数字，日期-日期）。 你可以用 JSON Schema，或者 Python 的 Pydantic 和 JavaScript 的 Zod 库来定义。\n",
    "\n",
    "2. **API 调用：**  在调用 OpenAI API 时，把定义好的结构通过 `response_format` 参数传递给模型。\n",
    "\n",
    "3. **使用数据：** 因为模型的回复已经符合你定义的结构，你可以直接在程序中安全地使用这些数据。\n",
    "\n",
    "具体在 https://platform.openai.com/docs/guides/structured-outputs/supported-schemas\n"
   ],
   "id": "de58eea5e00d93f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T07:27:38.648576Z",
     "start_time": "2024-10-25T07:27:38.624563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义助手的行动类型\n",
    "class ActionType(str, Enum):\n",
    "    CONTINUE = 'continue'\n",
    "    FINAL_ANSWER = 'final_answer'\n",
    "\n",
    "# 定义助手的响应格式\n",
    "class Answer(BaseModel):\n",
    "    title: str\n",
    "    next_action: ActionType\n",
    "    content: str"
   ],
   "id": "fe684f8a72b60bb6",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "62255eea",
   "metadata": {},
   "source": [
    "### 定义与模型交互的函数\n",
    "\n",
    "这个函数用于与 4o-mini 模型进行交互，发送请求并处理响应。"
   ]
  },
  {
   "cell_type": "code",
   "id": "3a71f17f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T07:43:25.551035Z",
     "start_time": "2024-10-25T07:43:25.539037Z"
    }
   },
   "source": [
    "def make_api_call(messages, max_tokens, is_final_answer=False):\n",
    "    \"\"\"\n",
    "    发送请求到 4o-mini 模型，并处理可能的异常。\n",
    "    \"\"\"\n",
    "    for attempt in range(3):\n",
    "        try:\n",
    "            response = client.beta.chat.completions.parse(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=messages,\n",
    "                max_tokens=max_tokens,\n",
    "                response_format=Answer\n",
    "            )\n",
    "            return json.loads(response.choices[0].message.content)\n",
    "        except Exception as e:\n",
    "            if attempt == 2:\n",
    "                if is_final_answer:\n",
    "                    return {\n",
    "                        \"title\": \"错误\",\n",
    "                        \"content\": f\"尝试3次后无法生成最终答案。错误信息: {str(e)}\"\n",
    "                    }\n",
    "                else:\n",
    "                    return {\n",
    "                        \"title\": \"错误\",\n",
    "                        \"content\": f\"尝试3次后无法生成步骤。错误信息: {str(e)}\",\n",
    "                        \"next_action\": \"final_answer\"\n",
    "                    }\n",
    "            time.sleep(1)  # 等待 1 秒后重试"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "f45ea87a",
   "metadata": {},
   "source": [
    "### 构建逐步生成推理步骤的函数\n",
    "\n",
    "这个函数是核心，根据用户提供的 prompt，通过迭代调用API，逐步推理并最终生成答案。它最多进行五个推理步骤，每个步骤都会生成一个包含标题、内容和下一步操作（继续或最终答案）的JSON格式数据。\n",
    "\n",
    "* **逐步推理:**  函数的核心是逐步推理，每个步骤都建立在前一步的基础上。\n",
    "* **JSON格式:**  API调用返回的数据和助手回复都是JSON格式，包含 `title`、`content` 和 `next_action`。\n",
    "* **最多五步:**  推理步骤最多进行五次。\n",
    "* **最终答案请求:**  在推理步骤完成后，显式请求助手给出最终答案。\n",
    "* **时间记录:**  记录每个步骤和最终答案的耗时。"
   ]
  },
  {
   "cell_type": "code",
   "id": "1ea0eee5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T07:43:26.359148Z",
     "start_time": "2024-10-25T07:43:26.344150Z"
    }
   },
   "source": [
    "def generate_response(prompt):\n",
    "    \"\"\"\n",
    "    根据用户提示，逐步生成推理步骤并最终给出答案。\n",
    "    \"\"\"\n",
    "    # 初始化消息列表\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"你是一个专家级的AI助手，能够逐步解释你的推理过程。\"\n",
    "                \"对于每一步，提供一个描述该步骤的标题和详细内容。\"\n",
    "                \"决定是否需要继续下一步，或是准备给出最终答案。\"\n",
    "                \"请以JSON格式响应，包含 'title'、'content' 和 'next_action'（'continue' 或 'final_answer'）。\"\n",
    "                \"请使用至少3个推理步骤。\"\n",
    "            )\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": \"好的，我将逐步分析并回答您的问题。\"}\n",
    "    ]\n",
    "\n",
    "    steps = []\n",
    "    step_count = 1\n",
    "    total_thinking_time = 0\n",
    "\n",
    "    while step_count <= 5:\n",
    "        start_time = time.time()\n",
    "        # 调用API获取当前步骤的数据\n",
    "        step_data = make_api_call(messages, max_tokens=500)\n",
    "        end_time = time.time()\n",
    "        thinking_time = end_time - start_time\n",
    "        total_thinking_time += thinking_time\n",
    "\n",
    "        # 添加当前步骤的信息\n",
    "        steps.append(\n",
    "            {\n",
    "                \"步骤\": step_count,\n",
    "                \"标题\": step_data.get('title', '无标题'),\n",
    "                \"内容\": step_data.get('content', ''),\n",
    "                \"耗时\": f\"{thinking_time:.2f} 秒\"\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # 更新消息列表，供下一次迭代使用\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": json.dumps(step_data, ensure_ascii=False)\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # 实时显示当前步骤\n",
    "        print(f\"\\n{'=' * 40}\\n步骤 {step_count}: {step_data.get('title', '无标题')}\\n{'-' * 40}\")\n",
    "        print(step_data.get('content', ''))\n",
    "        print(f\"此步骤耗时: {thinking_time:.2f} 秒\")\n",
    "\n",
    "        # 判断是否需要继续或结束\n",
    "        if step_data.get('next_action') == 'final_answer':\n",
    "            break\n",
    "\n",
    "        step_count += 1\n",
    "\n",
    "    # 请求生成最终答案\n",
    "    messages.append({\"role\": \"user\", \"content\": \"请根据以上推理给出最终答案。\"})\n",
    "\n",
    "    start_time = time.time()\n",
    "    final_data = make_api_call(messages, max_tokens=200, is_final_answer=True)\n",
    "    end_time = time.time()\n",
    "    thinking_time = end_time - start_time\n",
    "    total_thinking_time += thinking_time\n",
    "\n",
    "    # 添加最终答案的信息\n",
    "    steps.append(\n",
    "        {\n",
    "            \"步骤\": \"最终答案\",\n",
    "            \"内容\": final_data.get('content', ''),\n",
    "            \"耗时\": f\"{thinking_time:.2f} 秒\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # 显示最终答案\n",
    "    print(f\"\\n{'=' * 40}\\n最终答案\\n{'-' * 40}\")\n",
    "    print(final_data.get('content', ''))\n",
    "    print(f\"最终答案耗时: {thinking_time:.2f} 秒\")\n",
    "\n",
    "    # 返回所有步骤和总思考时间\n",
    "    return steps, total_thinking_time\n"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "9ee3f392",
   "metadata": {},
   "source": [
    "\n",
    "定义一个主函数来组织逻辑，运行整个程序。"
   ]
  },
  {
   "cell_type": "code",
   "id": "b70d13c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T07:43:27.470807Z",
     "start_time": "2024-10-25T07:43:27.452810Z"
    }
   },
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    主函数，负责获取用户输入并生成响应。\n",
    "    \"\"\"\n",
    "    print(\"==========================================\")\n",
    "    print(\" 使用 4o-mini 模拟 OpenAI One 的推理过程\")\n",
    "    print(\"==========================================\\n\")\n",
    "\n",
    "    print(\"这是一个使用 4o-mini 创建类似 OpenAI One 推理链的原型。\\n\")\n",
    "\n",
    "    # 获取用户查询\n",
    "    user_query = input(\"请输入您的查询（例如：单词 'strawberry' 中有多少个 'R'？）:\\n> \").strip()\n",
    "\n",
    "    if user_query:\n",
    "        print(\"\\n正在生成响应...\\n\")\n",
    "\n",
    "        # 生成并显示响应\n",
    "        steps, total_thinking_time = generate_response(user_query)\n"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "dadf5e1f",
   "metadata": {},
   "source": [
    "### 运行程序"
   ]
  },
  {
   "cell_type": "code",
   "id": "6d02eac6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T07:43:38.896294Z",
     "start_time": "2024-10-25T07:43:28.697111Z"
    }
   },
   "source": [
    "main()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================\n",
      " 使用 4o-mini 模拟 OpenAI One 的推理过程\n",
      "==========================================\n",
      "\n",
      "这是一个使用 4o-mini 创建类似 OpenAI One 推理链的原型。\n",
      "\n",
      "\n",
      "正在生成响应...\n",
      "\n",
      "\n",
      "========================================\n",
      "步骤 1: 步骤 1: 理解二极管发光的原理\n",
      "----------------------------------------\n",
      "二极管是一种电子元件，特别是LED（二极管发光二极管），其工作原理是当电流通过时会发光。需要确保二极管的极性连接正确，即阳极接正极，阴极接负极。\n",
      "此步骤耗时: 1.71 秒\n",
      "\n",
      "========================================\n",
      "步骤 2: 步骤 2: 找到合适的电源\n",
      "----------------------------------------\n",
      "为了让二极管发亮，我们需要一个可提供电流的简单电源。常见的选择包括：电池（如AA电池）、USB接口、电源适配器等。确保电源的电压与二极管的额定前向电压匹配。对于LED，通常在2V到3V之间。\n",
      "此步骤耗时: 1.24 秒\n",
      "\n",
      "========================================\n",
      "步骤 3: 步骤 3: 连接二极管与电源\n",
      "----------------------------------------\n",
      "将二极管的阳极（长脚）连接到电源的正极，阴极（短脚）连接到电源的负极。如果使用电池，直接将二极管与电池连接即可。确保电流流动方向正确，这样二极管就会发光。\n",
      "此步骤耗时: 1.23 秒\n",
      "\n",
      "========================================\n",
      "最终答案\n",
      "----------------------------------------\n",
      "你可以将二极管（如LED）连接到电池的正极和负极之间来让它发光。具体步骤是：1) 确保二极管的阳极（长脚）连接到电池的正极，阴极（短脚）连接到负极。2) 选择合适的电源（比如AA电池），确保电源电压与二极管工作电压相匹配。这样连接后，二极管应该会发光。\n",
      "最终答案耗时: 1.45 秒\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-25T07:45:19.531509Z",
     "start_time": "2024-10-25T07:45:14.281782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = client.beta.chat.completions.parse(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[{\"role\": \"user\", \"content\": \"可以把二极管插在什么地方能让他发亮，不要专业的设备，比如苹果？\"}],\n",
    "            )\n",
    "print(response.choices[0].message.content)"
   ],
   "id": "3990741b412adf10",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "要让二极管发亮，只需要供给它适当的电压和电流。你可以尝试以下几种简单的方法，而不需要专业的设备：\n",
      "\n",
      "1. **电池**：使用一个干电池（如AA或9V电池）和适当的电阻器，可以将二极管连接到电池的正负极。确保电路中有合适的电阻，以防止二极管过流烧毁。\n",
      "\n",
      "2. **LED手电筒**：许多LED手电筒中的电路可以直接连接LED二极管，如果能拆解手电筒并接入二极管，可能可以使二极管发亮。\n",
      "\n",
      "3. **电源适配器**：一些小型的电源适配器可以用来为二极管供电。确保电压符合二极管的额定值。\n",
      "\n",
      "4. **USB接口**：如果你有USB接口的供电设备（例如手机充电器），可以借助USB转接线，将二极管通过电阻与USB接口连接，利用5V电源使二极管发亮。\n",
      "\n",
      "5. **旧电子设备**：可以尝试从一些旧的电子设备（如玩具、旧手机等）中取出供电源，连接到二极管。\n",
      "\n",
      "确保在操作过程中遵循安全指引，避免短路和过热。\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "36fbd8ae",
   "metadata": {},
   "source": [
    "--- ++\n",
    "\n",
    "通过以上步骤，我们成功地使用 **4o-mini** 模型模拟了 **OpenAI One** 的逐步推理过程。尽管模型性能有所差距，但通过巧妙的提示设计和代码实现，我们能够让模型展示出类似的推理能力。"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
