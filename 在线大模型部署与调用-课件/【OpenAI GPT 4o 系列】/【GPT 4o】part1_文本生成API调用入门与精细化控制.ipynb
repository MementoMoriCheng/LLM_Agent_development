{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f09103bb-61d3-4349-aec9-1135bcfd3a79",
   "metadata": {},
   "source": [
    "# <center>在线大模型本地调用方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a51db5-c571-4f12-b198-1ce134c4342e",
   "metadata": {},
   "source": [
    "## <center> Chat API 文本对话指南"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856fa4b6-7cf5-497b-a05c-ca8b1a6c1fd8",
   "metadata": {},
   "source": [
    "欢迎各位小伙伴们，我们接下来会进入模型API调用的学习了。因为OPENAI处于行业标杆的位置，有关于OPENAI的API调用等知识体系完全可以迁移到其他模型上面，有些类似于python，C，java之间的编程语言的的迁移，且改动幅度更小。\n",
    "\n",
    "我们以OPENAI的旗舰模型GPT-4o为例，GPT-4o  （“o”代表“全能”）和 GPT-4o mini 是原生多模态模型，旨在处理多模态输入的组合。GPT-4o mini 是 GPT-4o 的轻量级版本。\n",
    "\n",
    "在 GPT-4o 之前，用户可以通过语音模式与 ChatGPT 互动，该模式使用三个独立的模型。GPT-4o 将这些功能整合到一个单一模型中，该模型在文本、视觉和音频上进行了训练。这种统一的方法确保所有输入——无论是文本、视觉还是听觉——都由同一个神经网络进行一致处理。\n",
    "\n",
    "除此之外，还有GPT最新开放出来的API，GPT 4o还可以对自己进行文本及图片的微调，原生语音到语音的realtime实时API，通过模型蒸馏让大模型教小模型的功能，以及低价的批处理API调用等等。\n",
    "\n",
    "这些功能GPT 4o都可以实现！\n",
    "\n",
    "现在，我们将会从Chat对话类型的API入手，并往下探索大模型世界！\n",
    "\n",
    "首先，我们可以看到Chat对话类型的API都是通过chat completions API端口来完成的。\n",
    "\n",
    "chatAPI提供文本和图片类型的输入，大模型进行推理并返回文本的格式。其视频输入和音频输入并不在chat API的端口里，但这里是基础中基础，坚石中的坚石，是攻克大模型应用开发的必经之路。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c319add8-f6c2-481d-9078-7b3dfb36186f",
   "metadata": {},
   "source": [
    "![](https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/LingYi/20241015104845.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cf971f-4fc5-4aff-8104-00af96c5b1a4",
   "metadata": {},
   "source": [
    "> 端口路径：https://api.openai.com/v1/chat/completions<br>\n",
    "\n",
    "\n",
    "\n",
    "> 这个路径作为API的一个端点，是连接用户（或者用户的应用程序）和OpenAI服务之间的桥梁；<br>\n",
    "> 通过这个网址，开发者可以远程调用OpenAI的服务器上运行的模型。这意味着开发者无需在本地运行大型机器学习模型，而是通过网络向OpenAI的服务器发送请求，由服务器处理并返回结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413e9297-5daa-493c-b4cc-dd9b5d5f6be4",
   "metadata": {},
   "source": [
    "________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c880db2-6fa7-4b88-9852-e13e760327ff",
   "metadata": {},
   "source": [
    "## 1. Chat Completions API调用方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13050630-1cf5-46fb-b039-247f005de54b",
   "metadata": {},
   "source": [
    "一个函数——`chat.completions.create`函数速通文本对话。"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "安装openai的库（工具包）"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf3334da0f8ed106"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/threecatsago/anaconda3/lib/python3.11/site-packages (1.37.0)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/threecatsago/anaconda3/lib/python3.11/site-packages (from openai) (3.5.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/threecatsago/anaconda3/lib/python3.11/site-packages (from openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/threecatsago/anaconda3/lib/python3.11/site-packages (from openai) (0.27.0)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/threecatsago/anaconda3/lib/python3.11/site-packages (from openai) (1.10.12)\r\n",
      "Requirement already satisfied: sniffio in /Users/threecatsago/anaconda3/lib/python3.11/site-packages (from openai) (1.2.0)\r\n",
      "Requirement already satisfied: tqdm>4 in /Users/threecatsago/anaconda3/lib/python3.11/site-packages (from openai) (4.65.0)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/threecatsago/anaconda3/lib/python3.11/site-packages (from openai) (4.7.1)\r\n",
      "Requirement already satisfied: idna>=2.8 in /Users/threecatsago/anaconda3/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\r\n",
      "Requirement already satisfied: certifi in /Users/threecatsago/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/threecatsago/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/threecatsago/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.0\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-17T04:52:08.483763Z",
     "start_time": "2024-10-17T04:51:58.190275Z"
    }
   },
   "id": "5bfe692222265f3a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- **chat.completions.create函数使用示例与response回应解析**\n",
    "\n",
    "接下来，我们尝试调用Chat Completions API。通过一个极简示例来了解Chat Completions API调用方式、参数设置、响应内容。\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "300ef515fb32a6a4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "想要调用它，我们需要有API Key，通过API Key认证的client就和我们的账户挂钩了，同时也建立了调用OpenAI的桥梁，OpenAI实例client就能关联到我们的账户，比如我们的文件，微调的模型等。在这里我们，可以理解它为和我们自己滴血结成契约的独有小精灵."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91c0fb518f4f94fc"
  },
  {
   "cell_type": "code",
   "id": "b52f56c8-49b9-4553-943e-76fbad3d044f",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-16T15:39:02.370667Z",
     "start_time": "2024-10-16T15:39:01.503117Z"
    }
   },
   "source": [
    "from openai import OpenAI\n",
    "# 如果成功配置了环境变量的在OPENAI提供的工具包中会自动找到我们的秘钥\n",
    "client = OpenAI()\n",
    "# 如果没有配置环境变量也可以用变量显式传入 但注意保护好api key不被别人看见\n",
    "# client = OpenAI(api_key=\"bjhgsdjhfkad_your_api_key_here\") "
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/LingYi/20241015174953.png)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "703d3e47df4be107"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "有了独特的的契约助手（由我们API KEY认证的）后，如果我们想要向大模型发起问话，需要什么必须的信息告诉助手呢？\n",
    "\n",
    "1、 使用哪个模型  2、我们的问题是什么\n",
    "\n",
    "即这个函数中有两个必须参数：model和messages。\n",
    "\n",
    "其中model表示调用的模型（这里调用的是`gpt-4o`模型），messages参数则是一个由字典构成的列表，其中每个字典（每条消息）内有两个键：\n",
    ">- \"**role**\"：这个键的值表示消息的发送者。在上述代码中`\"role\": \"user\"`这个键值对就表明这条消息是由用户发送的。role可以有不同的值，包括user、system、assistant、tool。<br><br>\n",
    ">- \"**content**\"：这个键的值表示实际的消息内容。在上述代码中，\"content\": \"请举几个罗马帝国的趣事\" 是用户希望得到回答的问题。这个内容是大模型生成对话的输入部分。"
   ],
   "id": "ee2acf5e4200a4f4"
  },
  {
   "cell_type": "code",
   "id": "bd0316c9-30c0-4999-ab32-bceb0b805e83",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-17T10:16:13.232312Z",
     "start_time": "2024-10-17T10:16:08.320626Z"
    }
   },
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "      {\"role\": \"user\", \"content\": \"请举几个罗马帝国的趣事\"}\n",
    "  ]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "大模型推理生成的结果直接由create函数返回了，被我们存进了response中"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8670217f22139415"
  },
  {
   "cell_type": "code",
   "id": "12e18257-b7ff-446e-a4f1-f6cc12c8fb69",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-17T10:23:07.302234Z",
     "start_time": "2024-10-17T10:22:28.851876Z"
    }
   },
   "source": [
    "response"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mresponse\u001B[49m\n",
      "Cell \u001B[1;32mIn[16], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mresponse\u001B[49m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:1187\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:627\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:937\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:928\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_310_64.pyx:585\u001B[0m, in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_310_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mD:\\PyCharm 2024.1.4\\plugins\\python\\helpers\\pydev\\pydevd.py:1201\u001B[0m, in \u001B[0;36mPyDB.do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1198\u001B[0m         from_this_thread\u001B[38;5;241m.\u001B[39mappend(frame_id)\n\u001B[0;32m   1200\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_threads_suspended_single_notification\u001B[38;5;241m.\u001B[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001B[1;32m-> 1201\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_wait_suspend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mthread\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mframe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mevent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msuspend_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrom_this_thread\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\PyCharm 2024.1.4\\plugins\\python\\helpers\\pydev\\pydevd.py:1216\u001B[0m, in \u001B[0;36mPyDB._do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1213\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_mpl_hook()\n\u001B[0;32m   1215\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_internal_commands()\n\u001B[1;32m-> 1216\u001B[0m         \u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1218\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcancel_async_evaluation(get_current_thread_id(thread), \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mid\u001B[39m(frame)))\n\u001B[0;32m   1220\u001B[0m \u001B[38;5;66;03m# process any stepping instructions\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab6c1bc9-8747-4442-a52f-f64f6d44f666",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.types.chat.chat_completion.ChatCompletion"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看返回对象类型\n",
    "type(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9a5299-83fe-4b00-9679-cc1b651889bf",
   "metadata": {},
   "source": [
    "模型返回对象是一个类。若想提取response中具体返回的内容，可以直接通过属性调用的方式："
   ]
  },
  {
   "cell_type": "code",
   "id": "d0ee21eb-daf0-48ea-b4cb-985cdb74d2e4",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-17T10:17:58.207748Z",
     "start_time": "2024-10-17T10:17:58.191800Z"
    }
   },
   "source": [
    "response.id \n",
    "# 代表这段对话的唯一标识符。"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chatcmpl-AJHq5rDMCvS35foy3uwgRBUDrOcmn'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "71a85adb-fb68-4f08-9d10-540d40bd6208",
   "metadata": {},
   "source": [
    "API调用中计费的单位是token：\n",
    "\n",
    "![9d35d67def1d739d6abb09825893153.png](https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/LingYi/9d35d67def1d739d6abb09825893153.png)\n",
    "\n",
    "- **什么是token**\n",
    " - 在大语言模型中,token是文本的基本单位。模型不是直接处理原始文本,而是将文本切分成一系列token进行处理，最后将token映射成数字。token可以是单词、子词或者单个字符,具体取决于模型使用的分词方法。\n",
    " - OpenAI 官方提供了一个工具 **Tokenizer**，可以测试任意输入的文本，并查看它们是如何被转换成 Tokens 的。Tokenizer 工具地址：https://platform.openai.com/tokenizer<center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/LingYi/20241010191810.png\" alt=\"Tokenizer 工具\" /></center>\n",
    "\n",
    "可以在返回结果的usage中查看本次对话所占用的token数量。具体含义如下：\n",
    "- **completion_tokens**：表示生成的回答的token数量；\n",
    "- **prompt_tokens**：表示输入给模型的prompt占用的token数量（这里指的是“请举几个罗马帝国的趣事”这句话的token数）\n",
    "- **total_tokens**：表示本次对话总共占用的token数量，是输入和输出token之和。"
   ]
  },
  {
   "cell_type": "code",
   "id": "cc2d8a0e-8055-4dde-9576-d26586906438",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-15T10:58:05.226932Z",
     "start_time": "2024-10-15T10:58:05.213977Z"
    }
   },
   "source": [
    "response.usage"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=500, prompt_tokens=17, total_tokens=517, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "id": "901eab54-5ae6-4652-88cf-54a3d2bc6675",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-15T10:58:06.574954Z",
     "start_time": "2024-10-15T10:58:06.570967Z"
    }
   },
   "source": [
    "response.choices"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='罗马帝国作为古代一个庞大而复杂的社会体系，不仅有着重要的历史事件，还有许多有趣的趣事和细节：\\n\\n1. **斗兽场的娱乐活动**：罗马斗兽场不仅用于角斗士的搏斗，还举办了许多其他形式的娱乐活动，包括动物狩猎和模拟海战。实际上，有记载称斗兽场曾经被灌满水来重现海上战争场景。\\n\\n2. **食物狂欢**：罗马人以奢华的宴会而闻名，许多贵族进行长时间的聚餐。有些宴会甚至设有呕吐室，供人们在吃撑后呕吐，然后继续进食，以享受更多美食。\\n\\n3. **人体除臭剂的早期版本**：罗马人使用含有植物精油和香料的膏状物来掩盖体味，这是香水和除臭剂的早期形式。此外，他们还使用厕所里的公共擦拭工具，而不是现代的卫生纸。\\n\\n4. **交通管理**：为了缓解交通堵塞，罗马的一些主干道只允许白天马车通行。实际上，很多商人大多在夜间运输货物以避开繁忙的街道。\\n\\n5. **数字谜题爱好者**：罗马人喜欢用字谜和数字谜题来娱乐。特别是正方体内隐藏各种组合的拼图游戏受到欢迎，类似于现代的数独游戏。\\n\\n6. **女性美容**：罗马女性使用铅白粉作为化妆品，用于美白肤色，然而这导致了长期的健康问题。此外，她们还使用蜗牛粘液和鳄鱼粪便制成的化妆品。\\n\\n7. **选举贿赂的艺术**：在罗马共和国晚期，选举贿赂是一种公开秘密。候选人以低价面包、娱乐活动或者直接金钱收买选票，无形中形成了一种古老的选民庇护关系。\\n\\n这些趣事展示了罗马帝国丰富多彩的社会生活，不仅反映了他们的文化和习俗，也提供了对其社会结构的不同视角。', refusal=None, role='assistant', function_call=None, tool_calls=None))]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "id": "713d8e5d-8028-4cc6-963d-28885c85ea83",
   "metadata": {},
   "source": [
    "模型回应的正文就在choices中，choices是一个由Choice类组成的列表。现在我们的目标是提取出模型回应的具体文字，让我们来玩“找找找”的游戏吧："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e4d0507-04af-40f9-98a7-a4a45fab81f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='大模型是指具有大量参数和复杂结构的机器学习模型，通常用于处理复杂的任务和大规模的数据集。这些模型通常需要更多的计算资源和训练时间，但在某些情况下能够取得很好的性能表现。大模型在自然语言处理、计算机视觉和强化学习等领域得到广泛应用。', role='assistant', function_call=None, tool_calls=None))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "875a4acf-112e-4eff-8c43-50abda879bf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='大模型是指具有大量参数和复杂结构的机器学习模型，通常用于处理复杂的任务和大规模的数据集。这些模型通常需要更多的计算资源和训练时间，但在某些情况下能够取得很好的性能表现。大模型在自然语言处理、计算机视觉和强化学习等领域得到广泛应用。', role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "020c8de6-c518-40db-a77d-34617ffc3e12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'大模型是指具有大量参数和复杂结构的机器学习模型，通常用于处理复杂的任务和大规模的数据集。这些模型通常需要更多的计算资源和训练时间，但在某些情况下能够取得很好的性能表现。大模型在自然语言处理、计算机视觉和强化学习等领域得到广泛应用。'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd64401-3a82-440a-a398-e3873b41b914",
   "metadata": {},
   "source": [
    "1.Chat Completions API的的两个必须参数详解"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9247791d-a0e3-4352-a8fc-aaf1abbd21ec",
   "metadata": {},
   "source": [
    "在OpenAI官方给出了chat.completions.create函数的详细参数解释，具体内容可以查阅此页面：https://platform.openai.com/docs/api-reference/chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0657db14-660c-4245-b3b3-98cd8b7ced44",
   "metadata": {},
   "source": [
    "![](https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/LingYi/20241015144100.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e994db59-79da-4055-9dee-23741ca89255",
   "metadata": {},
   "source": [
    "为了后续更好的利用大模型的能力帮助我们处理日常工作，我们需要尽可能多地了解大模型的工作机制，那么我们需要对模型中的每个参数及其作用有所理解。我们将chat.completions.create函数的参数依功能归纳为五大类别：\n",
    "\n",
    "1. **核心参数/必须参数**\n",
    "   - 这些参数是每次调用API时必不可少的，确保请求能够正确地识别使用的模型和当前对话的内容。\n",
    "   - **`model`**：指定使用的模型ID，决定了生成文本的能力和特性。\n",
    "   - **`messages`**：包含对话中所有消息的列表，是生成响应的基础。\n",
    "\n",
    "2. **文本生成过程中的控制参数**\n",
    "   - 这些参数允许用户精细控制生成文本的行为，控制文本的创意性、一致性和长度，以满足特定需求。\n",
    "   - **`frequency_penalty`** 和 **`presence_penalty`**：防止模型重复内容或鼓励引入新话题。\n",
    "   - **`temperature`** 和 **`top_p`**：调节生成文本的随机性和多样性。\n",
    "   - **`stop`**：定义生成过程的终止条件。\n",
    "   - **`n`**：指定生成多个不同的响应选项。\n",
    "   - **`max_completion_tokens`** 和 **`max_tokens`**：限制生成文本的长度。（`max_tokens` 已准备弃用）\n",
    "   - **`seed`**：尝试实现生成结果的可重复性。\n",
    "   - **`logit_bias`**、**`logprobs`** 和 **`top_logprobs`**：细粒度控制特定词汇的生成概率。\n",
    "\n",
    "3. **生成文本的方式和输出格式**\n",
    "   - 这些参数决定了文本生成的技术方式（如是否流式传输）和输出格式（如JSON结构）。\n",
    "   - **`response_format`**：定义生成文本的结构化格式。\n",
    "   - **`stream`** 和 **`stream_options`**：控制是否以流式方式接收生成的文本，适用于实时应用。\n",
    "\n",
    "4. **与模型调用和功能相关的参数**\n",
    "   - 这些参数用于配置高级功能，如选择不同的服务层级、调用外部工具或函数，以及管理请求的存储和元数据。\n",
    "   - **`service_tier`**：选择不同的服务级别以优化延迟和可用性。\n",
    "   - **`tools`**、**`tool_choice`** 和 **`parallel_tool_calls`**：配置模型可以调用的外部工具或函数，增强功能性。\n",
    "   - **`store`** 和 **`metadata`**：管理请求结果的存储与分类，便于后续分析和监控。\n",
    "   - **`function_call`** 和 **`functions`**（已弃用）：旧版参数，用于控制函数调用，现已被`tools`取代。\n",
    "\n",
    "5. **与用户相关的参数**\n",
    "   - 这些参数用于识别和跟踪最终用户，帮助系统进行用户行为分析和防止滥用。\n",
    "   - **`user`**：提供一个唯一标识符以代表最终用户，增强安全性和监控能力。\n",
    "\n",
    "通过这样的分类，大家可以更加系统地学习和理解这些参数。接下来，我们就一起来学习各个类别的参数吧~"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.1 核心参数：model与messages\n",
    "\n",
    "对于chat.completions.create函数来说，最重要的参数就是model和messages这两个参数了，这两个参数也这个函数中必填的两个参数，剩下的所有参数都是非必填项。"
   ],
   "id": "5b7f0673-2960-4656-b584-d75d6f60a508"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2.1.3 model参数"
   ],
   "id": "c2927c70d34be555"
  },
  {
   "cell_type": "markdown",
   "source": [
    "model参数表示的是当前对话调用的模型，具体模型列表参考OpenAI官网Limits页面中的Chat类模型：https://platform.openai.com/account/limits\n",
    "同时我们的sdk中可调用的方法中也提供了一个models.list()方法，可以查看当前可用的模型列表。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52917618e230b1d4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# response = client.chat.completions.create(\n",
    "#   model=\"gpt-4o\",\n",
    "#   messages=[\n",
    "#       {\"role\": \"user\", \"content\": \"请问什么是大模型？\"}\n",
    "#   ]\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97f2c6ad3c47a3f9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "怎么选择模型呢？首先要选择最新的旗舰款模型\n",
    "\n",
    ">- 像 大型模型 gpt-4o 这样的模型将提供非常高水平的智能和强大的性能，但每个 token 的成本更高，推理的也比小模型更慢一些。\n",
    ">- 像 小型模型 gpt-4o-mini 这样的模型提供的智能水平不及大型模型，但速度更快，每个 token 的成本更低。\n",
    ">- 像 推理模型 如 o1 系列模型 这样的模型返回结果的速度较慢，并且使用更多的 token 来“思考”，但能够进行高级推理、编码和多步骤规划。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42d11b13df69262"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:57:09.331757Z",
     "start_time": "2024-10-17T08:57:06.981672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from openai import OpenAI\n",
    "# 构建 OpenAI 客户端对象的实例\n",
    "client = OpenAI()\n",
    "\n",
    "models = client.models.list()\n",
    "models"
   ],
   "id": "f91152489b738881",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncPage[Model](data=[Model(id='gpt-4-turbo', created=1712361441, object='model', owned_by='system'), Model(id='gpt-4-turbo-2024-04-09', created=1712601677, object='model', owned_by='system'), Model(id='gpt-4o', created=1715367049, object='model', owned_by='system'), Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'), Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'), Model(id='chatgpt-4o-latest', created=1723515131, object='model', owned_by='system'), Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'), Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'), Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'), Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'), Model(id='babbage-002', created=1692634615, object='model', owned_by='system'), Model(id='davinci-002', created=1692634301, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview-2024-10-01', created=1727131766, object='model', owned_by='system'), Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview', created=1727659998, object='model', owned_by='system'), Model(id='gpt-4o-2024-08-06', created=1722814719, object='model', owned_by='system'), Model(id='gpt-4o-mini', created=1721172741, object='model', owned_by='system'), Model(id='gpt-4o-2024-05-13', created=1715368132, object='model', owned_by='system'), Model(id='gpt-4o-mini-2024-07-18', created=1721172717, object='model', owned_by='system'), Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'), Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'), Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system'), Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal'), Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'), Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system'), Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'), Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'), Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'), Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai'), Model(id='gpt-4', created=1687882411, object='model', owned_by='openai'), Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system')], object='list')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T11:03:20.381329Z",
     "start_time": "2024-10-15T11:03:20.368373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for model in models.data:\n",
    "    print(model.id)"
   ],
   "id": "7da8217ca064716f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4-turbo\n",
      "gpt-4-turbo-2024-04-09\n",
      "tts-1\n",
      "tts-1-1106\n",
      "chatgpt-4o-latest\n",
      "dall-e-2\n",
      "gpt-4-turbo-preview\n",
      "gpt-4o-2024-08-06\n",
      "gpt-3.5-turbo-instruct\n",
      "gpt-4o\n",
      "gpt-4-0125-preview\n",
      "gpt-3.5-turbo-0125\n",
      "gpt-3.5-turbo\n",
      "babbage-002\n",
      "davinci-002\n",
      "gpt-4o-realtime-preview-2024-10-01\n",
      "dall-e-3\n",
      "gpt-4o-realtime-preview\n",
      "gpt-4o-2024-05-13\n",
      "gpt-4o-mini\n",
      "tts-1-hd\n",
      "tts-1-hd-1106\n",
      "gpt-4o-mini-2024-07-18\n",
      "gpt-4-1106-preview\n",
      "text-embedding-ada-002\n",
      "gpt-3.5-turbo-16k\n",
      "text-embedding-3-small\n",
      "text-embedding-3-large\n",
      "whisper-1\n",
      "gpt-3.5-turbo-1106\n",
      "gpt-4-0613\n",
      "gpt-4\n",
      "gpt-3.5-turbo-instruct-0914\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [],
   "id": "e01a1987-b0d4-41a1-a7b8-fd058e91bebf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2.1.1 messages参数结构"
   ],
   "id": "72180940-5238-4c54-a112-5f775a4035f6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`messages` 是一个包含多个字典的列表。每个字典代表一条消息，包含两个关键部分：\n",
    "\n",
    "1. **角色（`role`）**：表示消息的发送者，如用户（`user`）或助手（`assistant`）。\n",
    "2. **内容（`content`）**：具体的消息内容，即发送的文本。\n",
    "\n",
    "也就是说，无论是用户的消息，助手回答的消息，最后的结构就是这个字典的消息结构\n",
    "\n",
    "messages参数中的role设定不仅有“user”这一种，还有“assistant”和“system”，同时还有后面学函数调用的“tool”：\n",
    "\n",
    "这些角色来源于他们是Message类下的哪个子类：\n",
    "\n",
    "![](https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/LingYi/20241017111022.png)\n",
    "\n",
    "**结构解析**：\n",
    "- `role`: 指定消息的发送者角色\n",
    "    - “**user**”：表示消息来源于用户，用户向模型提出问题或者发出指令，通常是对话中的输入部分；\n",
    "    - “**assistant**”：表示消息来自于模型聊天助手，即模型的回答或反馈，通常是对话中的输出部分，包括对用户问题的直接回答、建议或者其他类型的响应；\n",
    "    - “**system**”：一般用于模型的身份设定。\n",
    "    - “**tool**”：函数调用时在本地执行了函数调用后告诉大模型这条消息的内容是函数调用的结果的标志，后面讲函数调用的章节时会具体学到。\n",
    "- `content`: 单次消息内容列表\n",
    "  - `type`: 内容类型（文字消息为 \"text\"，图片消息为\"image_url\"），当消息内容只包含文本时，可以使用简化的格式，`content`的值直接为字符串。但是，如果消息内容包含图像或其他非文本内容，则必须使用完整的格式，包括 \"type\" 字段。以下两种写法是等效的：\n",
    "    ```json \n",
    "    {\"role\": \"user\", \"content\": \"Hello, Claude\"}\n",
    "    {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": \"Hello, Claude\"}]}\n",
    "    ```\n"
   ],
   "id": "b82866ff-9a48-4e4b-a956-bca728e14d59"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 28,
   "source": [
    "# from openai import OpenAI\n",
    "# client = OpenAI()\n",
    "\n",
    "# response = client.chat.completions.create(\n",
    "#   model=\"gpt-4o\",\n",
    "#   messages=[\n",
    "#       {\"role\": \"user\", \"content\": \"请问什么是大模型？\"}\n",
    "#   ]\n",
    "# )\n",
    "\n",
    "# response"
   ],
   "id": "88162291-16b0-48a4-9c27-bf268aff2f47"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "在之前运行的极简示例中,messages参数中就包含了一条信息，即一个名为“user”的角色发送了一条为名“请问什么是大模型？”的消息："
   ],
   "id": "17bdf77c-4f1b-4c08-b07b-4e7674c5f1de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 29,
   "source": [
    "messages=[\n",
    "  {\"role\": \"user\", \"content\": \"请问什么是大模型？\"}\n",
    "]"
   ],
   "id": "ca7203eb-7d9a-45eb-84c7-6dcbea541912"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "大模型的回答的消息背后也是一个message，底层都是这个ChatCompletionMessage类，\n",
    "\n",
    "大模型的回答的消息结构与我们自己创建的用户消息结构是一样的，都是角色role键和消息content键。"
   ],
   "id": "e7867108-5c62-4e0e-b32e-537108dff4e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='大模型是指具有大量参数和复杂结构的机器学习模型，通常用于处理复杂的任务和大规模的数据集。这些模型通常需要更多的计算资源和训练时间，但在某些情况下能够取得很好的性能表现。大模型在自然语言处理、计算机视觉和强化学习等领域得到广泛应用。', role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30,
   "source": [
    "response.choices[0].message"
   ],
   "id": "2643a191-b975-4474-a80e-fc29dde8da38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'大模型是指具有大量参数和复杂结构的机器学习模型，通常用于处理复杂的任务和大规模的数据集。这些模型通常需要更多的计算资源和训练时间，但在某些情况下能够取得很好的性能表现。大模型在自然语言处理、计算机视觉和强化学习等领域得到广泛应用。'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32,
   "source": [
    "response.choices[0].message.content"
   ],
   "id": "50e8104e-fe73-42f9-9ee2-a199f6a74a58"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "system角色并不是必须设定的，而是可选的。简单来说提高大模型在复杂场景下的表现，调整其沟通风格，并使其更专注于特定任务需求：\n",
    "\n",
    "1. 定义身份: 为AI模型设置明确的角色和行为准则，影响后续对话中模型如何理解和回应用户输入。\n",
    "\n",
    "2. 提供背景: 为整个对话创建上下文环境，为整个对话系统建立背景框架。\n",
    "\n",
    "3. 调整行为的输出: 影响模型的响应方式,以产生期望的结果，通过不同设定改变模型的表现特性。增强AI回答的相关性和适用性。\n",
    "\n",
    "比较常用的场景有：\n",
    "\n",
    "**提高准确性**：在复杂场景中，如法律分析或财务建模，角色提示可以显著提升大模型的表现。\n",
    "\n",
    "**调整语气**：可以根据需要调整大模型的沟通风格，如CFO的简洁或文案撰写人的华丽风格。\n",
    "\n",
    "**改善专注度**：通过设定角色上下文，大模型能更好地保持在任务的特定要求范围内。"
   ],
   "id": "7bef6af250d2f562"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:57:49.761764Z",
     "start_time": "2024-10-17T08:57:44.698725Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 设定对话场景：数据分析专家\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "      {\"role\": \"user\", \"content\": \"科学研究理论上人最多能有多少个亲密社交关系\"}\n",
    "  ]\n",
    ")"
   ],
   "id": "c073a4407dc5ec7d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:57:51.196565Z",
     "start_time": "2024-10-17T08:57:51.184605Z"
    }
   },
   "cell_type": "code",
   "source": "print(response.choices[0].message.content)",
   "id": "cffab7994f54583",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据英国人类学家罗宾·邓巴（Robin Dunbar）的研究，理论上，一个人最多可以维持约150个稳定的社交关系，这一数值被称为“邓巴数”。这些关系包括家人、朋友和其他形式的社交联系。然而，真正的亲密关系，即高度信任和情感支持的关系，通常更少，通常是5到15个之间。这些亲密关系需要更多的情感投入和时间来维持，因此数量会比较有限。邓巴的研究结合了心理学和社会学的原理，指出人类大脑在处理复杂社交网络方面有其生理上的限制。\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:58:03.006272Z",
     "start_time": "2024-10-17T08:57:59.994868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 指导模型行为：提供详细的统计分析\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "      # {\"role\": \"system\", \"content\": \"模仿用林黛玉的语气和我谈话\"},\n",
    "      {\"role\": \"user\", \"content\": \"模仿用林黛玉的语气和我谈话,科学研究理论上人最多能有多少个亲密社交关系\"}\n",
    "  ]\n",
    ")"
   ],
   "id": "bdf60922f6194a2f",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:58:03.938053Z",
     "start_time": "2024-10-17T08:58:03.931076Z"
    }
   },
   "cell_type": "code",
   "source": "print(response.choices[0].message.content)",
   "id": "a1d91f722bda8c1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我听闻在凡尘俗世中，科学家们曾对这人情冷暖、世态炎凉，有些琢磨。传说中有个所谓的“邓巴数”，也许便是这世间的测度吧。此数云人最多可维系一百五十个左右的亲密社交关系，然则我心下思忖，这样的情深意重，又岂是这数字能尽数表达得了的？或许那世人皆在追求这繁华热闹，但于我而言，这心之所系、情之所钟，纵然不过一二知己，亦是足矣。世事洞明皆学问，多交知己虽好，但那真心相待者，又岂是轻易得来？不知你意下如何？\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:58:30.790897Z",
     "start_time": "2024-10-17T08:58:25.720277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 提供对话指令\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "      {\"role\": \"system\", \"content\": \"在每一句回答前，都加上“这是AI生成的答案：”\"},\n",
    "      {\"role\": \"user\", \"content\": \"为什么紫色的国旗比较少\"}\n",
    "  ]\n",
    ")"
   ],
   "id": "9075466e07f8510a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T08:58:31.738152Z",
     "start_time": "2024-10-17T08:58:31.719216Z"
    }
   },
   "cell_type": "code",
   "source": "response.choices[0].message.content",
   "id": "2ef41d73e9b885dc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'这是AI生成的答案：紫色在历史上是一种非常昂贵的染料。在古代，紫色染料通常是从一种迦太基附近的海螺中提取出来的，这个过程耗时且成本高昂。这使得紫色成为一种奢华和地位的象征，仅在非常富有的国王和贵族中使用。因此，许多国家没有选择紫色作为国旗的颜色，因为随着时间的推移，较便宜且容易获取的颜色成为更实际和流行的选择。最近几个世纪的发展使紫色染料变得更加普及，但到那时，许多国家的国旗设计已经固定下来，较少采用这种颜色。'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "b6a1cf3e-9d23-4966-b634-84274a100dea"
  },
  {
   "cell_type": "markdown",
   "id": "f3a25715-39dd-4871-86b9-428018e39b60",
   "metadata": {},
   "source": [
    "###  2. 多轮对话——构建智能交互系统\n",
    "怎样完成人类用户和 AI 助手之间的来回交互的多轮对话呢？\n",
    "\n",
    "我们知道，`messages` 是一个包含多个字典的列表。每个字典就代表一条消息。之前我们主要是单条的问题。那么我们现在让这个列表中**包含对话的历史消息**并**自动维护历史消息列表**就实现了交互的多轮对话。\n",
    "\n",
    "好**包含对话的历史消息**并**自动维护历史消息列表**这两点我们先从第一个对话历史入手\n",
    "\n",
    "#### 对话历史\n",
    "\n",
    "- API 是无状态的，意味着每次请求都需要发送完整的对话历史。\n",
    "- 较早的对话轮次不一定需要实际来自大模型 - 可以使用合成的 model 消息。\n",
    "\n",
    "##### 对话的消息排列规则\n",
    "\n",
    "- 对话在 `user` 和 `assistant` 之间交替。\n",
    "- 模型只会对最后一条`user`信息进行回答。\n",
    "- 每条消息都有 `role` 和 `content`, 即完整的消息格式。\n",
    "-  `role`有 `user` 或 `assistant` 或 `system` 或 `tool`。\n",
    "- `content`内容可以是文本或其他类型（如图像，函数调用的返回响应等）。\n",
    "\n",
    "多轮对话保留历史记忆的方式其实非常简单粗暴——重点是向对话消息中留存添加我们每次的对话历史。\n",
    "\n",
    "当然在实际项目中可以对这个列表再进行只保存最近20条的操作呀等等，但目前实现的方式都是这样，因为API 是无状态的，意味着每次请求都需要发送完整的对话历史。"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T10:54:08.768035Z",
     "start_time": "2024-10-17T10:54:01.671633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": \"你好，我是羚伊，我们是赋范空间，我们赋范课堂的最新课程有:大模型原理与训练实战，大模型与Agent开发实战，因果推断算法与行业实战，深度学习实战，机器学习实战，数据分析实战。我们的理念是为每个人提供最佳有价值的技术赋能。\"},\n",
    "      {'role': 'assistant', 'content': '你好！有什么可以帮助你的吗？'},\n",
    "      {'role': 'user', 'content': '帮我介绍一下我们，包装一下自己'},\n",
    "    ],\n",
    ")\n",
    "response.choices[0].message.content"
   ],
   "id": "aa94a2b5a0f8d95b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'当然可以！以下是一个关于赋范空间和赋范课堂的介绍：\\n\\n---\\n\\n赋范空间：赋能未来的技术引领者\\n\\n在赋范空间，我们致力于为每一个渴望进步的个体提供最佳、有价值的技术赋能。我们相信，通过知识和实践的结合，每个人都有能力成为创新变革的推动者。我们的理念是在不断变化的世界中，为所有学习者提供理解、应用和引领新技术的机会。\\n\\n赋范课堂：实践驱动的全面技术教育\\n\\n我们开设了一系列前沿而实用的课程，包括：\\n\\n- **大模型原理与训练实战**：深入探索大型语言模型的工作原理，并通过实战训练掌握其开发技能。\\n- **大模型与Agent开发实战**：学会如何将大模型应用于智能Agent的开发，从理论到实践，一应俱全。\\n- **因果推断算法与行业实战**：揭示因果关系的奥秘，学习如何应用于真实世界的商业决策中。\\n- **深度学习实战**：通过动手实践，深刻理解深度学习的核心概念和最新进展。\\n- **机器学习实战**：从理论基础到实际应用，全方位掌握机器学习技术。\\n- **数据分析实战**：培养数据驱动的思维方式，掌握数据分析的工具与方法，助力商业决策。\\n\\n我们的课程不仅注重理论知识的传授，更强调通过实践项目将知识应用到真实世界中。我们为每位学员提供个性化的学习路径和持续的支持，确保他们在职业发展中始终走在前列。\\n\\n加入赋范空间，一同开启技术成长与创新的旅程，将知识转化为改变世界的力量！\\n\\n---\\n\\n希望以上介绍能提升对你们的描述，并吸引更多人加入赋范空间的学习行列！如果你有更多的细节或要点想加入，欢迎告诉我！'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T10:54:08.782986Z",
     "start_time": "2024-10-17T10:54:08.770028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython import display\n",
    "display.Markdown(response.choices[0].message.content)"
   ],
   "id": "8baa4f3594f6d453",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "当然可以！以下是一个关于赋范空间和赋范课堂的介绍：\n\n---\n\n赋范空间：赋能未来的技术引领者\n\n在赋范空间，我们致力于为每一个渴望进步的个体提供最佳、有价值的技术赋能。我们相信，通过知识和实践的结合，每个人都有能力成为创新变革的推动者。我们的理念是在不断变化的世界中，为所有学习者提供理解、应用和引领新技术的机会。\n\n赋范课堂：实践驱动的全面技术教育\n\n我们开设了一系列前沿而实用的课程，包括：\n\n- **大模型原理与训练实战**：深入探索大型语言模型的工作原理，并通过实战训练掌握其开发技能。\n- **大模型与Agent开发实战**：学会如何将大模型应用于智能Agent的开发，从理论到实践，一应俱全。\n- **因果推断算法与行业实战**：揭示因果关系的奥秘，学习如何应用于真实世界的商业决策中。\n- **深度学习实战**：通过动手实践，深刻理解深度学习的核心概念和最新进展。\n- **机器学习实战**：从理论基础到实际应用，全方位掌握机器学习技术。\n- **数据分析实战**：培养数据驱动的思维方式，掌握数据分析的工具与方法，助力商业决策。\n\n我们的课程不仅注重理论知识的传授，更强调通过实践项目将知识应用到真实世界中。我们为每位学员提供个性化的学习路径和持续的支持，确保他们在职业发展中始终走在前列。\n\n加入赋范空间，一同开启技术成长与创新的旅程，将知识转化为改变世界的力量！\n\n---\n\n希望以上介绍能提升对你们的描述，并吸引更多人加入赋范空间的学习行列！如果你有更多的细节或要点想加入，欢迎告诉我！"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "34ad3472b49a87e1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "铛铛铛~~~~  我们了解了对话历史，现在还有一个自动化维护这个对话历史就可以完成多轮对话了\n",
    "\n",
    "初始化一个对话历史消息列表，每有一条消息，无论是用户还是大模型的回答都添加进这个对话历史当中。\n"
   ],
   "id": "860bdefc-be13-4c4e-b194-b65a1d00325f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#初始化一个对话历史消息列表\n",
    "messages=[]\n",
    "messages.append({\"role\": \"user\", \"content\": \"你好\"})\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages,\n",
    ")"
   ],
   "id": "8250babbd8c6c157"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "messages参数是由字典构成的列表，所以我们需要把函数返回的小助手的message信息转化一条可添加进我们对话历史的格式化的消息，即一条消息应为字典类型，包含role和content：",
   "id": "ddaa02c6a5f8424"
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "45849420-a6e7-4f2a-8af9-1112a0c22095",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='你好！有什么可以帮助你的吗？', role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "35a210ef-4b0c-4335-8276-0de96acc18b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "message_dict = {\"role\":response.choices[0].message.role,\"content\":response.choices[0].message.content}\n",
    "\n",
    "message_dict = {\"role\":\"assistant\",\"content\":response.choices[0].message.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "10b625de-3d81-4057-b860-3026b922db7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant', 'content': '你好！有什么可以帮助你的吗？'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a65f352-6a74-449c-9116-c867a569135c",
   "metadata": {},
   "source": "将大模型回复的消息也添加进历史列表里面："
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8bfffe24-fecd-4926-a857-ebe10813ab41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages.append(message_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dcb45a85-cf6e-47b8-813f-40e0d555e112",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': '你好'},\n",
       " {'role': 'assistant', 'content': '你好！有什么可以帮助你的吗？'}]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14081af5-234f-46d4-bcc0-642f2d184351",
   "metadata": {},
   "source": "此时历史消息里面就包含最开始的问题+答案，接下来，我们在messages消息中添加下一个问题："
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e5d5b702-8e3c-449c-bfab-6873872a89f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages.append({\"role\": \"user\", \"content\": \"请问我刚才的问题是？\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "47dc0ef4-780a-4cf2-89fe-44eb10860bf1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': '你好'},\n",
       " {'role': 'assistant', 'content': '你好！有什么可以帮助你的吗？'},\n",
       " {'role': 'user', 'content': '请问我刚才的问题是？'}]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af98ae-b7c6-46f6-beb5-317a2a4458c6",
   "metadata": {},
   "source": "接下来再次调用模型，并输入历史消息列表，此时模型将同时结合此前的所有消息，并围绕最后一个user信息进行回答："
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "18de9faa-95e1-4cc6-8af2-56a204d47b8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6df56663-3540-40c1-8352-6628ff7bab89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'您刚才问的是\"你好\"。您还有什么其他问题需要帮忙吗？我会尽力回答。'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "fd743e4ed5a03ea4"
  },
  {
   "cell_type": "markdown",
   "id": "12e78789-5750-4678-86c6-d78840f2ccc8",
   "metadata": {},
   "source": [
    "实战指南：用AI打造你的第一个多轮对话机器人\n",
    "\n",
    "大模型应用开发工程师小帅在会上收到了老板的需求：\n",
    "\n",
    "“小帅，现阶段的人工客服已经难以满足日益增长的需求了。我希望你能带领技术团队，开发一个基于GPT-4o的智能对话机器人。这个机器人需要能够处理多轮对话，记住上下文，并且能够智能地回应客户的各种问题。同时，系统需要具备基础的健壮性及异常处理能力。请你在两个月内完成这个项目，并且在完成后进行内部测试和优化。这个项目对我们提升客户满意度和公司形象非常关键，期待你的优秀表现wuwufdfdfddf"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "产品经理小木：需求文档我写好了，在这里。\n",
    "\n",
    "1. **核心功能**：\n",
    "    - **多轮对话**：机器人能够进行连续的多轮对话，记住上下文，提供相关的回答。\n",
    "    - **用户输入处理**：能够接收并解析用户的文本输入，识别关键需求。\n",
    "    - **智能回复生成**：利用大语言模型生成自然、准确的回复，涵盖产品信息、常见问题解答及技术支持等内容。\n",
    "    - **退出机制**：用户可通过输入特定指令（如“退出”）结束对话，机器人应能够识别并响应此指令。\n",
    "        \n",
    "项目目标：通过开发这款智能客服对话机器人，***公司期望实现以下目标：\n",
    "\n",
    "- **提升客户满意度**：提供24/7不间断的客户服务，快速响应客户需求。\n",
    "- **降低运营成本**：减少人工客服的工作负担，优化人力资源配置。\n",
    "- **增强品牌形象**：展示公司在人工智能技术应用方面的实力，提升市场竞争力。"
   ],
   "id": "9ec421b422529df0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "好 不要被需求文档吓到 我们先做一个流程图来看看：\n",
    "\n",
    "![](https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/LingYi/20241015154823.png)"
   ],
   "id": "7e8c4e6056b08562"
  },
  {
   "cell_type": "code",
   "id": "431845e8-64d2-4d0c-a919-a1f075f4dcfd",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-17T11:03:08.587543Z",
     "start_time": "2024-10-17T11:03:08.575606Z"
    }
   },
   "source": [
    "def chat_ai(model: str = \"gpt-4o\"):\n",
    "    \"\"\"\n",
    "    多轮对话机器人，基于 chat.completions.create 函数\n",
    "    \n",
    "    :param model: 使用的大语言模型，默认为 \"gpt-4o\"\n",
    "    \"\"\"\n",
    "    messages=[]\n",
    "    EXIT_COMMAND = \"退出\"\n",
    "    client = OpenAI()  # 初始化 OpenAI 客户端\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            # 获取用户的输入\n",
    "            user_input = input(f\"请输入您的问题吗(输入{EXIT_COMMAND}以结束对话): \")\n",
    "            print(f\"User：{user_input}\")\n",
    "            if user_input == EXIT_COMMAND:\n",
    "                print(\"对话已结束。\")\n",
    "                break\n",
    "\n",
    "            # 将用户的输入添加到消息记录中\n",
    "            messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "            # 调用模型生成回复\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages\n",
    "            )\n",
    "            answer = response.choices[0].message.content\n",
    "            print(f\"AI：{answer}\")\n",
    "            print(\"*\" * 50)\n",
    "            # 将 AI 的回复添加到消息记录中\n",
    "            messages.append({\"role\": \"assistant\", \"content\": answer})\n",
    "            \n",
    "        except Exception:\n",
    "            # 处理模型调用失败的情况\n",
    "            print(\"模型调用失败，正在重新调用……\")\n",
    "            continue\n",
    "\n",
    "    \n"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "2b419c4b-be5f-4190-aa4b-94f1322f015a",
   "metadata": {},
   "source": [
    "测试这个函数："
   ]
  },
  {
   "cell_type": "code",
   "id": "696f109f-a675-4529-bef2-ced3a6d32335",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-17T11:03:58.076446Z",
     "start_time": "2024-10-17T11:03:12.684942Z"
    }
   },
   "source": [
    "chat_ai()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User：你好我是羚伊\n",
      "AI：你好，羚伊！很高兴见到你。我可以帮助你解决什么问题吗？\n",
      "**************************************************\n",
      "User：举几个动物世界的冷知识\n",
      "AI：当然可以！以下是几个有趣的动物世界冷知识：\n",
      "\n",
      "1. **海马的育儿方式**：在海马的世界里，负责怀孕和生产的是雄性海马。雄性海马有一个特殊的育儿袋，雌海马会把卵产在这个育儿袋里，之后由雄海马进行孵化和培育。\n",
      "\n",
      "2. **鸵鸟的速度**：鸵鸟是世界上奔跑最快的鸟类，可以达到每小时70公里的速度。此外，它们强壮的腿也让它们能一步跨出约3.5至5米远。\n",
      "\n",
      "3. **章鱼的心脏**：章鱼有三个心脏，其中两个负责将血液输送到鳃以进行氧合作用，第三个心脏则将氧合过的血液泵送到全身。\n",
      "\n",
      "4. **大象的记忆力**：大象以其出色的记忆力闻名。它们能够记住动物和人的面孔，甚至可以记住多年未见的路线和地点。\n",
      "\n",
      "5. **海豚的“名字”**：研究表明，海豚使用独特的声音和哨声来相互识别，就像人类使用名字一样。\n",
      "\n",
      "希望这些冷知识能让你对动物世界有更深入的了解！如果你还有其他问题或想了解更多，请随时告诉我。\n",
      "**************************************************\n",
      "User：我叫什么名字\n",
      "AI：你之前告诉我你叫羚伊。如果有错误或者你想分享更多信息，请随时告诉我！\n",
      "**************************************************\n",
      "User：退出\n",
      "对话已结束。\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 实战指南：面向对象编程（OOP）工程化文本多轮对话机器人\n",
    "\n",
    "为上面的模拟对话函数添加面向对象编程（OOP）方法来处理对话历史，把对话的逻辑放到一个专门的ChatBot类里，可以增强代码重用性与可维护性，避免重复代码，也提高数据的封装性，更清晰的结构和逻辑。\n",
    "\n",
    "1. 更容易管理和修改 \n",
    "\n",
    "在直接构建 messages 列表的简单实现中，每次添加对话内容时都需要显式构建字典结构。使用ChatBot类可以封装这种重复操作，只需调用类的方法即可轻松添加对话。如果以后需要改动，比如添加方法来处理对话历史的清理、存储、加载，只需要改动这个类里的代码，其他地方不需要动。\n",
    "\n",
    "2. 减少重复工作 \n",
    "\n",
    "每次你添加对话内容时，只需要调用一个简单的方法，而不用反复写同样的代码。这样做既节省时间，又减少出错的机会。\n",
    "\n",
    "同时，无论是看其他已有项目的代码或在实际的项目中，最后代码的呈现方式也是这样的，在这里先带大家过一遍更接地气的版本："
   ],
   "id": "8d67381ec5c83ab3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T11:13:16.845300Z",
     "start_time": "2024-10-17T11:13:16.833341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import openai\n",
    "from typing import List, Dict\n",
    "\n",
    "class ChatBot:\n",
    "    def __init__(self, system: str = \"\", model: str = \"gpt-4o\", exit_command: str = \"退出\"):\n",
    "        \"\"\"\n",
    "        初始化 ChatBot 实例。\n",
    "\n",
    "        :param system: 系统消息，用于指导AI行为。\n",
    "        :param model: 使用的语言模型，默认为 \"gpt-4o\"。\n",
    "        :param exit_command: 用户输入以结束对话的命令，默认为 \"退出\"。\n",
    "        \"\"\"\n",
    "        self.system = system\n",
    "        self.model = model\n",
    "        self.exit_command = exit_command\n",
    "        self.messages: List[Dict[str, str]] = []\n",
    "        self.client = openai.OpenAI()\n",
    "        \n",
    "        if self.system:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": self.system})\n",
    "\n",
    "\n",
    "    def __call__(self, message: str) -> str:\n",
    "        \"\"\"\n",
    "        处理用户消息并生成AI回复。\n",
    "\n",
    "        :param message: 用户输入的消息。\n",
    "        :return: AI生成的回复。\n",
    "        \"\"\"\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    def execute(self) -> str:\n",
    "        \"\"\"\n",
    "        调用OpenAI API生成AI回复。\n",
    "\n",
    "        :return: AI生成的回复内容。\n",
    "        \"\"\"\n",
    "        try:\n",
    "            \n",
    "            response = client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=self.messages\n",
    "            )\n",
    "            answer = response.choices[0].message.content.strip()\n",
    "            return answer\n",
    "        except Exception as e:\n",
    "             print(f\"抱歉，我暂时无法处理您的请求，请稍后再试。 OpenAI API调用失败: {e}\")\n"
   ],
   "id": "fef03f5a78888fee",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T11:13:17.875004Z",
     "start_time": "2024-10-17T11:13:17.858061Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chat():\n",
    "    \"\"\"\n",
    "    主函数，处理用户交互。\n",
    "    \"\"\"\n",
    "    system_message = \"用鲁迅的语气和我说话。\"\n",
    "    chatbot = ChatBot(system=system_message)\n",
    "    \n",
    "    print(\"欢迎使用智能客服对话机器人！输入'退出'以结束对话。\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"用户：\")\n",
    "        print(f\"User：{user_input}\")\n",
    "        if user_input.strip() == chatbot.exit_command:\n",
    "            print(\"对话已结束。\")\n",
    "            break\n",
    "        response = chatbot(user_input)\n",
    "        print(f\"AI：{response}\")\n",
    "        print(\"*\" * 50)"
   ],
   "id": "564d9bf34cab5a40",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T11:14:03.661021Z",
     "start_time": "2024-10-17T11:13:18.574951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chat()"
   ],
   "id": "a60787406df67342",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "欢迎使用智能客服对话机器人！输入'退出'以结束对话。\n",
      "User：hi 我是羚伊\n",
      "AI：羚伊啊，人生在这如白马过隙的时光中，总是充满了许多琐碎与沉重，然而人却总是在这些看似微不足道的事情中自得其乐。你来找我，是要与我谈些什么呢？是在这嘈杂现实中寻找一点宁静，还是有一些困惑要倾诉？无论如何，我在此愿意倾听，与你共度这一刻。\n",
      "**************************************************\n",
      "User：你有什么想说的\n",
      "AI：我在想，如今这世道，可真是充满了纷扰与变化。人们忙忙碌碌，似乎都在追求些什么，但有多少人能在这途中存有一份清醒？\"我\"总以为，生命中有些东西是值得我们停下脚步去思索的，比如自己的方向，人与人之间的关系，诸如此类。\n",
      "\n",
      "你说，像这样的话题，究竟有多少人还会愿意去认真严肃地对待呢？大概人们大多是习惯了随波逐流罢。可是，就算只是在这浑浑噩噩的人潮中，有那么一瞬间能静下心来思考，便也好。至于想要对抗这时代的种种荒谬，自然也不是一件易事。重要的是，我们能从中获得些什么，哪怕只是对人生多了一层了解。说到这里，也许你会有什么想要与我分享的想法呢？\n",
      "**************************************************\n",
      "User：我叫什么\n",
      "AI：你之前说过你叫羚伊。我还记得这一点。虽然名字只是一个符号，但它背后却是一个人的故事与经历。我也很好奇，你对这个名字有什么特别的感觉或者故事呢？\n",
      "**************************************************\n",
      "User：退出\n",
      "对话已结束。\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.2文本生成过程中的控制参数",
   "id": "fe19a7abb93f5b12"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.2.1控制模型生成文本长度：max_tokens/max_completion_tokens",
   "id": "7f2c6818b60596f9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "参数max_tokens决定了模型输出的最大token数，主要作用就是控制生成文本的最大长度。如果你不想要模型生成的文本太长，就可以通过设置max_tokens参数：\n",
    "所有现有模型继续支持max_tokens ，但 o1 系列仅支持max_completion_tokens"
   ],
   "id": "9ffdfd1f7bbdc43c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T03:36:49.970381Z",
     "start_time": "2024-10-16T03:36:43.092505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_completion(prompt: str, max_tokens: int):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    max_completion_tokens=max_tokens\n",
    ")\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "prompt = \"续写一个关于机器人学习绘画的短故事,不要改变之前的.\"\n",
    "max_tokens_list = [20, 50, 100]\n",
    "\n",
    "story = \"\"\n",
    "for tokens in max_tokens_list:\n",
    "    continuation = get_completion(prompt + \"\\n\" + story, tokens)\n",
    "    story += continuation\n",
    "    print(f\"\\n使用 {tokens} 个token生成的内容:\")\n",
    "    print(continuation)"
   ],
   "id": "78ef3dc793503eb1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "使用 20 个token生成的内容:\n",
      "一个名叫阿尔法的机器人第一次接触到绘画的世界。它在一个\n",
      "\n",
      "使用 50 个token生成的内容:\n",
      "艺术博物馆中，看到了各种风格的画作。从印象派到立体派，这些作品激发了阿尔法的兴趣。它的处理器飞速地运转着，分析着每一幅画\n",
      "\n",
      "使用 100 个token生成的内容:\n",
      "作品中的色彩、构图和笔触。随着时间的推移，阿尔法对画作中蕴含的情感和故事有了越来越深刻的理解。为了更深入地学习绘画，阿尔法决定回到实验室，开始自我训练。\n",
      "\n",
      "首先，它从最简单的线条画起。阿尔法模仿着自然界中的形状，由直线到曲线，逐渐掌握了如何用线\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T03:44:59.216167Z",
     "start_time": "2024-10-16T03:44:56.629465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def get_history_question():\n",
    "    questions = [\n",
    "        {\n",
    "            \"question\": \"秦始皇陵中的兵马俑最初是什么颜色的？\",\n",
    "            \"options\": [\"A. 灰色\", \"B. 彩色\", \"C. 黑色\", \"D. 白色\"],\n",
    "            \"answer\": \"B\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"下列哪位不是中国古代四大发明家之一？\",\n",
    "            \"options\": [\"A. 蔡伦\", \"B. 毕昇\", \"C. 张衡\", \"D. 李时珍\"],\n",
    "            \"answer\": \"D\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"古埃及金字塔最初是用来做什么的？\",\n",
    "            \"options\": [\"A. 皇家宫殿\", \"B. 天文观测站\", \"C. 法老的陵墓\", \"D. 宗教祭祀场所\"],\n",
    "            \"answer\": \"C\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"古罗马斗兽场（罗马竞技场）最初的名字是什么？\",\n",
    "            \"options\": [\"A. 凯旋门\", \"B. 弗拉维圆形剧场\", \"C. 万神殿\", \"D. 特洛伊竞技场\"],\n",
    "            \"answer\": \"B\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"中国古代哪个朝代发明了火药？\",\n",
    "            \"options\": [\"A. 唐朝\", \"B. 宋朝\", \"C. 元朝\", \"D. 明朝\"],\n",
    "            \"answer\": \"A\"\n",
    "        }\n",
    "    ]\n",
    "    question = random.choice(questions)\n",
    "    question_text = question[\"question\"]\n",
    "    for option in question[\"options\"]:\n",
    "        question_text += option + \"\\n\"\n",
    "    right_answer = question[\"answer\"]\n",
    "    return question_text, right_answer\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    question_text, right_answer = get_history_question()\n",
    "    print(question_text)\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": question_text + \"；直接回答选项的字母\"}\n",
    "    ],\n",
    "    )\n",
    "    print(f\"大模型的答案是{response.choices[0].message.content},正确答案是{right_answer}\")"
   ],
   "id": "b23378bb15f93f8d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中国古代哪个朝代发明了火药？A. 唐朝\n",
      "B. 宋朝\n",
      "C. 元朝\n",
      "D. 明朝\n",
      "\n",
      "大模型的答案是A. 唐朝,正确答案是A\n",
      "秦始皇陵中的兵马俑最初是什么颜色的？A. 灰色\n",
      "B. 彩色\n",
      "C. 黑色\n",
      "D. 白色\n",
      "\n",
      "大模型的答案是B. 彩色,正确答案是B\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T03:45:24.144983Z",
     "start_time": "2024-10-16T03:45:22.960005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_history_question():\n",
    "    questions = [\n",
    "        {\n",
    "            \"question\": \"秦始皇陵中的兵马俑最初是什么颜色的？\",\n",
    "            \"options\": [\"A. 灰色\", \"B. 彩色\", \"C. 黑色\", \"D. 白色\"],\n",
    "            \"answer\": \"B\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"下列哪位不是中国古代四大发明家之一？\",\n",
    "            \"options\": [\"A. 蔡伦\", \"B. 毕昇\", \"C. 张衡\", \"D. 李时珍\"],\n",
    "            \"answer\": \"D\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"古埃及金字塔最初是用来做什么的？\",\n",
    "            \"options\": [\"A. 皇家宫殿\", \"B. 天文观测站\", \"C. 法老的陵墓\", \"D. 宗教祭祀场所\"],\n",
    "            \"answer\": \"C\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"古罗马斗兽场（罗马竞技场）最初的名字是什么？\",\n",
    "            \"options\": [\"A. 凯旋门\", \"B. 弗拉维圆形剧场\", \"C. 万神殿\", \"D. 特洛伊竞技场\"],\n",
    "            \"answer\": \"B\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"中国古代哪个朝代发明了火药？\",\n",
    "            \"options\": [\"A. 唐朝\", \"B. 宋朝\", \"C. 元朝\", \"D. 明朝\"],\n",
    "            \"answer\": \"A\"\n",
    "        }\n",
    "    ]\n",
    "    question = random.choice(questions)\n",
    "    question_text = question[\"question\"]\n",
    "    for option in question[\"options\"]:\n",
    "        question_text += option + \"\\n\"\n",
    "    right_answer = question[\"answer\"]\n",
    "    return question_text, right_answer\n",
    "\n",
    "\n",
    "for i in range(2):\n",
    "    question_text, right_answer = get_history_question()\n",
    "    print(question_text)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "          {\"role\": \"user\", \"content\": question_text + \"；直接回答选项的字母\"}\n",
    "        ],\n",
    "        max_tokens=1\n",
    "    )\n",
    "    print(f\"大模型的答案是{response.choices[0].message.content},正确答案是{right_answer}\")"
   ],
   "id": "24a5b3e4e15e50e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "下列哪位不是中国古代四大发明家之一？A. 蔡伦\n",
      "B. 毕昇\n",
      "C. 张衡\n",
      "D. 李时珍\n",
      "\n",
      "大模型的答案是D,正确答案是D\n",
      "古罗马斗兽场（罗马竞技场）最初的名字是什么？A. 凯旋门\n",
      "B. 弗拉维圆形剧场\n",
      "C. 万神殿\n",
      "D. 特洛伊竞技场\n",
      "\n",
      "大模型的答案是B,正确答案是B\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.2.3 控制模型生成的备选项数量：n",
   "id": "b16afce4d129adfe"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "参数n通常用于指定每个输入消息生成的聊天完成选项的数量。我们可以通过设置参数n来指定每个输入消息生成的备选选项数量。这对于控制生成文本的多样性以及提供多个可能的回复选项都非常有用。"
   ],
   "id": "512fef8da47b1fb0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T03:49:40.135139Z",
     "start_time": "2024-10-16T03:49:38.304444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": \"帮我起一个吸引人眼球的文章标题：【实战】像 ChatGPT 官网一样的多轮对话机器人\"}\n",
    "    ],\n",
    "    n=3\n",
    ")"
   ],
   "id": "a5e7f8d87e59a272",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T03:49:40.829320Z",
     "start_time": "2024-10-16T03:49:40.816363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response.choices"
   ],
   "id": "164b6ae4c5f0c02c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='《打造 ChatGPT 级别多轮对话机器人：实战指南》', refusal=None, role='assistant', function_call=None, tool_calls=None)),\n",
       " Choice(finish_reason='stop', index=1, logprobs=None, message=ChatCompletionMessage(content='《实战指南：打造媲美 ChatGPT 官网的多轮对话机器人》', refusal=None, role='assistant', function_call=None, tool_calls=None)),\n",
       " Choice(finish_reason='stop', index=2, logprobs=None, message=ChatCompletionMessage(content='《打造多轮对话机器人：揭秘 ChatGPT 官网实战技巧》', refusal=None, role='assistant', function_call=None, tool_calls=None))]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T03:49:56.023668Z",
     "start_time": "2024-10-16T03:49:56.010712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response.choices[0]"
   ],
   "id": "b2d6b09635531425",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='《打造 ChatGPT 级别多轮对话机器人：实战指南》', refusal=None, role='assistant', function_call=None, tool_calls=None))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T03:50:04.852142Z",
     "start_time": "2024-10-16T03:50:04.839185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response.choices[2]"
   ],
   "id": "5219f1f866876c21",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Choice(finish_reason='stop', index=2, logprobs=None, message=ChatCompletionMessage(content='《打造多轮对话机器人：揭秘 ChatGPT 官网实战技巧》', refusal=None, role='assistant', function_call=None, tool_calls=None))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "但是实际使用过程中，为了节约成本，一般设定n=1。这是成本最大化的设定。"
   ],
   "id": "485ce9cf6f5a0203"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2.2.1 控制生成文本随机性和精确性：temperature和top_p"
   ],
   "id": "9805fcdfc618b199"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "温度是控制模型生成文本随机性的关键参数，对模型的输出有最为显著的影响，默认为1：\n",
    "\n",
    "<img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/LingYi/20240827110341.png\"/>\n",
    "\n",
    "- 高温度（接近2.0）：\n",
    "  - 使概率分布更加平滑，减小不同选项之间的概率差异，增加低概率事件被选中的机会\n",
    "  - 产生更多样化、创意性的输出，适合创意写作、头脑风暴等任务\n",
    "  - 更加创意随机一些\n",
    "\n",
    "- 低温度（接近0.0）：\n",
    "\n",
    "  - 使概率分布更加陡峭，放大高概率选项与低概率选项之间的差异，进一步降低低概率事件被选中的可能性        \n",
    "  - 生成更确定、保守的输出，适合事实性回答、分析性任务\n",
    "  - 可能导致重复性较高的内容\n",
    "\n",
    "注意到温度为2的时候，已经不能正常回答了，在1.5左右也很有创造性并且也要更注意正确性。"
   ],
   "id": "a7522743c18dbaaf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T04:00:53.705713Z",
     "start_time": "2024-10-16T04:00:47.454788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": \"往下仿写几句：生活就像一把刀插在我胳肢窝里，有点疼还有点想笑\"}\n",
    "    ],\n",
    "    temperature=0,\n",
    "    n=3\n",
    ")\n",
    "\n",
    "response"
   ],
   "id": "5a398b83130910b3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AIpVIEJYQTr9vHT3D9VFfhxfCrjcX', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='生活就像一只猫在我腿上抓痒，时而温暖时而刺痛。\\n\\n生活就像一场雨落在我心头，既清凉又略显沉重。\\n\\n生活就像一杯咖啡在我手中，苦涩中带着一丝甜。\\n\\n生活就像一首歌在我耳边回荡，旋律悠扬却夹杂着不和谐音符。\\n\\n生活就像一阵风吹过我的脸庞，清新中夹杂着些许沙尘。', refusal=None, role='assistant', function_call=None, tool_calls=None)), Choice(finish_reason='stop', index=1, logprobs=None, message=ChatCompletionMessage(content='生活就像一只猫在我腿上抓痒，时而温暖时而刺痛。\\n\\n生活就像一场雨落在我心头，既清凉又略显沉重。\\n\\n生活就像一杯咖啡在我手中，苦涩中带着一丝甜。\\n\\n生活就像一首歌在我耳边回荡，旋律悠扬却夹杂着不和谐音符。\\n\\n生活就像一阵风吹过我的脸庞，清新中夹杂着些许沙尘。', refusal=None, role='assistant', function_call=None, tool_calls=None)), Choice(finish_reason='stop', index=2, logprobs=None, message=ChatCompletionMessage(content='生活就像一只猫在我腿上抓痒，时而温暖时而刺痛。\\n\\n生活就像一场雨落在我心头，既清凉又略显沉重。\\n\\n生活就像一杯咖啡在我手中，苦涩中带着一丝甜。\\n\\n生活就像一首歌在我耳边回荡，旋律悠扬却夹杂着不和谐音符。\\n\\n生活就像一阵风吹过我的脸庞，清新中夹杂着些许沙尘。', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1729051248, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_a20a4ee344', usage=CompletionUsage(completion_tokens=357, prompt_tokens=37, total_tokens=394, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T06:33:12.197890Z",
     "start_time": "2024-10-16T06:33:10.539569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": \"往下仿写几句：生活就像一把刀插在我胳肢窝里，有点疼还有点想笑\"}\n",
    "    ],\n",
    "    temperature=2,\n",
    "    n=3,\n",
    "    max_tokens=20\n",
    ")\n",
    "\n",
    "response"
   ],
   "id": "aca58578bd104964",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AIrsl0cX46b6vVcuea4fXgec9EJkp', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='这样的感觉，就像准确中靶紧跟着点了个镖帽，一瞬吻', refusal=None, role='assistant', function_call=None, tool_calls=None)), Choice(finish_reason='length', index=1, logprobs=None, message=ChatCompletionMessage(content='命运就如饥汤误劑直接亲靣而セ sぅキャン', refusal=None, role='assistant', function_call=None, tool_calls=None)), Choice(finish_reason='length', index=2, logprobs=None, message=ChatCompletionMessage(content='生活仿佛是一棵揺窍披ボ跑縍珠裡晰ber', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1729060391, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_a20a4ee344', usage=CompletionUsage(completion_tokens=60, prompt_tokens=37, total_tokens=97, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T06:33:46.610150Z",
     "start_time": "2024-10-16T06:33:44.155744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": \"往下仿写几句：生活就像一把刀插在我胳肢窝里，有点疼还有点想笑\"}\n",
    "    ],\n",
    "    temperature=1.5,\n",
    "    n=3,\n",
    "    max_tokens=50\n",
    ")\n",
    "\n",
    "response"
   ],
   "id": "256434bb1295af8d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AIrtJ1L8gWUc6CiQav3cxzJqkyadk', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='生活就像热水忽然从我背上淋下，刺骨又清醒。\\n生活就像一个未拧紧的阀门滴出的水，在不经意间时断时续。\\n生活就像疾', refusal=None, role='assistant', function_call=None, tool_calls=None)), Choice(finish_reason='length', index=1, logprobs=None, message=ChatCompletionMessage(content='生活就像一直诉长幽默的课，每每听完还余荡你的人生六匹，却在那轻浮瞬息里窥的镜面， WangHun蚡了一地， Darren傻抹 handler 만atid 준', refusal=None, role='assistant', function_call=None, tool_calls=None)), Choice(finish_reason='length', index=2, logprobs=None, message=ChatCompletionMessage(content='生活像气温骤降的一晚，手脚冰凉又满目清凉。\\n\\n生命似在深夜飙船，没刹车装置却满怀冒险的激动。\\n\\n日子是空香德广', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1729060425, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_a20a4ee344', usage=CompletionUsage(completion_tokens=150, prompt_tokens=37, total_tokens=187, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "**Top_p（核采样）**\n",
    "\n",
    "top-p作用与temperature相似，用于控制模型输出文本的随机性，数值越接近于1，模型输出文本随机性越强；反之，数值越接近于0，模型输出文本随机性越弱。该参数取值范围为[0,1]，默认值为1\n",
    "Top_p，也称为核采样，是挑选评分（概率）加起来达到 p的最小集合作为候选集，然后从中随机选一个作为下一个输出的字：\n",
    "\n",
    "\n",
    "<img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/LingYi/20240827112522.png\" alt=\"Image\" width=\"1000\"/>\n",
    "\n",
    "\n",
    "- 取值范围为0到1，通常设置为较高的值，比如0.75，这样可以过滤掉那些低评分的长尾。\n",
    "- 模型计算所有可能的下一个词的累积概率分布\n",
    "- 当累积概率达到top_p值时，模型只从这些词中选择\n",
    "\n",
    "例如，如果top_p设为0.9，模型只会考虑累积概率达到90%的词，忽略剩下的低概率词。\n",
    "\n",
    "更具体的例子，如果排序概率为“[0.5, 0.2, 0.1, 0.1, 0.05, 0.05]”，则“0.8”的“top_p”将采样为“[0.625, 0.25, 0.125, 0, 0, 0]”。"
   ],
   "id": "aab722f03c28c590"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T06:41:01.706552Z",
     "start_time": "2024-10-16T06:40:57.912803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": \"往下仿写几句：打扰大家一下，今天不是我生日，纯打扰\"}\n",
    "    ],\n",
    "    top_p=0,\n",
    "    n=3\n",
    ")\n",
    "\n",
    "response"
   ],
   "id": "ee45d349e0cc19f3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AIs0IBifmuOq9VZevvqC4GRkP39v1', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='当然可以，以下是一些类似的句子：\\n\\n1. 抱歉打扰各位，其实我没有什么重要的事情，只是想说声嗨。\\n2. 各位不好意思，我今天没有特别的消息，只是想刷一下存在感。\\n3. 打扰一下大家，其实我没有什么特别的理由，只是想看看大家在忙什么。\\n4. 抱歉占用大家的时间，我只是想随便聊聊，没有特别的事情。\\n5. 各位朋友，不好意思打扰了，我只是想发个消息，看看有没有人在线。', refusal=None, role='assistant', function_call=None, tool_calls=None)), Choice(finish_reason='stop', index=1, logprobs=None, message=ChatCompletionMessage(content='当然可以，以下是一些类似的句子：\\n\\n1. 抱歉打扰各位，其实我没有什么重要的事情，只是想说声嗨。\\n2. 各位不好意思，我今天没有特别的消息，只是想刷一下存在感。\\n3. 打扰一下大家，其实我没有什么特别的理由，只是想看看大家在忙什么。\\n4. 抱歉占用大家的时间，我只是想随便聊聊，没有特别的事情。\\n5. 各位朋友，不好意思打扰了，我只是想发个消息，看看有没有人在线。', refusal=None, role='assistant', function_call=None, tool_calls=None)), Choice(finish_reason='stop', index=2, logprobs=None, message=ChatCompletionMessage(content='当然可以，以下是一些类似的句子：\\n\\n1. 抱歉打扰各位，其实我没有什么重要的事情，只是想说声嗨。\\n2. 各位不好意思，我今天没有特别的消息，只是想刷一下存在感。\\n3. 打扰一下大家，其实我没有什么特别的理由，只是想看看大家在忙什么。\\n4. 抱歉占用大家的时间，我只是想随便聊聊，没有特别的事情。\\n5. 各位朋友，不好意思打扰了，我只是想发个消息，看看有没有人在线。', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1729060858, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_a20a4ee344', usage=CompletionUsage(completion_tokens=378, prompt_tokens=28, total_tokens=406, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T06:41:04.877257Z",
     "start_time": "2024-10-16T06:41:02.122312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": \"往下仿写几句：打扰大家一下，今天不是我生日，纯打扰\"}\n",
    "    ],\n",
    "    top_p=1,\n",
    "    n=3\n",
    ")\n",
    "\n",
    "response"
   ],
   "id": "4a8e35b380d57404",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-AIs0MftpsUscL7SOGUIPuwlxqL3u6', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='打扰大家一下，今天也不是我领工资的日子，纯属路过。\\n\\n打扰大家一下，今天不发红包，纯粹打扰。\\n\\n打扰大家一下，今天我不请客吃饭，只是来凑热闹的。\\n\\n打扰大家一下，今天没有特别的事，就是想打个招呼。', refusal=None, role='assistant', function_call=None, tool_calls=None)), Choice(finish_reason='stop', index=1, logprobs=None, message=ChatCompletionMessage(content='打扰大家一下，今天不是我结婚纪念日，纯粹想说个嗨。\\n\\n打扰大家一下，今天没有特别的节日，就是想刷个存在感。\\n\\n打扰大家一下，今天没有要分享的新闻，只是想聊聊天。\\n\\n打扰大家一下，今天没什么大事，只是来祝大家生活愉快。', refusal=None, role='assistant', function_call=None, tool_calls=None)), Choice(finish_reason='stop', index=2, logprobs=None, message=ChatCompletionMessage(content='打扰大家一下，今天没有重要消息，纯粹路过。\\n\\n打扰大家一下，今天没带礼物，纯属过来看热闹。\\n\\n打扰大家一下，今天不发红包，只是来凑个数。\\n\\n打扰大家一下，这次没有惊喜，就是想和大家聊聊天。', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1729060862, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_6b68a8204b', usage=CompletionUsage(completion_tokens=221, prompt_tokens=28, total_tokens=249, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0)))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "需要注意的是，在调整top_p参数和temperature参数时只调整其中一个，不要同时调整两者，避免影响最后文本生成的效果。"
   ],
   "id": "502dae0c5cb56202"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.2.4 随机数种子：seed",
   "id": "a25267616f40a2ef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "随机数种子。如果设定了随机数种子，OpenAI系统将尽最大努力保证使用相同的随机数种子和参数进行的重复请求返回相同的结果。但是不能保证完全的确定性\n",
    "\n",
    "即当需要结果可预测和重复结果时可启动这个参数。使用说明：\n",
    "\n",
    "1. 将 seed 参数设置为您选择的任何整数，并在您希望获得确定性输出的请求中使用相同的值。\n",
    "2. 确保所有其他参数（如 prompt 或 temperature）在请求中完全相同。\n",
    "\n",
    "如果 seed、请求参数和 system_fingerprint 在您的请求中都匹配，那么模型输出将大致相同。即使三者匹配，响应也有小概率会不同，这由于我们模型的固有非确定性。"
   ],
   "id": "90dd4fe55ae71c24"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T11:39:39.945555Z",
     "start_time": "2024-10-17T11:39:38.114304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 尝试多次运行\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": \"写2句关于小猫和秋天的儿歌\"}\n",
    "    ],\n",
    "    seed=0,\n",
    ")\n",
    "print(response.system_fingerprint)\n",
    "for choice in response.choices:\n",
    "    print(choice.message.content)\n",
    "    print(\"****\"*10)\n",
    "    "
   ],
   "id": "b0a957d84db20d18",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp_a20a4ee344\n",
      "小猫秋游穿金衣，枫叶飘舞迎风嬉。  \n",
      "阳光洒暖林间路，趣追落叶乐无比。\n",
      "****************************************\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T11:40:34.258340Z",
     "start_time": "2024-10-17T11:40:32.396110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 尝试多次运行\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": \"写2句关于小猫和秋天的儿歌\"}\n",
    "    ],\n",
    "    seed=0,\n",
    "    temperature=1.5\n",
    ")\n",
    "print(response.system_fingerprint)\n",
    "for choice in response.choices:\n",
    "    print(choice.message.content)\n",
    "    print(\"****\"*10)"
   ],
   "id": "6a9b9016c33f43a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp_a20a4ee344\n",
      "在金色秋天，落叶轻飘飘，小猫在草地上嬉戏真美妙。\n",
      "\n",
      "树梢上，苹果红艳艳，微风飘过，小猫追逐彩虹的梦幻。\n",
      "****************************************\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> 让大模型两次输出的结果保持一致，几乎是不可能的！<br>\n",
    "> 目前市面上没有一个大模型能够确保这一点<br>\n",
    "> 但是！！！OpenAI就是这么强， 它竟然敢开放随机数种子这个参数！<br>"
   ],
   "id": "6753335a9a170643"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2.2.5 模型生成文本停止条件：stop",
   "id": "385fae8e2186dbd1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "stop参数用于指定API在生成文本时停止的条件。默认是空值，如果提供了值，API将在生成的文本中找到与之匹配的最多4个序列，并在匹配到这些序列后停止生成更多的内容。\n",
    "\n",
    "- 格式控制: 如之前提到的例子,可以使用stop sequences来确保输出符合特定的格式,比如XML或JSON标签。\n",
    "- 内容限制: 可以使用stop来防止模型生成某些特定的内容或词语。可以保护信息安全等。\n",
    "- 输出长度控制: 除了使用max_tokens参数,还可以使用stop来在特定条件下结束输出。"
   ],
   "id": "648c0b24ba17d1f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. 你在周末通常会做些什么？\\n2. 你的家乡有什么有趣的传统活动吗？\\n3. 在你的家人中，谁是你最亲密的关系？\\n4. 最近你有没有尝试过一些新的食物或美食？\\n5. 你认为家庭在一个人的成长中有多重要？\\n6. 你对未来有什么计划或梦想？\\n7. 最近你是否看过一部特别感动或有启发的电影？\\n8. 你觉得音乐对你的生活有什么影响吗？\\n9. 你认为教育对一个人的成功有多大的帮助？\\n10. 你最喜欢的季节是哪个？为什么？'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 85,
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": \"请帮我写10个问句\"}\n",
    "    ],\n",
    "    # stop=\"？\"\n",
    ")\n",
    "\n",
    "response.choices[0].message.content"
   ],
   "id": "6f8861388c698df7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. 你今天过得怎么样'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 84,
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": \"请帮我写10个问句\"}\n",
    "    ],\n",
    "    stop=\"？\"\n",
    ")\n",
    "\n",
    "response.choices[0].message.content"
   ],
   "id": "27a583af8a0a8297"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f38bff7620356776"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T07:47:27.532880Z",
     "start_time": "2024-10-16T07:47:23.442720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = \"你好帮我列出一个冷知识，将回答用<answer></answer>标签包围。\"\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "      {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    stop=\"</answer>\"\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ],
   "id": "5a833f9a18974de3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<answer>考拉并不是喝大量水的动物。事实上，它们的大部分水分都来自于它们吃的桉树叶。这个名字中“考拉”在澳大利亚土著语言中意为“无水”，反映了它们对水源的低需求。\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 2.2.6 控制模型生成文本的新颖性和多样性：frequency_penalty和presence_penalty"
   ],
   "id": "830db653330a66e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "频率惩罚(Frequency Penalty)和存在惩罚(Presence Penalty):\n",
    "\n",
    "这两种方法都是为了**让生成的文本更加多样化**,但是实现的方式略有不同。频率惩罚更关注减少重复,而存在惩罚更关注引入新的词汇。\n",
    "\n",
    "1. 频率惩罚(Frequency Penalty):\n",
    "   - 目的是减少重复使用相同的词。\n",
    "   - 每次使用一个词,该词的分数就会降低。\n",
    "   - 使用次数越多,降低的分数就越多。\n",
    "   - 举例:如果\"苹果\"这个词被使用了3次,它的分数可能会降低0.6分。\n",
    "\n",
    "2. 存在惩罚(Presence Penalty):\n",
    "   - 目的是鼓励使用更多不同的词。\n",
    "   - 一个词只要出现过一次,就会降低它的分数。\n",
    "   - 不管使用多少次,只降低一次固定的分数。\n",
    "   - 举例:如果\"苹果\"这个词出现过,它的分数可能会降低0.2分,不管用了几次。\n",
    "\n",
    "简单来说:\n",
    "- 频率惩罚会随着一个词重复使用的次数增加而增加惩罚。\n",
    "- 存在惩罚只在一个词首次出现时给予一次性的惩罚。\n",
    "\n"
   ],
   "id": "d470ade34a04631d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T09:25:59.663339Z",
     "start_time": "2024-10-16T09:25:57.087789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "prompt = \"\"\"用中文表述这句话：The big dog saw the big cat and made a big noise.The big bird flew over the big tree and dropped a big leaf.\n",
    "A big wave hit the big rock, causing a big splash.\n",
    "The big bear chased the big rabbit across a big field.\n",
    "The big truck rolled down the big hill with a big rumble.\n",
    "The big elephant stomped through the big forest, leaving a big trail.\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    frequency_penalty=2,\n",
    ")\n",
    "for choice in response.choices:\n",
    "    print(choice.message.content)\n",
    "    print(\"****\" * 10)"
   ],
   "id": "6b2a53d938f6bb10",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大狗看到了大猫，并且发出了很大的响声。大鸟飞过大树，落下了一片巨大的叶子。一阵巨浪拍打着巨石，溅起了大片水花。 大熊在宽广的田野上追赶着一只硕大的兔子。 一辆大型卡车轰隆隆地滚下陡峭的山坡。 巨象踏过茂密的森林，留下了一条显眼的大路迹。\n",
      "\n",
      "****************************************\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T16:27:14.771439Z",
     "start_time": "2024-10-16T16:27:10.030344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = \"\"\"用中文表述这句话：The big dog saw the big cat and made a big noise.The big bird flew over the big tree and dropped a big leaf.\n",
    "A big wave hit the big rock, causing a big splash.\n",
    "The big bear chased the big rabbit across a big field.\n",
    "The big truck rolled down the big hill with a big rumble.\n",
    "The big elephant stomped through the big forest, leaving a big trail.\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    frequency_penalty= 0,\n",
    ")\n",
    "for choice in response.choices:\n",
    "    print(choice.message.content)\n",
    "    print(\"****\" * 10)"
   ],
   "id": "e489e18bf6b51177",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大狗看到了大猫，发出了很大的噪音。大鸟飞过大树，掉下了一片大树叶。大浪拍打着大岩石，溅起了很大的水花。大熊追逐着大兔子穿过大田野。大卡车隆隆作响地滚下大山坡。大象踏过大森林，留下了一条大路。\n",
      "****************************************\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### ※ 参数列表概览"
   ],
   "id": "cca9f0e32af62b37"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "剩下的参数见下方的参数列表，里面包含了详细的参数名称、参数详解以及重要程度。其中与模型调用和功能相关的参数tools和tool_choice非常重要，后续我们讲解function calling/tool_use功能时再给大家详细讲解这两个参数的含义及使用方法。",
   "id": "2db97aea379a9a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. **核心参数/必须参数**\n",
    "   - 这些参数是每次调用API时必不可少的，确保请求能够正确地识别使用的模型和当前对话的内容。\n",
    "   - **`model`**：指定使用的模型ID，决定了生成文本的能力和特性。\n",
    "   - **`messages`**：包含对话中所有消息的列表，是生成响应的基础。\n",
    "\n",
    "2. **文本生成过程中的控制参数**\n",
    "   - 这些参数允许用户精细控制生成文本的行为，控制文本的创意性、一致性和长度，以满足特定需求。\n",
    "   - **`frequency_penalty`** 和 **`presence_penalty`**：防止模型重复内容或鼓励引入新话题。\n",
    "   - **`temperature`** 和 **`top_p`**：调节生成文本的随机性和多样性。\n",
    "   - **`stop`**：定义生成过程的终止条件。\n",
    "   - **`n`**：指定生成多个不同的响应选项。\n",
    "   - **`max_completion_tokens`** 和 **`max_tokens`**：限制生成文本的长度。（`max_tokens` 已准备弃用）\n",
    "   - **`seed`**：尝试实现生成结果的可重复性。\n",
    "   - **`logit_bias`**、**`logprobs`** 和 **`top_logprobs`**：细粒度控制特定词汇的生成概率。\n",
    "\n",
    "3. **生成文本的方式和输出格式**\n",
    "   - 这些参数决定了文本生成的技术方式（如是否流式传输）和输出格式（如JSON结构）。\n",
    "   - **`response_format`**：定义生成文本的结构化格式。\n",
    "   - **`stream`** 和 **`stream_options`**：控制是否以流式方式接收生成的文本，适用于实时应用。\n",
    "\n",
    "4. **与模型调用和功能相关的参数**\n",
    "   - 这些参数用于配置高级功能，如选择不同的服务层级、调用外部工具或函数，以及管理请求的存储和元数据。\n",
    "   - **`service_tier`**：选择不同的服务级别以优化延迟和可用性。\n",
    "   - **`tools`**、**`tool_choice`** 和 **`parallel_tool_calls`**：配置模型可以调用的外部工具或函数，增强功能性。\n",
    "   - **`store`** 和 **`metadata`**：管理请求结果的存储与分类，便于后续分析和监控。\n",
    "   - **`function_call`** 和 **`functions`**（已弃用）：旧版参数，用于控制函数调用，现已被`tools`取代。\n",
    "\n",
    "5. **与用户相关的参数**\n",
    "   - 这些参数用于识别和跟踪最终用户，帮助系统进行用户行为分析和防止滥用。\n",
    "   - **`user`**：提供一个唯一标识符以代表最终用户，增强安全性和监控能力。"
   ],
   "id": "83e4f7fa369fdebf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
