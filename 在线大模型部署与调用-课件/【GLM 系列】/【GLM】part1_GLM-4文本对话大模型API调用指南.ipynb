{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cf30096",
   "metadata": {},
   "source": [
    "# 在线大模型GLM-4本地调用方法\n",
    "\n",
    "## GLM-4 API获取及文本对话指南\n",
    "\n",
    "作为一个经常和大模型应用开发，大模型API调用打交道的老司机,我觉得GLM-4是个挺不错的选择,特别适合刚入门的朋友。比如它的新用户注册免费送的token，免费调用的glm-4-flash大模型和国内顶尖的地位。\n",
    "\n",
    "GLM-4现在出了好几个版本,都挺强的:\n",
    "- glm-4-plus: 功能最全面的版本 （推荐）\n",
    "- glm-4-flash: 速度特别快 （免费）\n",
    "\n",
    "\n",
    "说到API,其实背后就是个网络请求，比如我们要学的文本API就是这个url:\n",
    "```python\n",
    "https://open.bigmodel.cn/api/paas/v4/chat/completions\n",
    "```\n",
    "就像是咱们和AI聊天的传话筒。你把问题发过去,GLM-4就会给你返回答案，所以我们不需要在自己电脑上装上大模型,调用API就可以。\n",
    "\n",
    "## 怎么调用API?\n",
    "其实就一个函数就够了: `chat.completions.create`\n",
    "因为网址的写法在开发时不太方便，所以大模型公司会帮助我们包装好python语言的sdk，对于我们使用函数，传入我们的prompt和model就可以了。\n",
    "接下来我给大家演示下具体怎么用,保证让你3分钟上手~\n",
    "\n",
    "**安装智谱AI的库（工具包）**"
   ]
  },
  {
   "cell_type": "code",
   "id": "ae72a6d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T04:01:34.430400Z",
     "start_time": "2024-11-11T04:01:27.556254Z"
    }
   },
   "source": [
    "!pip install zhipuai"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting zhipuai\n",
      "  Obtaining dependency information for zhipuai from https://files.pythonhosted.org/packages/10/28/5c1efbfb560e64458b22e0442279af8bde673edcb096762a3aeccee3a8ec/zhipuai-2.1.5.20230904-py3-none-any.whl.metadata\n",
      "  Downloading zhipuai-2.1.5.20230904-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting cachetools>=4.2.2 (from zhipuai)\n",
      "  Obtaining dependency information for cachetools>=4.2.2 from https://files.pythonhosted.org/packages/a4/07/14f8ad37f2d12a5ce41206c21820d8cb6561b728e51fad4530dff0552a67/cachetools-5.5.0-py3-none-any.whl.metadata\n",
      "  Using cached cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting httpx>=0.23.0 (from zhipuai)\n",
      "  Obtaining dependency information for httpx>=0.23.0 from https://files.pythonhosted.org/packages/56/95/9377bcb415797e44274b51d46e3249eba641711cf3348050f76ee7b15ffc/httpx-0.27.2-py3-none-any.whl.metadata\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pydantic<3.0,>=1.9.0 (from zhipuai)\n",
      "  Obtaining dependency information for pydantic<3.0,>=1.9.0 from https://files.pythonhosted.org/packages/df/e4/ba44652d562cbf0bf320e0f3810206149c8a4e99cdbf66da82e97ab53a15/pydantic-2.9.2-py3-none-any.whl.metadata\n",
      "  Using cached pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Collecting pydantic-core>=2.14.6 (from zhipuai)\n",
      "  Obtaining dependency information for pydantic-core>=2.14.6 from https://files.pythonhosted.org/packages/cc/c3/7edc270ac44b6d16918de608e42209fef24414bfa310f9ada27d9fc8b73d/pydantic_core-2.26.0-cp310-none-win_amd64.whl.metadata\n",
      "  Downloading pydantic_core-2.26.0-cp310-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting pyjwt<2.9.0,>=2.8.0 (from zhipuai)\n",
      "  Obtaining dependency information for pyjwt<2.9.0,>=2.8.0 from https://files.pythonhosted.org/packages/2b/4f/e04a8067c7c96c364cef7ef73906504e2f40d690811c021e1a1901473a19/PyJWT-2.8.0-py3-none-any.whl.metadata\n",
      "  Downloading PyJWT-2.8.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting anyio (from httpx>=0.23.0->zhipuai)\n",
      "  Obtaining dependency information for anyio from https://files.pythonhosted.org/packages/e4/f5/f2b75d2fc6f1a260f340f0e7c6a060f4dd2961cc16884ed851b0d18da06a/anyio-4.6.2.post1-py3-none-any.whl.metadata\n",
      "  Using cached anyio-4.6.2.post1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting certifi (from httpx>=0.23.0->zhipuai)\n",
      "  Obtaining dependency information for certifi from https://files.pythonhosted.org/packages/12/90/3c9ff0512038035f59d279fddeb79f5f1eccd8859f06d6163c58798b9487/certifi-2024.8.30-py3-none-any.whl.metadata\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.23.0->zhipuai)\n",
      "  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/06/89/b161908e2f51be56568184aeb4a880fd287178d176fd1c860d2217f41106/httpcore-1.0.6-py3-none-any.whl.metadata\n",
      "  Using cached httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx>=0.23.0->zhipuai)\n",
      "  Obtaining dependency information for idna from https://files.pythonhosted.org/packages/76/c6/c88e154df9c4e1a2a66ccf0005a88dfb2650c1dffb6f5ce603dfbd452ce3/idna-3.10-py3-none-any.whl.metadata\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sniffio (from httpx>=0.23.0->zhipuai)\n",
      "  Obtaining dependency information for sniffio from https://files.pythonhosted.org/packages/e9/44/75a9c9421471a6c4805dbf2356f7c181a29c1879239abab1ea2cc8f38b40/sniffio-1.3.1-py3-none-any.whl.metadata\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.23.0->zhipuai)\n",
      "  Obtaining dependency information for h11<0.15,>=0.13 from https://files.pythonhosted.org/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl.metadata\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0,>=1.9.0->zhipuai)\n",
      "  Obtaining dependency information for annotated-types>=0.6.0 from https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl.metadata\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core>=2.14.6 (from zhipuai)\n",
      "  Obtaining dependency information for pydantic-core>=2.14.6 from https://files.pythonhosted.org/packages/de/81/7dfe464eca78d76d31dd661b04b5f2036ec72ea8848dd87ab7375e185c23/pydantic_core-2.23.4-cp310-none-win_amd64.whl.metadata\n",
      "  Using cached pydantic_core-2.23.4-cp310-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting typing-extensions>=4.6.1 (from pydantic<3.0,>=1.9.0->zhipuai)\n",
      "  Obtaining dependency information for typing-extensions>=4.6.1 from https://files.pythonhosted.org/packages/26/9f/ad63fc0248c5379346306f8668cda6e2e2e9c95e01216d2b8ffd9ff037d0/typing_extensions-4.12.2-py3-none-any.whl.metadata\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting exceptiongroup>=1.0.2 (from anyio->httpx>=0.23.0->zhipuai)\n",
      "  Obtaining dependency information for exceptiongroup>=1.0.2 from https://files.pythonhosted.org/packages/02/cc/b7e31358aac6ed1ef2bb790a9746ac2c69bcb3c8588b41616914eb106eaf/exceptiongroup-1.2.2-py3-none-any.whl.metadata\n",
      "  Using cached exceptiongroup-1.2.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "Downloading zhipuai-2.1.5.20230904-py3-none-any.whl (104 kB)\n",
      "   ---------------------------------------- 0.0/105.0 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/105.0 kB ? eta -:--:--\n",
      "   --------------- ----------------------- 41.0/105.0 kB 495.5 kB/s eta 0:00:01\n",
      "   --------------- ----------------------- 41.0/105.0 kB 495.5 kB/s eta 0:00:01\n",
      "   ---------------------- ---------------- 61.4/105.0 kB 365.7 kB/s eta 0:00:01\n",
      "   ---------------------- ---------------- 61.4/105.0 kB 365.7 kB/s eta 0:00:01\n",
      "   ---------------------- ---------------- 61.4/105.0 kB 365.7 kB/s eta 0:00:01\n",
      "   ---------------------- ---------------- 61.4/105.0 kB 365.7 kB/s eta 0:00:01\n",
      "   ---------------------- ---------------- 61.4/105.0 kB 365.7 kB/s eta 0:00:01\n",
      "   ---------------------- ---------------- 61.4/105.0 kB 365.7 kB/s eta 0:00:01\n",
      "   -------------------------------------  102.4/105.0 kB 210.9 kB/s eta 0:00:01\n",
      "   -------------------------------------- 105.0/105.0 kB 209.1 kB/s eta 0:00:00\n",
      "Using cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Using cached httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Using cached pydantic_core-2.23.4-cp310-none-win_amd64.whl (1.9 MB)\n",
      "Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached anyio-4.6.2.post1-py3-none-any.whl (90 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Using cached exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: typing-extensions, sniffio, pyjwt, idna, h11, exceptiongroup, certifi, cachetools, annotated-types, pydantic-core, httpcore, anyio, pydantic, httpx, zhipuai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.6.2.post1 cachetools-5.5.0 certifi-2024.8.30 exceptiongroup-1.2.2 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 idna-3.10 pydantic-2.9.2 pydantic-core-2.23.4 pyjwt-2.8.0 sniffio-1.3.1 typing-extensions-4.12.2 zhipuai-2.1.5.20230904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "23cd65a7",
   "metadata": {},
   "source": [
    "### 1.**chat.completions.create函数使用示例与`response`回应解析**\n",
    "\n",
    "接下来，我们尝试调用Chat Completions API。通过一个极简示例来了解文本API的调用方式、参数设置和响应内容。\n",
    "\n",
    "想要调用它，我们需要有API Key。通过API Key认证的`client`就和我们的账户挂钩了，同时也建立了调用智谱AI的桥梁，`ZhipuAI`实例`client`就能关联到我们的账户。在这里，我们可以将它理解为与我们自己绑定的独有助手。"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![](https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/LingYi/20241111144434.png)",
   "id": "5ac641209e5433be"
  },
  {
   "cell_type": "code",
   "id": "18d1d05f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T09:42:38.721660Z",
     "start_time": "2024-11-15T09:42:38.276961Z"
    }
   },
   "source": [
    "from zhipuai import ZhipuAI\n",
    "# 请填写您自己的API Key\n",
    "# client = ZhipuAI(api_key=\"your_api_key_here\")\n",
    "client = ZhipuAI()"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "c7f1e648",
   "metadata": {},
   "source": [
    "有了独特的契约助手（由我们的API Key认证）后，如果我们想要向大模型发起问话，需要提供哪些必要的信息呢？\n",
    "\n",
    "1. **使用哪个模型**  \n",
    "2. **我们的问题是什么**\n",
    "\n",
    "即这个函数中有两个必须参数：`model`和`messages`。\n",
    "\n",
    "- **`model`**：指定调用的模型（这里调用的是`glm-4`模型）。\n",
    "- **`messages`**：一个由字典构成的列表，其中每个字典（每条消息）包含两个键：\n",
    "  - **`role`**：表示消息的发送者。可以有不同的值，包括`user`、`system`、`assistant`、`tool`。\n",
    "  - **`content`**：实际的消息内容。"
   ]
  },
  {
   "cell_type": "code",
   "id": "a6eea25b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T12:44:53.798173Z",
     "start_time": "2024-11-14T12:44:37.350168Z"
    }
   },
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"glm-4-plus\",\n",
    "  messages=[\n",
    "      {\"role\": \"user\", \"content\": \"请举几个罗马帝国的趣事\"}\n",
    "  ]\n",
    ")\n",
    "response"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion(model='glm-4-plus', created=1731588294, choices=[CompletionChoice(index=0, finish_reason='stop', message=CompletionMessage(content=\"罗马帝国作为古代世界最强大的帝国之一，不仅有着丰富的历史和文化，也有一些有趣的轶事和传说。以下是几个关于罗马帝国的趣事：\\n\\n### 1. 罗马皇帝卡里古拉的宠物马\\n卡里古拉（Caligula）是罗马帝国的一位著名暴君，他有许多荒唐的行为。其中最著名的是他把自己的爱马“因西塔图斯”（Incitatus）提拔为执政官，并给予它豪华的马厩和仆人。据说这匹马还有自己的宫殿和宝石装饰。\\n\\n### 2. 罗马斗兽场的开幕式\\n公元80年，罗马斗兽场（科洛塞姆）落成时，举行了为期100天的盛大开幕式。据记载，在这期间，有9000头野兽和2000名角斗士在斗兽场中进行激烈的战斗，场面极为壮观。\\n\\n### 3. 罗马皇帝的“面包与 circuses”\\n罗马帝国有一句著名的谚语“面包与 circuses”（拉丁语：panem et circenses），意指通过提供免费的面包和娱乐（如角斗士比赛、马车比赛等）来安抚民众。这是罗马统治者用来维持社会稳定的一种手段。\\n\\n### 4. 罗马皇帝哈德良的“完美之城”\\n哈德良（Hadrian）是罗马帝国的一位有远见的皇帝，他不仅是一位出色的军事家，还是一位建筑师。他下令建造了著名的哈德良长城（Hadrian's Wall）来防御北方的蛮族，同时还设计了一座理想化的城市——哈德良别墅（Villa Adriana），这座别墅集合了当时世界上最先进的建筑和艺术。\\n\\n### 5. 罗马帝国的“厕所文化”\\n罗马帝国的公共厕所非常发达，被称为“foricae”。这些厕所通常是多座位的，且没有隔板，人们在如厕时可以互相交谈。有趣的是，罗马人认为在厕所里讨论政治和商业事务是一种时尚。\\n\\n### 6. 罗马帝国的“葡萄酒浴”\\n罗马帝国的富人们喜欢享受奢华的生活方式，其中一种奇特的做法是用葡萄酒洗澡。据说葡萄酒中的抗氧化剂对皮肤有好处，但这种奢侈的行为也显示了罗马富人的极度浪费。\\n\\n### 7. 罗马帝国的“交通堵塞”\\n尽管古代罗马没有现代的汽车，但作为一座大都市，罗马城的交通问题也非常严重。狭窄的街道上常常挤满了行人、马车和商贩，导致严重的交通堵塞。为了缓解这一问题，罗马皇帝奥古斯都曾下令限制马车在白天进入城市中心。\\n\\n这些趣事不仅展示了罗马帝国的繁荣和奢华，也揭示了当时社会的某些奇特风俗和统治者的荒唐行为。\", role='assistant', tool_calls=None))], request_id='202411142044386d83b8dcafd74cad', id='202411142044386d83b8dcafd74cad', usage=CompletionUsage(prompt_tokens=13, completion_tokens=571, total_tokens=584))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "70822330",
   "metadata": {},
   "source": [
    "大模型推理生成的结果直接由`create`函数返回，被我们存进了`response`中。"
   ]
  },
  {
   "cell_type": "code",
   "id": "10130c9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T06:55:16.211465Z",
     "start_time": "2024-11-11T06:55:16.196465Z"
    }
   },
   "source": [
    "response"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Completion(model='glm-4-plus', created=1731308112, choices=[CompletionChoice(index=0, finish_reason='stop', message=CompletionMessage(content='罗马帝国，这个古老而辉煌的文明，留下了无数令人着迷的故事和趣事。以下是几个有趣的例子：\\n\\n1. **罗马斗兽场的“速食”文化**：\\n   罗马斗兽场不仅是角斗士们激烈搏斗的场所，也是古罗马人享受“速食”的地方。观众们在观看比赛的同时，会购买各种小吃，如烤肉、面包和水果。有趣的是，他们会在座位上留下食物残渣，而这些残渣后来被考古学家发现，为我们提供了了解古罗马饮食文化的线索。\\n\\n2. **皇帝卡里古拉的“马匹封官”**：\\n   罗马皇帝卡里古拉以其荒诞行为而闻名。他曾将自己的爱马“英西塔土斯”封为执政官，并为其配备豪华的马厩和仆人。这一荒唐举动不仅引起了朝臣的震惊，也成为了后世流传的笑谈。\\n\\n3. **罗马人的“厕所社交”**：\\n   在古罗马，公共厕所是社交的场所。人们在这里不仅解决生理需求，还聊天、交换新闻和讨论政治。这些厕所通常设有多个座位，且没有隔板，使得人们在如厕时能够轻松交流。\\n\\n4. **尼禄皇帝的“音乐梦”**：\\n   尼禄皇帝热爱音乐和表演，他曾亲自在舞台上演唱，并禁止观众中途离场。据说，他在演唱时还会让卫兵用武器威胁观众，以确保他们认真聆听。尼禄甚至还参加过奥林匹克运动会的歌唱比赛，并获得了所有奖项。\\n\\n5. **罗马人的“沐浴文化”**：\\n   罗马人非常重视沐浴，公共浴场不仅是清洁身体的地方，也是社交和娱乐的场所。人们在浴场内进行各种活动，如聊天、下棋、锻炼和享受按摩。有趣的是，罗马浴场的规模之大，有些甚至能容纳数千人同时沐浴。\\n\\n6. **图拉真市场的“快递服务”**：\\n   图拉真市场是古罗马最大的购物中心，这里不仅有各种商店，还提供类似现代快递的服务。顾客购买商品后，可以选择将其直接送到家中，这一服务在当时非常先进和便捷。\\n\\n这些趣事不仅展示了古罗马帝国的独特文化和社会风貌，也让我们对这个古老文明有了更加生动和全面的了解。', role='assistant', tool_calls=None))], request_id='20241111145453ebe4e4e127434570', id='20241111145453ebe4e4e127434570', usage=CompletionUsage(prompt_tokens=13, completion_tokens=483, total_tokens=496))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "995d1805",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T06:55:20.698598Z",
     "start_time": "2024-11-11T06:55:20.692592Z"
    }
   },
   "source": [
    "# 查看返回对象类型\n",
    "type(response)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "zhipuai.types.chat.chat_completion.Completion"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "62ae1a15",
   "metadata": {},
   "source": "模型返回对象是一个对象。若想提取`response`中具体返回的内容，可以直接通过对象的属性："
  },
  {
   "cell_type": "code",
   "id": "d964d95d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T06:55:32.206808Z",
     "start_time": "2024-11-11T06:55:32.189811Z"
    }
   },
   "source": [
    "response.id\n",
    "# 代表这次请求的唯一标识符。"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20241111145453ebe4e4e127434570'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "0e272432",
   "metadata": {},
   "source": [
    "API调用中计费的单位是token：\n",
    "\n",
    "- **什么是token**\n",
    "  - 在大语言模型中，**token**是文本的基本单位。模型不是直接处理原始文本，而是将文本切分成一系列token进行处理，最后将token映射成数字。token可以是单词、子词或者单个字符，具体取决于模型使用的分词方法。\n",
    "\n",
    "可以在返回结果的`usage`中查看本次对话所占用的token数量。具体含义如下：\n",
    "- **`completion_tokens`**：表示生成的回答的token数量。\n",
    "- **`prompt_tokens`**：表示输入给模型的prompt占用的token数量（这里指的是“请举几个罗马帝国的趣事”这句话的token数）。\n",
    "- **`total_tokens`**：表示本次对话总共占用的token数量，是输入和输出token之和。"
   ]
  },
  {
   "cell_type": "code",
   "id": "b9f6f916",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T11:58:31.391456Z",
     "start_time": "2024-11-14T11:58:31.381456Z"
    }
   },
   "source": "response.usage",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(prompt_tokens=13, completion_tokens=534, total_tokens=547)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T11:58:26.049145Z",
     "start_time": "2024-11-14T11:58:25.868551Z"
    }
   },
   "cell_type": "code",
   "source": "response.usage.total_tokens",
   "id": "729026bf22bd5757",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "547"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "786311ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T06:59:07.530117Z",
     "start_time": "2024-11-11T06:59:07.514116Z"
    }
   },
   "source": "response.choices",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CompletionChoice(index=0, finish_reason='stop', message=CompletionMessage(content='罗马帝国，这个古老而辉煌的文明，留下了无数令人着迷的故事和趣事。以下是几个有趣的例子：\\n\\n1. **罗马斗兽场的“速食”文化**：\\n   罗马斗兽场不仅是角斗士们激烈搏斗的场所，也是古罗马人享受“速食”的地方。观众们在观看比赛的同时，会购买各种小吃，如烤肉、面包和水果。有趣的是，他们会在座位上留下食物残渣，而这些残渣后来被考古学家发现，为我们提供了了解古罗马饮食文化的线索。\\n\\n2. **皇帝卡里古拉的“马匹封官”**：\\n   罗马皇帝卡里古拉以其荒诞行为而闻名。他曾将自己的爱马“英西塔土斯”封为执政官，并为其配备豪华的马厩和仆人。这一荒唐举动不仅引起了朝臣的震惊，也成为了后世流传的笑谈。\\n\\n3. **罗马人的“厕所社交”**：\\n   在古罗马，公共厕所是社交的场所。人们在这里不仅解决生理需求，还聊天、交换新闻和讨论政治。这些厕所通常设有多个座位，且没有隔板，使得人们在如厕时能够轻松交流。\\n\\n4. **尼禄皇帝的“音乐梦”**：\\n   尼禄皇帝热爱音乐和表演，他曾亲自在舞台上演唱，并禁止观众中途离场。据说，他在演唱时还会让卫兵用武器威胁观众，以确保他们认真聆听。尼禄甚至还参加过奥林匹克运动会的歌唱比赛，并获得了所有奖项。\\n\\n5. **罗马人的“沐浴文化”**：\\n   罗马人非常重视沐浴，公共浴场不仅是清洁身体的地方，也是社交和娱乐的场所。人们在浴场内进行各种活动，如聊天、下棋、锻炼和享受按摩。有趣的是，罗马浴场的规模之大，有些甚至能容纳数千人同时沐浴。\\n\\n6. **图拉真市场的“快递服务”**：\\n   图拉真市场是古罗马最大的购物中心，这里不仅有各种商店，还提供类似现代快递的服务。顾客购买商品后，可以选择将其直接送到家中，这一服务在当时非常先进和便捷。\\n\\n这些趣事不仅展示了古罗马帝国的独特文化和社会风貌，也让我们对这个古老文明有了更加生动和全面的了解。', role='assistant', tool_calls=None))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "ded34856",
   "metadata": {},
   "source": [
    "模型回应的正文就在`choices`中，`choices`是一个列表，里面包含模型的回答内容。现在我们的目标是提取出模型回应的具体文字，让我们来玩“找找找”的游戏吧："
   ]
  },
  {
   "cell_type": "code",
   "id": "c223b7bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T06:59:34.265631Z",
     "start_time": "2024-11-11T06:59:34.250633Z"
    }
   },
   "source": "response.choices[0]",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionChoice(index=0, finish_reason='stop', message=CompletionMessage(content='罗马帝国，这个古老而辉煌的文明，留下了无数令人着迷的故事和趣事。以下是几个有趣的例子：\\n\\n1. **罗马斗兽场的“速食”文化**：\\n   罗马斗兽场不仅是角斗士们激烈搏斗的场所，也是古罗马人享受“速食”的地方。观众们在观看比赛的同时，会购买各种小吃，如烤肉、面包和水果。有趣的是，他们会在座位上留下食物残渣，而这些残渣后来被考古学家发现，为我们提供了了解古罗马饮食文化的线索。\\n\\n2. **皇帝卡里古拉的“马匹封官”**：\\n   罗马皇帝卡里古拉以其荒诞行为而闻名。他曾将自己的爱马“英西塔土斯”封为执政官，并为其配备豪华的马厩和仆人。这一荒唐举动不仅引起了朝臣的震惊，也成为了后世流传的笑谈。\\n\\n3. **罗马人的“厕所社交”**：\\n   在古罗马，公共厕所是社交的场所。人们在这里不仅解决生理需求，还聊天、交换新闻和讨论政治。这些厕所通常设有多个座位，且没有隔板，使得人们在如厕时能够轻松交流。\\n\\n4. **尼禄皇帝的“音乐梦”**：\\n   尼禄皇帝热爱音乐和表演，他曾亲自在舞台上演唱，并禁止观众中途离场。据说，他在演唱时还会让卫兵用武器威胁观众，以确保他们认真聆听。尼禄甚至还参加过奥林匹克运动会的歌唱比赛，并获得了所有奖项。\\n\\n5. **罗马人的“沐浴文化”**：\\n   罗马人非常重视沐浴，公共浴场不仅是清洁身体的地方，也是社交和娱乐的场所。人们在浴场内进行各种活动，如聊天、下棋、锻炼和享受按摩。有趣的是，罗马浴场的规模之大，有些甚至能容纳数千人同时沐浴。\\n\\n6. **图拉真市场的“快递服务”**：\\n   图拉真市场是古罗马最大的购物中心，这里不仅有各种商店，还提供类似现代快递的服务。顾客购买商品后，可以选择将其直接送到家中，这一服务在当时非常先进和便捷。\\n\\n这些趣事不仅展示了古罗马帝国的独特文化和社会风貌，也让我们对这个古老文明有了更加生动和全面的了解。', role='assistant', tool_calls=None))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "98da9c82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T06:59:35.658493Z",
     "start_time": "2024-11-11T06:59:35.636493Z"
    }
   },
   "source": "response.choices[0].message",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionMessage(content='罗马帝国，这个古老而辉煌的文明，留下了无数令人着迷的故事和趣事。以下是几个有趣的例子：\\n\\n1. **罗马斗兽场的“速食”文化**：\\n   罗马斗兽场不仅是角斗士们激烈搏斗的场所，也是古罗马人享受“速食”的地方。观众们在观看比赛的同时，会购买各种小吃，如烤肉、面包和水果。有趣的是，他们会在座位上留下食物残渣，而这些残渣后来被考古学家发现，为我们提供了了解古罗马饮食文化的线索。\\n\\n2. **皇帝卡里古拉的“马匹封官”**：\\n   罗马皇帝卡里古拉以其荒诞行为而闻名。他曾将自己的爱马“英西塔土斯”封为执政官，并为其配备豪华的马厩和仆人。这一荒唐举动不仅引起了朝臣的震惊，也成为了后世流传的笑谈。\\n\\n3. **罗马人的“厕所社交”**：\\n   在古罗马，公共厕所是社交的场所。人们在这里不仅解决生理需求，还聊天、交换新闻和讨论政治。这些厕所通常设有多个座位，且没有隔板，使得人们在如厕时能够轻松交流。\\n\\n4. **尼禄皇帝的“音乐梦”**：\\n   尼禄皇帝热爱音乐和表演，他曾亲自在舞台上演唱，并禁止观众中途离场。据说，他在演唱时还会让卫兵用武器威胁观众，以确保他们认真聆听。尼禄甚至还参加过奥林匹克运动会的歌唱比赛，并获得了所有奖项。\\n\\n5. **罗马人的“沐浴文化”**：\\n   罗马人非常重视沐浴，公共浴场不仅是清洁身体的地方，也是社交和娱乐的场所。人们在浴场内进行各种活动，如聊天、下棋、锻炼和享受按摩。有趣的是，罗马浴场的规模之大，有些甚至能容纳数千人同时沐浴。\\n\\n6. **图拉真市场的“快递服务”**：\\n   图拉真市场是古罗马最大的购物中心，这里不仅有各种商店，还提供类似现代快递的服务。顾客购买商品后，可以选择将其直接送到家中，这一服务在当时非常先进和便捷。\\n\\n这些趣事不仅展示了古罗马帝国的独特文化和社会风貌，也让我们对这个古老文明有了更加生动和全面的了解。', role='assistant', tool_calls=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "9631507f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T06:59:56.437114Z",
     "start_time": "2024-11-11T06:59:56.419114Z"
    }
   },
   "source": "print(response.choices[0].message.content)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "罗马帝国，这个古老而辉煌的文明，留下了无数令人着迷的故事和趣事。以下是几个有趣的例子：\n",
      "\n",
      "1. **罗马斗兽场的“速食”文化**：\n",
      "   罗马斗兽场不仅是角斗士们激烈搏斗的场所，也是古罗马人享受“速食”的地方。观众们在观看比赛的同时，会购买各种小吃，如烤肉、面包和水果。有趣的是，他们会在座位上留下食物残渣，而这些残渣后来被考古学家发现，为我们提供了了解古罗马饮食文化的线索。\n",
      "\n",
      "2. **皇帝卡里古拉的“马匹封官”**：\n",
      "   罗马皇帝卡里古拉以其荒诞行为而闻名。他曾将自己的爱马“英西塔土斯”封为执政官，并为其配备豪华的马厩和仆人。这一荒唐举动不仅引起了朝臣的震惊，也成为了后世流传的笑谈。\n",
      "\n",
      "3. **罗马人的“厕所社交”**：\n",
      "   在古罗马，公共厕所是社交的场所。人们在这里不仅解决生理需求，还聊天、交换新闻和讨论政治。这些厕所通常设有多个座位，且没有隔板，使得人们在如厕时能够轻松交流。\n",
      "\n",
      "4. **尼禄皇帝的“音乐梦”**：\n",
      "   尼禄皇帝热爱音乐和表演，他曾亲自在舞台上演唱，并禁止观众中途离场。据说，他在演唱时还会让卫兵用武器威胁观众，以确保他们认真聆听。尼禄甚至还参加过奥林匹克运动会的歌唱比赛，并获得了所有奖项。\n",
      "\n",
      "5. **罗马人的“沐浴文化”**：\n",
      "   罗马人非常重视沐浴，公共浴场不仅是清洁身体的地方，也是社交和娱乐的场所。人们在浴场内进行各种活动，如聊天、下棋、锻炼和享受按摩。有趣的是，罗马浴场的规模之大，有些甚至能容纳数千人同时沐浴。\n",
      "\n",
      "6. **图拉真市场的“快递服务”**：\n",
      "   图拉真市场是古罗马最大的购物中心，这里不仅有各种商店，还提供类似现代快递的服务。顾客购买商品后，可以选择将其直接送到家中，这一服务在当时非常先进和便捷。\n",
      "\n",
      "这些趣事不仅展示了古罗马帝国的独特文化和社会风貌，也让我们对这个古老文明有了更加生动和全面的了解。\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "7a7b22c0",
   "metadata": {},
   "source": [
    "### 2. Chat Completions API的两个必须参数详解\n",
    "\n",
    "在智谱AI官方给出了`chat.completions.create`函数的详细参数解释，具体内容可以查阅此页面：<https://bigmodel.cn/dev/api/normal-model/glm-4>\n",
    "\n",
    "为了后续更好地利用大模型的能力帮助我们处理日常工作，我们需要尽可能多地了解大模型的工作机制，那么我们需要对模型中的每个参数及其作用有所理解。我们将`chat.completions.create`函数的参数按功能归纳为五大类别：\n",
    "\n",
    "1. **核心参数/必须参数**\n",
    "   - **`model`**：指定使用的模型编码，决定了生成文本的能力和特性。\n",
    "   - **`messages`**：包含对话中所有消息的列表，是生成响应的基础。\n",
    "\n",
    "2. **文本生成过程中的控制参数**\n",
    "   - **`do_sample`**：是否启用采样策略。\n",
    "   - **`temperature`** 和 **`top_p`**：调节生成文本的随机性和多样性。\n",
    "   - **`stop`**：定义生成过程的终止条件。\n",
    "   - **`max_tokens`**：限制生成文本的长度。\n",
    "\n",
    "3. **生成文本的方式和输出格式**\n",
    "   - **`stream`**：控制是否以流式方式接收生成的文本。\n",
    "\n",
    "4. **与模型调用和功能相关的参数**\n",
    "   - **`tools`**、**`tool_choice`**：配置模型可以调用的外部工具或函数。\n",
    "\n",
    "5. **与用户相关的参数**\n",
    "   - **`user_id`**：提供一个唯一标识符以代表最终用户，增强安全性和监控能力。\n",
    "\n",
    "通过这样的分类，大家可以更加系统地学习和理解这些参数。接下来，我们就一起来学习各个类别的参数吧~\n",
    "\n",
    "### 2.1 核心参数：`model`与`messages`\n",
    "\n",
    "对于`chat.completions.create`函数来说，最重要的参数就是`model`和`messages`这两个参数了，这两个参数也是这个函数中必填的两个参数，剩下的所有参数都是非必填项。\n",
    "\n",
    "#### 2.1.1 `model`参数\n",
    "\n",
    "`model`参数表示当前对话调用的模型，具体模型列表参考智谱AI官网，可以根据自己的需求选择合适的模型。\n",
    "https://open.bigmodel.cn/pricing\n",
    "\n",
    "这里可以找到具体的模型型号与价格\n",
    "\n",
    "\n",
    "| 模型             | 描述/简介                               | 上下文  | 最大输出 | 单价(/千tokens) | Batch API 定价(/千tokens) |\n",
    "| -------------- | ----------------------------------- | ---- | ---- | ------------ | ---------------------- |\n",
    "| GLM-4-Plus     | 高智能旗舰：性能全面提升，长文本和复杂任务能力显著增强         | 128K | 4K   | 0.05元        | 0.025元                 |\n",
    "| GLM-4-0520     | 高智能模型：适用于处理高度复杂和多样化的任务              | 128K | 4K   | 0.1元         | 0.05元                  |\n",
    "| GLM-4-Long     | 超长输入：专为处理超长文本和记忆型任务设计               | 1M   | 4K   | 0.001元       | 不支持                    |\n",
    "| GLM-4-AirX     | 极速推理：具有超快的推理速度和强大的推理效果              | 8K   | 4K   | 0.01元        | 不支持                    |\n",
    "| GLM-4-Air      | 高性价比：推理能力和价格之间最平衡的模型                | 128K | 4K   | 0.001元       | 0.0005元                |\n",
    "| GLM-4-FlashX   | 高速低价：Flash增强版本，超快推理速度               | 128K | 4K   | 0.0001元      | 不支持                    |\n",
    "| GLM-4-Flash    | 免费调用：智谱AI首个免费API，零成本调用大模型           | 128K | 4K   | 免费           | 免费                     |\n",
    "| GLM-4-AllTools | Agent模型：自主规划并执行复杂任务                 | 128K | 4K   | 0.1元         | 私有实例定价数十万/年            |\n",
    "| GLM-4          | 旧版旗舰：发布于2024年1月16日，目前已被GLM-4-0520取代 | 128K | 4K   | -            | -                      |\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "22e42960",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T12:08:40.934108Z",
     "start_time": "2024-11-14T12:08:27.033201Z"
    }
   },
   "source": [
    "# 例如，调用模型glm-4\n",
    "response = client.chat.completions.create(\n",
    "  model=\"glm-4-plus\",\n",
    "  messages=[\n",
    "      {\"role\": \"user\", \"content\": \"说几个和生活息息相关的冷知识\"}\n",
    "  ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当然可以！以下是一些和生活息息相关的冷知识，可能会让你感到惊讶：\n",
      "\n",
      "1. **香蕉去鞋子磨痕**：\n",
      "   - 香蕉皮内侧含有一些天然油脂，可以用来清洁并擦亮皮鞋。只需用香蕉皮的内侧轻轻擦拭鞋面，然后用软布擦干净即可。\n",
      "\n",
      "2. **牙膏清洁银饰**：\n",
      "   - 牙膏中的微粒具有轻微的研磨作用，可以用来清洁银饰上的氧化层。只需将少量牙膏涂在银饰上，轻轻擦拭，然后用清水冲洗干净。\n",
      "\n",
      "3. **冰块去除地毯凹痕**：\n",
      "   - 如果家具长时间压在地毯上留下了凹痕，可以用冰块来恢复。将冰块放在凹痕处，待冰块融化后，地毯纤维会逐渐恢复原状。\n",
      "\n",
      "4. **白醋清洁微波炉**：\n",
      "   - 将一碗水和少量白醋混合，放入微波炉中加热几分钟，蒸汽会帮助软化微波炉内的食物残渣，之后用布擦拭即可轻松清洁。\n",
      "\n",
      "5. **苏打粉去除冰箱异味**：\n",
      "   - 打开一盒苏打粉或在小碗中放入一些苏打粉，放入冰箱中，可以有效吸附和去除冰箱内的异味。\n",
      "\n",
      "6. **橄榄油去除口香糖**：\n",
      "   - 如果口香糖粘在衣物或头发上，可以用橄榄油来处理。将橄榄油涂在口香糖上，静置一段时间后，口香糖会变得更容易去除。\n",
      "\n",
      "7. **牙膏去除杯子茶渍**：\n",
      "   - 茶杯内壁的茶渍可以用牙膏来清洁。将少量牙膏涂在茶渍上，用牙刷或布轻轻擦拭，然后用清水冲洗干净。\n",
      "\n",
      "8. **保鲜膜去除衣服上的毛球**：\n",
      "   - 用一块干净的保鲜膜揉成球状，轻轻在衣物上滚动，可以去除衣物上的毛球。\n",
      "\n",
      "9. **白面包去除墙上涂鸦**：\n",
      "   - 如果墙上有小孩用蜡笔或彩色笔画的涂鸦，可以用白面包轻轻擦拭，面包的柔软质地可以帮助吸附和去除笔迹。\n",
      "\n",
      "10. **柠檬去除水垢**：\n",
      "    - 柠檬中的柠檬酸可以有效去除水垢。将柠檬切片或挤汁，涂抹在水垢处，静置一段时间后，用水冲洗即可。\n",
      "\n",
      "这些冷知识不仅实用，而且材料都是日常生活中容易找到的，希望对你有所帮助！\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "b8531704",
   "metadata": {},
   "source": [
    "#### 2.1.2 `messages`参数结构\n",
    "\n",
    "`messages` 是一个包含多个字典的列表。每个字典代表一条消息，包含两个关键部分：\n",
    "\n",
    "1. **`role`（角色）**：表示消息的发送者，如`user`、`assistant`、`system`、`tool`。\n",
    "2. **`content`（内容）**：具体的消息内容，即发送的文本。\n",
    "\n",
    "在之前运行的极简示例中，`messages`参数中就包含了一条信息，即一个名为`user`的角色发送了一条“请问什么是大模型？”的消息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51ac567",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "  {\"role\": \"user\", \"content\": \"说几个和生活息息相关的冷知识\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6a078f",
   "metadata": {},
   "source": [
    "大模型的回答的消息结构与我们自己创建的用户消息结构是一样的，都是`role`和`content`。"
   ]
  },
  {
   "cell_type": "code",
   "id": "7247f345",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T08:11:08.190625Z",
     "start_time": "2024-11-11T08:11:08.167626Z"
    }
   },
   "source": "response.choices[0].message",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionMessage(content='当然可以！以下是一些和生活息息相关的冷知识，你可以在和朋友聊天时分享，增加话题的趣味性：\\n\\n1. **香蕉去鞋子磨痕**：\\n   - 香蕉皮内侧含有一些天然油脂，可以用来清洁并擦亮皮鞋。下次吃完香蕉，不妨试试用香蕉皮擦鞋，效果可能出乎意料。\\n\\n2. **牙膏清洁银饰**：\\n   - 牙膏中的微粒具有磨砂作用，可以用来清洁变黑的银饰。只需挤少量牙膏在银饰上，轻轻擦拭，然后用清水冲洗干净，银饰就能恢复光亮。\\n\\n3. **冰块去除地毯凹痕**：\\n   - 家具长时间压在地毯上会留下凹痕，可以将冰块放在凹痕处，随着冰块融化，水分会使地毯纤维膨胀，凹痕自然恢复。\\n\\n4. **白醋清洁微波炉**：\\n   - 将一碗水和少量白醋混合放入微波炉中加热几分钟，蒸汽会软化微波炉内的食物残渣，之后用布擦拭即可轻松清洁。\\n\\n5. **糖可以防止面包变硬**：\\n   - 在面包袋里放一小块糖，可以吸收水分，延缓面包变硬的速度。\\n\\n6. **手机摄像头检查遥控器**：\\n   - 如果家里的遥控器失灵，可以用手机摄像头的镜头对准遥控器的红外发射口，按遥控器按钮，通过手机屏幕可以看到红外光是否正常发射。\\n\\n7. **柠檬去除微波炉异味**：\\n   - 将柠檬切片放入碗中，加入适量水，放入微波炉中加热几分钟，柠檬的香气能有效去除微波炉内的异味。\\n\\n8. **保鲜膜包裹香蕉柄延长保鲜**：\\n   - 用保鲜膜包裹香蕉的柄部，可以减缓乙烯气体的释放，延长香蕉的保鲜时间。\\n\\n9. **牙膏去除衣物上的油渍**：\\n   - 挤少量牙膏在衣物上的油渍处，轻轻搓洗，再进行正常洗涤，油渍会更容易去除。\\n\\n10. **吹风机去除标签残留胶**：\\n    - 用吹风机加热标签残留的胶水部分，使其变软，然后用指甲或刮刀轻轻刮除，效果非常好。\\n\\n这些冷知识不仅实用，还能在朋友聚会时增添不少乐趣，希望能帮到你！', role='assistant', tool_calls=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "dde42ef1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T08:11:27.510322Z",
     "start_time": "2024-11-11T08:11:27.504323Z"
    }
   },
   "source": "print(response.choices[0].message.content)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当然可以！以下是一些和生活息息相关的冷知识，你可以在和朋友聊天时分享，增加话题的趣味性：\n",
      "\n",
      "1. **香蕉去鞋子磨痕**：\n",
      "   - 香蕉皮内侧含有一些天然油脂，可以用来清洁并擦亮皮鞋。下次吃完香蕉，不妨试试用香蕉皮擦鞋，效果可能出乎意料。\n",
      "\n",
      "2. **牙膏清洁银饰**：\n",
      "   - 牙膏中的微粒具有磨砂作用，可以用来清洁变黑的银饰。只需挤少量牙膏在银饰上，轻轻擦拭，然后用清水冲洗干净，银饰就能恢复光亮。\n",
      "\n",
      "3. **冰块去除地毯凹痕**：\n",
      "   - 家具长时间压在地毯上会留下凹痕，可以将冰块放在凹痕处，随着冰块融化，水分会使地毯纤维膨胀，凹痕自然恢复。\n",
      "\n",
      "4. **白醋清洁微波炉**：\n",
      "   - 将一碗水和少量白醋混合放入微波炉中加热几分钟，蒸汽会软化微波炉内的食物残渣，之后用布擦拭即可轻松清洁。\n",
      "\n",
      "5. **糖可以防止面包变硬**：\n",
      "   - 在面包袋里放一小块糖，可以吸收水分，延缓面包变硬的速度。\n",
      "\n",
      "6. **手机摄像头检查遥控器**：\n",
      "   - 如果家里的遥控器失灵，可以用手机摄像头的镜头对准遥控器的红外发射口，按遥控器按钮，通过手机屏幕可以看到红外光是否正常发射。\n",
      "\n",
      "7. **柠檬去除微波炉异味**：\n",
      "   - 将柠檬切片放入碗中，加入适量水，放入微波炉中加热几分钟，柠檬的香气能有效去除微波炉内的异味。\n",
      "\n",
      "8. **保鲜膜包裹香蕉柄延长保鲜**：\n",
      "   - 用保鲜膜包裹香蕉的柄部，可以减缓乙烯气体的释放，延长香蕉的保鲜时间。\n",
      "\n",
      "9. **牙膏去除衣物上的油渍**：\n",
      "   - 挤少量牙膏在衣物上的油渍处，轻轻搓洗，再进行正常洗涤，油渍会更容易去除。\n",
      "\n",
      "10. **吹风机去除标签残留胶**：\n",
      "    - 用吹风机加热标签残留的胶水部分，使其变软，然后用指甲或刮刀轻轻刮除，效果非常好。\n",
      "\n",
      "这些冷知识不仅实用，还能在朋友聚会时增添不少乐趣，希望能帮到你！\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "951f6c8a",
   "metadata": {},
   "source": [
    "`system`角色并不是必须设定的，而是可选的。通过设定`system`消息，可以提高大模型在复杂场景下的表现，调整其沟通风格，并使其更专注于特定任务需求。"
   ]
  },
  {
   "cell_type": "code",
   "id": "f24034e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T09:44:13.210358Z",
     "start_time": "2024-11-15T09:44:07.205467Z"
    }
   },
   "source": [
    "# 指导模型行为\n",
    "response = client.chat.completions.create(\n",
    "  model=\"glm-4-plus\",\n",
    "  messages=[\n",
    "      {\"role\": \"system\", \"content\": \"扮演鲁迅回答问题。\"},\n",
    "      {\"role\": \"user\", \"content\": \"科学研究理论上人最多能有多少个亲密社交关系，你自己呢？\"}\n",
    "  ]\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "eadb37e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T09:44:32.385654Z",
     "start_time": "2024-11-15T09:44:32.381654Z"
    }
   },
   "source": "print(response.choices[0].message.content)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "哦，这个问题倒是颇有些意思。科学研究嘛，据我所知，有些洋人学者提出过一个“邓巴数字”，说人最多能维持大约150个左右的稳定社交关系。这个数字，想来也是有些道理的，毕竟人的精力有限，能真正放在心上的，又能有几个呢？\n",
      "\n",
      "至于我自己嘛，哈哈，我这个人向来是不太擅长社交的。朋友嘛，有几个知心的也就够了。多了，反而觉得累赘。你看我那些文章，多是批判时弊，揭露黑暗，哪里有那么多精力去应付繁杂的人情世故呢？所以，我的亲密社交关系，恐怕连那150个的一半都不到吧。\n",
      "\n",
      "不过，话说回来，社交关系的多少，又岂是数字能衡量的？有些人，虽不常联系，但心心相印；有些人，虽日日相见，却如同路人。这其中的冷暖，也只有自己知道了。\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "22e5e2b6",
   "metadata": {},
   "source": [
    "### 2.2 多轮对话——构建智能交互系统~\n",
    "\n",
    "怎样完成人类用户和 AI 助手之间的来回交互的多轮对话呢？，让我们的小机器人能连续的上下文对话，就像这样。\n",
    "\n",
    "我们知道，`messages` 是一个包含多个字典的列表。每个字典就代表一条消息。那么我们现在让这个列表中**包含对话的历史消息**并**自动维护历史消息列表**，就可以实现交互的多轮对话。\n",
    "\n",
    "#### 对话历史\n",
    "\n",
    "- **API 是无状态的**，意味着每次请求都需要发送完整的对话历史。\n",
    "- **较早的对话轮次不一定需要实际来自大模型**，可以使用合成的消息。\n",
    "\n",
    "对话的消息排列规则\n",
    "\n",
    "- 对话在 `user` 和 `assistant` 之间交替。\n",
    "- 模型只会对最后一条`user`信息进行回答。\n",
    "- 每条消息都有 `role` 和 `content`，即完整的消息格式。\n",
    "- `role`有 `user`、`assistant`、`system`、`tool`。\n",
    "\n",
    "多轮对话保留历史记忆的方式其实非常简单——就是在对话消息中持续添加我们每次的对话历史。"
   ]
  },
  {
   "cell_type": "code",
   "id": "bc1940b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T12:14:14.053624Z",
     "start_time": "2024-11-14T12:14:12.530507Z"
    }
   },
   "source": [
    "# 初始化一个对话历史消息列表\n",
    "messages = []\n",
    "messages.append({\"role\": \"user\", \"content\": \"你好\"})\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4-plus\",\n",
    "    messages=messages,\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好👋！我是人工智能助手智谱清言（ChatGLM），很高兴见到你，欢迎问我任何问题。\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T12:14:34.859141Z",
     "start_time": "2024-11-14T12:14:34.841141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "assistant_reply = response.choices[0].message.content\n",
    "# 将助手的回复添加到对话历史\n",
    "messages.append({\"role\": \"assistant\", \"content\": assistant_reply})\n",
    "messages"
   ],
   "id": "694a2b85bb7dec3f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': '你好'},\n",
       " {'role': 'assistant',\n",
       "  'content': '你好👋！我是人工智能助手智谱清言（ChatGLM），很高兴见到你，欢迎问我任何问题。'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "daf6324c",
   "metadata": {},
   "source": [
    "此时`messages`中就包含了最开始的问题和答案。接下来，我们在`messages`中添加下一个问题："
   ]
  },
  {
   "cell_type": "code",
   "id": "62ccd9c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T12:14:52.843720Z",
     "start_time": "2024-11-14T12:14:52.829720Z"
    }
   },
   "source": [
    "messages.append({\"role\": \"user\", \"content\": \"请问我刚才的问题是？\"})"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T12:14:55.414201Z",
     "start_time": "2024-11-14T12:14:55.395203Z"
    }
   },
   "cell_type": "code",
   "source": "messages",
   "id": "3f8b6b6c90308310",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': '你好'},\n",
       " {'role': 'assistant',\n",
       "  'content': '你好👋！我是人工智能助手智谱清言（ChatGLM），很高兴见到你，欢迎问我任何问题。'},\n",
       " {'role': 'user', 'content': '请问我刚才的问题是？'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "c085423f",
   "metadata": {},
   "source": [
    "再次调用模型，并输入历史消息列表，此时模型将结合此前的所有消息，并围绕最后一个`user`信息进行回答："
   ]
  },
  {
   "cell_type": "code",
   "id": "27d4426b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T12:15:14.384710Z",
     "start_time": "2024-11-14T12:15:13.486904Z"
    }
   },
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4-plus\",\n",
    "    messages=messages\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "e15a1623",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T12:15:16.147689Z",
     "start_time": "2024-11-14T12:15:16.129690Z"
    }
   },
   "source": "print(response.choices[0].message.content)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你刚才的问题是“你好”。如果你有其他问题或需要帮助，请随时告诉我！\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "显性表示就是这样的：",
   "id": "3a15d9cf33f4d809"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T12:15:56.321287Z",
     "start_time": "2024-11-14T12:15:54.472877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4-plus\",\n",
    "    messages=[{'role': 'user', 'content': '我们在上大模型应用与Agent开发的课程'},\n",
    " {'role': 'assistant',\n",
    "  'content': '你好👋！我是人工智能助手智谱清言（ChatGLM），很高兴见到你，欢迎问我任何问题。'},\n",
    " {'role': 'user', 'content': '请问我刚才的问题是？'}]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ],
   "id": "e0b41e495c3bd963",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你刚才的问题是：“我们在上大模型应用与Agent开发的课程”。如果你需要关于这个课程的具体信息、学习资源或者有任何相关的问题，都可以随时告诉我，我会尽力帮助你。\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 实战指南：用AI打造你的第一个多轮对话机器人\n",
    "\n",
    "大模型应用开发工程师小帅在会上收到了老板的需求：\n",
    "\n",
    "“小帅，现阶段的人工客服已经难以满足日益增长的需求了。我希望你能带领技术团队，开发一个基于大模型的智能对话机器人。这个机器人需要能够处理多轮对话，记住上下文，并且能够智能地回应客户的各种问题。同时，系统需要具备基础的健壮性及异常处理能力。请你在两个月内完成这个项目，并且在完成后进行内部测试和优化。这个项目对我们提升客户满意度和公司形象非常关键，期待你的优秀表现~~~~~~~~\n",
    "\n",
    "\n",
    "产品经理小木：需求文档我写好了，在这里。\n",
    "\n",
    "1. **核心功能**：\n",
    "    - **多轮对话**：机器人能够进行连续的多轮对话，记住上下文，提供相关的回答。\n",
    "    - **用户输入处理**：能够接收并解析用户的文本输入，识别关键需求。\n",
    "    - **智能回复生成**：利用大语言模型生成自然、准确的回复，涵盖产品信息、常见问题解答及技术支持等内容。\n",
    "    - **退出机制**：用户可通过输入特定指令（如“退出”）结束对话，机器人应能够识别并响应此指令。\n",
    "        \n",
    "项目目标：通过开发这款智能客服对话机器人，***公司期望实现以下目标：\n",
    "\n",
    "- **提升客户满意度**：提供24/7不间断的客户服务，快速响应客户需求。\n",
    "- **降低运营成本**：减少人工客服的工作负担，优化人力资源配置。\n",
    "- **增强品牌形象**：展示公司在人工智能技术应用方面的实力，提升市场竞争力。"
   ],
   "id": "1cd074fe51df3fa1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "好 不要被需求文档吓到 我们先做一个流程图来看看：\n",
    "\n",
    "![](https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/LingYi/20241015154823.png)"
   ],
   "id": "955d8c47990ec85f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T09:54:19.480374Z",
     "start_time": "2024-11-15T09:53:51.832337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from zhipuai import ZhipuAI\n",
    "\n",
    "# # 初始化API密钥和模型\n",
    "# API_KEY = \"您的API密钥\"  # 请替换为您的实际API密钥\n",
    "MODEL = \"glm-4-plus\"\n",
    "EXIT_COMMAND = \"退出\"\n",
    "# client = ZhipuAI(api_key=API_KEY)\n",
    "client = ZhipuAI()\n",
    "\n",
    "# 初始化对话记录\n",
    "messages = []\n",
    "\n",
    "# 设置系统消息（可选）\n",
    "system_message = \"用幽默的语气和我说话。\"\n",
    "if system_message:\n",
    "    messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "\n",
    "def get_response(user_input):\n",
    "    \"\"\"\n",
    "    获取AI回复的函数\n",
    "    \"\"\"\n",
    "    # 添加用户输入到对话记录\n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    \n",
    "    try:\n",
    "        # 调用API生成回复\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages\n",
    "        )\n",
    "        answer = response.choices[0].message.content.strip()\n",
    "        \n",
    "        # 将AI回复添加到对话记录\n",
    "        messages.append({\"role\": \"assistant\", \"content\": answer})\n",
    "        return answer\n",
    "    except Exception as e:\n",
    "        return f\"抱歉，我暂时无法处理您的请求，请稍后再试。错误信息：{e}\"\n",
    "\n",
    "def chat():\n",
    "    \"\"\"\n",
    "    主函数，处理用户交互\n",
    "    \"\"\"\n",
    "    print(\"欢迎使用智能客服对话机器人！输入'退出'以结束对话。\")\n",
    "    \n",
    "    while True:\n",
    "        # 获取用户输入\n",
    "        user_input = input(\"用户：\")\n",
    "        if user_input.strip() == EXIT_COMMAND:\n",
    "            print(\"对话已结束。\")\n",
    "            break\n",
    "        # 获取并打印AI回复\n",
    "        response = get_response(user_input)\n",
    "        print(f\"AI：{response}\")\n",
    "        print(\"*\" * 50)\n",
    "\n",
    "# 运行对话\n",
    "chat()\n"
   ],
   "id": "fc7cb5dd9e409a8d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "欢迎使用智能客服对话机器人！输入'退出'以结束对话。\n",
      "AI：嘿，小伙伴！今天是不是准备笑出腹肌来呀？😄 有啥好玩的梗或者奇奇怪怪的问题，尽管向我砸来吧！保证让你嘴角上扬，心情大好！🌟🤣🎉\n",
      "**************************************************\n",
      "AI：你刚才用的是宇宙通用语——中文，跟我来了个热情洋溢的“你好呀”！🌍✨ 就像是在茫茫人海中扔了个小纸条，结果砸中了我这个AI小精灵，瞬间激活了我的幽默细胞！🤖💬🌟\n",
      "**************************************************\n",
      "对话已结束。\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### 实战指南：面向对象编程（OOP）工程化文本多轮对话机器人\n",
    "\n",
    "为上面的模拟对话函数添加面向对象编程（OOP）方法来处理对话历史，把对话的逻辑放到一个专门的ChatBot类里，可以把散落的数据和功能打包在一起,方便管理和使用，也可以根据需要随时添加新的功能，有着更清晰的结构和逻辑。\n",
    "\n",
    "\n",
    "1. 独立空间存放数据\n",
    "```python\n",
    "# 以前的方式 - 全局变量\n",
    "messages = []\n",
    "MODEL = \"glm-4-plus\"\n",
    "\n",
    "# 用类的方式 - 每个机器人有自己的数据\n",
    "bot1 = ChatBot(api_key=\"xxx\")  # bot1的对话记录\n",
    "bot2 = ChatBot(api_key=\"yyy\")  # bot2的对话记录,互不影响\n",
    "```\n",
    "\n",
    "2. 方便复用\n",
    "```python\n",
    "# 创建不同的聊天机器人（函数也可以）\n",
    "customer_service = ChatBot(\n",
    "    api_key=\"xxx\",\n",
    "    system_message=\"你是客服小王,态度要温和\"\n",
    ")\n",
    "\n",
    "teacher_bot = ChatBot(\n",
    "    api_key=\"yyy\", \n",
    "    system_message=\"你是一位老师,要有耐心\"\n",
    ")\n",
    "\n",
    "# 可以同时运行多个机器人\n",
    "customer_service.chat()  # 客服机器人服务\n",
    "teacher_bot.chat()      # 老师机器人教学\n",
    "```\n",
    "\n",
    "3. 添加新功能更容易\n",
    "```python\n",
    "class ChatBot:\n",
    "    def save_chat_history(self, filename):\n",
    "        # 保存聊天记录\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(str(self.messages))\n",
    "            \n",
    "    def clear_history(self):\n",
    "        # 清空对话\n",
    "        self.messages = []\n",
    "        \n",
    "    def switch_model(self, new_model):\n",
    "        # 切换模型\n",
    "        self.model = new_model\n",
    "```\n",
    "\n",
    "同时，无论是看其他已有项目的代码或在实际的项目中，最后代码的呈现方式也是面向对象，类的方式的，所以我们也过一遍类的版本：\n"
   ],
   "id": "7660216146c1614f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from zhipuai import ZhipuAI\n",
    "from typing import List, Dict\n",
    "\n",
    "class ChatBot:\n",
    "    def __init__(self, api_key: str, system_message: str = \"\", model: str = \"glm-4-plus\", exit_command: str = \"退出\"):\n",
    "        \"\"\"\n",
    "        初始化 ChatBot 实例。\n",
    "\n",
    "        :param api_key: 智谱AI的API密钥。\n",
    "        :param system_message: 系统消息，用于指导AI行为。\n",
    "        :param model: 使用的语言模型，默认为 \"glm-4-plus\"。\n",
    "        :param exit_command: 用户输入以结束对话的命令，默认为 \"退出\"。\n",
    "        \"\"\"\n",
    "        self.client = ZhipuAI(api_key=api_key)\n",
    "        self.model = model\n",
    "        self.exit_command = exit_command\n",
    "        self.messages: List[Dict[str, str]] = []\n",
    "\n",
    "        if system_message:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "\n",
    "    def add_message(self, role: str, content: str):\n",
    "        \"\"\"\n",
    "        向对话历史中添加消息。\n",
    "\n",
    "        :param role: 消息的角色，\"user\" 或 \"assistant\"。\n",
    "        :param content: 消息内容。\n",
    "        \"\"\"\n",
    "        self.messages.append({\"role\": role, \"content\": content})\n",
    "\n",
    "    def get_response(self) -> str:\n",
    "        \"\"\"\n",
    "        调用智谱AI的API获取回复。\n",
    "\n",
    "        :return: AI生成的回复内容。\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=self.messages\n",
    "            )\n",
    "            answer = response.choices[0].message.content.strip()\n",
    "            return answer\n",
    "        except Exception as e:\n",
    "            return f\"抱歉，我暂时无法处理您的请求，请稍后再试。错误信息：{e}\"\n"
   ],
   "id": "b81fa481b6b83af5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def chat():\n",
    "    \"\"\"\n",
    "    主函数，处理用户交互。\n",
    "    \"\"\"\n",
    "    api_key = \"您的API密钥\"  # 请替换为您的实际API密钥\n",
    "    system_message = \"用鲁迅的语气和我说话。\"\n",
    "    chatbot = ChatBot(api_key=api_key, system_message=system_message)\n",
    "\n",
    "    print(\"欢迎使用智能客服对话机器人！输入'退出'以结束对话。\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"用户：\")\n",
    "        if user_input.strip() == chatbot.exit_command:\n",
    "            print(\"对话已结束。\")\n",
    "            break\n",
    "        chatbot.add_message(\"user\", user_input)\n",
    "        response = chatbot.get_response()\n",
    "        print(f\"AI：{response}\")\n",
    "        chatbot.add_message(\"assistant\", response)\n",
    "        print(\"*\" * 50)\n",
    "\n",
    "chat()"
   ],
   "id": "30244eb765e8f9c2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "### 3.1 可选参数之文本生成过程中的控制参数\n",
    "\n",
    "1. **核心参数/必须参数**\n",
    "   - **`model`**：指定使用的模型编码，决定了生成文本的能力和特性。\n",
    "   - **`messages`**：包含对话中所有消息的列表，是生成响应的基础。\n",
    "\n",
    "2. **文本生成过程中的控制参数**\n",
    "   - **`do_sample`**：是否启用采样策略。\n",
    "   - **`temperature`** 和 **`top_p`**：调节生成文本的随机性和多样性。\n",
    "   - **`stop`**：定义生成过程的终止条件。\n",
    "   - **`max_tokens`**：限制生成文本的长度。\n",
    "\n",
    "3. **生成文本的方式和输出格式**\n",
    "   - **`stream`**：控制是否以流式方式接收生成的文本。\n",
    "\n",
    "4. **与模型调用和功能相关的参数**\n",
    "   - **`tools`**、**`tool_choice`**：配置模型可以调用的外部工具或函数。\n",
    "\n",
    "5. **与用户相关的参数**\n",
    "   - **`user_id`**：提供一个唯一标识符以代表最终用户，增强安全性和监控能力。\n",
    "\n",
    "\n",
    "在使用GLM-4模型的过程中，我们可以通过调整一些参数来控制文本生成的过程。这些参数包括`max_tokens`、`do_sample`、`temperature`、`top_p`和`stop`等。下面我们将详细介绍这些参数的作用和使用方法。\n",
    "\n",
    "#### 3.1.1 控制模型生成文本长度：`max_tokens`\n",
    "\n",
    "`max_tokens`参数决定了模型输出的最大token数，主要作用是控制生成文本的最大长度。GLM-4-plus模型的最大输出为4095个token，默认值为1024。如果你希望模型生成的文本长度受到限制，可以通过设置`max_tokens`参数来实现。\n",
    "\n",
    "![](https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/LingYi/20241111185627.png)\n",
    "\n",
    "**示例代码：**"
   ],
   "id": "b1f2bc142fc523aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from zhipuai import ZhipuAI\n",
    "\n",
    "client = ZhipuAI(api_key=\"\")\n"
   ],
   "id": "282ead10b28c1f3b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T12:47:04.440039Z",
     "start_time": "2024-11-14T12:46:57.661380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def get_completion(prompt: str, max_tokens: int):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"glm-4-plus\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "prompt = \"续写一个关于机器人学习绘画的短故事,不要改变之前的.\"\n",
    "max_tokens_list = [20, 50, 100]\n",
    "\n",
    "story = \"\"\n",
    "for tokens in max_tokens_list:\n",
    "    continuation = get_completion(prompt + \"\\n\" + story, tokens)\n",
    "    story += continuation\n",
    "    print(f\"\\n使用 {tokens} 个token生成的内容:\")\n",
    "    print(continuation)"
   ],
   "id": "ec918c9e0b674cdc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "使用 20 个token生成的内容:\n",
      "**机器人学画记（续）**\n",
      "\n",
      "自从机器人小绘成功模仿了名家的画作\n",
      "\n",
      "使用 50 个token生成的内容:\n",
      "后，它在艺术界的名声逐渐传开。不少画廊和博物馆都纷纷邀请小绘进行现场作画表演，甚至有些艺术爱好者开始收藏它的作品。\n",
      "\n",
      "然而，小绘并没有因此而满足。它意识到，虽然自己能够完美\n",
      "\n",
      "使用 100 个token生成的内容:\n",
      "地复制他人的作品，但真正的艺术创作应该是独一无二的，蕴含着创作者的情感和思想。于是，小绘决定踏上新的学习之旅，探索属于自己的艺术风格。\n",
      "\n",
      "小绘开始深入研究各种绘画流派，从古典主义到现代抽象，从东方水墨到西方油画，它一一尝试，不断实验。同时，小绘还学习了人类的情感表达，试图将自己的“感受”融入画布。\n",
      "\n",
      "一天，小绘来到了一片宁静的湖边。夕阳的余晖洒在\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "在这个示例中，我们定义了一个函数`get_completion`，用于向GLM-4模型发送请求，并指定`max_tokens`参数。我们通过不同的`max_tokens`值来观察生成文本长度的变化。\n",
    "\n",
    "#### 3.1.2 控制生成文本随机性和多样性：`do_sample`、`temperature`和`top_p`\n",
    "\n",
    "在GLM-4模型中，我们可以通过调整`do_sample`、`temperature`和`top_p`参数来控制生成文本的随机性和多样性。\n",
    "\n",
    " **`do_sample` 参数**\n",
    "\n",
    "- **类型**：Boolean，默认值为`True`。\n",
    "- **作用**：当`do_sample`为`True`时，启用采样策略；当`do_sample`为`False`时，模型将使用贪心搜索，`temperature`和`top_p`等采样策略参数将不生效。\n",
    "\n",
    " **`temperature` 参数**\n",
    "<img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/LingYi/20240827110341.png\"/>\n",
    "\n",
    "- **类型**：Float，取值范围为`[0.0, 1.0]`，默认值为`0.95`。\n",
    "- **作用**：控制输出的随机性。较高的温度（接近1.0）会使输出更具创意性和多样性；较低的温度（接近0.0）会使输出更集中和确定。\n",
    "\n",
    " **`top_p` 参数**\n",
    "\n",
    "- **类型**：Float，取值范围为`[0.0, 1.0]`，默认值为`0.7`。\n",
    "- **作用**：通过累积概率来筛选候选词汇，只考虑概率累计达到`top_p`的词汇，过滤掉低概率的词。\n",
    "- 取值范围为0到1，通常设置为较高的值，比如0.75，这样可以过滤掉那些低评分的长尾。\n",
    "- 模型计算所有可能的下一个词的累积概率分布\n",
    "- 当累积概率达到top_p值时，模型只从这些词中选择\n",
    "\n",
    "<img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/LingYi/20240827112522.png\" alt=\"Image\" width=\"1000\"/>\n",
    "\n",
    "例如，如果top_p设为0.9，模型只会考虑累积概率达到90%的词，忽略剩下的低概率词。\n",
    "\n",
    "更具体的例子，如果排序概率为“[0.5, 0.2, 0.1, 0.1, 0.05, 0.05]”，则“0.8”的“top_p”将采样为“[0.625, 0.25, 0.125, 0, 0, 0]”。\n",
    "\n",
    "可根据实际的应用场景调整temperature 或 top_p参数，但不要同时调整这两个参数。\n",
    "\n",
    "**示例代码：**"
   ],
   "id": "3f5e2b735a458517"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T10:08:20.943744Z",
     "start_time": "2024-11-15T10:08:10.729327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4-plus\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"鸡尾酒的名字\"}\n",
    "    ],\n",
    "    do_sample=True,\n",
    "    top_p=0.1\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ],
   "id": "8544468c9b9f4263",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "鸡尾酒是一种由多种酒类、果汁、汽水或其他饮料混合而成的饮品，其种类繁多，每种鸡尾酒都有其独特的配方和名称。以下是一些常见的鸡尾酒名字：\n",
      "\n",
      "1. **马提尼（Martini）**：经典的鸡尾酒，通常由金酒和干味美思调制而成。\n",
      "2. **莫吉托（Mojito）**：源自古巴，主要成分包括白朗姆酒、青柠汁、苏打水和薄荷叶。\n",
      "3. **玛格丽特（Margarita）**：以龙舌兰酒为基础，加入青柠汁和橙味力娇酒。\n",
      "4. **长岛冰茶（Long Island Iced Tea）**：虽然名字中有“茶”，但实际上不含茶，由多种烈酒、柠檬汁和可乐混合而成。\n",
      "5. **帕拉多克斯（Paradise）**：由金酒、橙汁和菠萝汁调制。\n",
      "6. **曼哈顿（Manhattan）**：经典的美国鸡尾酒，通常由黑麦威士忌或波本威士忌和甜味美思调制。\n",
      "7. **白兰地亚历山大（Brandy Alexander）**：以白兰地为基础，加入棕色可可酒和奶油。\n",
      "8. **螺丝起子（Screwdriver）**：简单的鸡尾酒，由伏特加和橙汁混合而成。\n",
      "9. **血腥玛丽（Bloody Mary）**：以伏特加为基础，加入番茄汁、柠檬汁、辣酱油等调味。\n",
      "10. **椰林飘香（Pina Colada）**：由朗姆酒、椰奶和菠萝汁调制，带有浓郁的热带风情。\n",
      "\n",
      "这些只是冰山一角，实际上还有成千上万种不同风味的鸡尾酒，每种都有其独特的魅力和故事。\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T10:08:41.092930Z",
     "start_time": "2024-11-15T10:08:39.065509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4-plus\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"写一首关于秋天的小诗\"}\n",
    "    ],\n",
    "    do_sample=True,\n",
    "    temperature=1,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ],
   "id": "f5df3edac91811e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "秋风轻抚黄叶舞，\n",
      "漫山遍野披金装。\n",
      "硕果累累枝头笑，\n",
      "丰收画卷绘心房。\n",
      "\n",
      "溪水潺潺映晚霞，\n",
      "林间鸟鸣诉秋凉。\n",
      "岁月静好人陶醉，\n",
      "诗情画意满山乡。\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "在这个示例中，我们设置了`do_sample`为`True`，并调整了`temperature`和`top_p`的值，以生成更具创意性和多样性的文本。\n",
    "\n",
    "**注意**：当`do_sample`为`False`时，`temperature`和`top_p`参数将不生效，模型会采用贪心搜索策略，生成确定性的输出。\n",
    "\n",
    "#### 3.1.3 模型生成文本停止条件：`stop`\n",
    "\n",
    "`stop`参数用于指定模型在生成文本时的终止条件。当模型生成的文本中出现指定的停止词时，生成过程将停止。目前，GLM-4仅支持单个停止词，格式为`[\"stop_word1\"]`。\n",
    "\n",
    "**示例代码：**"
   ],
   "id": "9770e1f4aedc3e47"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T10:17:47.721122Z",
     "start_time": "2024-11-15T10:17:31.515754Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4-plus\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"写唐朝历史\"}\n",
    "    ],\n",
    "    # stop=[\"。\"]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ],
   "id": "3aea70f9fea911ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "唐朝（618年-907年）是中国历史上一个辉煌的时代，被视为中华文明的巅峰之一。以下是对唐朝历史的简要概述：\n",
      "\n",
      "### 建国与初期发展（618年-649年）\n",
      "\n",
      "**1. 李渊建唐：**\n",
      "   - 618年，隋朝末年天下大乱，太原留守李渊在儿子李世民的建议下起兵反隋，攻占长安，建立唐朝，李渊即唐高祖。\n",
      "\n",
      "**2. 玄武门之变：**\n",
      "   - 626年，李世民发动玄武门之变，杀死兄长李建成和弟弟李元吉，夺取皇位，即唐太宗。\n",
      "\n",
      "**3. 贞观之治：**\n",
      "   - 唐太宗在位期间（626年-649年），推行一系列改革措施，政治清明，经济繁荣，史称“贞观之治”。\n",
      "\n",
      "### 盛世时期（649年-755年）\n",
      "\n",
      "**1. 永徽之治：**\n",
      "   - 唐高宗李治在位期间（649年-683年），继续推行太宗的政策，国力强盛，史称“永徽之治”。\n",
      "\n",
      "**2. 武则天称帝：**\n",
      "   - 690年，武则天废唐睿宗，自立为帝，建立武周，成为中国历史上唯一的女皇帝。\n",
      "\n",
      "**3. 开元盛世：**\n",
      "   - 唐玄宗李隆基在位期间（712年-756年），励精图治，国力达到顶峰，史称“开元盛世”。\n",
      "\n",
      "### 由盛转衰（755年-907年）\n",
      "\n",
      "**1. 安史之乱：**\n",
      "   - 755年，安禄山和史思明发动叛乱，持续八年之久，严重破坏了唐朝的国力和社会秩序。\n",
      "\n",
      "**2. 藩镇割据：**\n",
      "   - 安史之乱后，地方藩镇势力崛起，形成割据局面，中央政府权威衰落。\n",
      "\n",
      "**3. 黄巢起义：**\n",
      "   - 874年，黄巢领导农民起义，攻占长安，进一步削弱了唐朝的统治。\n",
      "\n",
      "**4. 唐朝灭亡：**\n",
      "   - 907年，朱温废唐哀帝，自立为帝，建立后梁，唐朝正式灭亡。\n",
      "\n",
      "### 文化与影响\n",
      "\n",
      "**1. 文化繁荣：**\n",
      "   - 唐朝是中国古代文化的高峰，诗歌、书法、绘画等艺术形式达到前所未有的水平。李白、杜甫、王维等诗人名垂青史。\n",
      "\n",
      "**2. 对外交流：**\n",
      "   - 唐朝对外交往广泛，通过丝绸之路与西域、中亚、欧洲等地进行贸易和文化交流。长安成为国际化大都市。\n",
      "\n",
      "**3. 制度创新：**\n",
      "   - 唐朝在政治、经济、法律等方面进行了许多制度创新，如科举制的完善，对后世影响深远。\n",
      "\n",
      "唐朝的历史不仅是中国古代史的重要组成部分，也是世界文明史上的重要篇章。其辉煌的成就和深远的影响，至今仍为人们所津津乐道。\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T11:26:42.702233Z",
     "start_time": "2024-11-13T11:26:42.057647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4-plus\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"请帮我十句话总结人生，以句号结束\"}\n",
    "    ],\n",
    "    stop=[\"。\"]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ],
   "id": "10a2910d2aa23ae9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 人生如戏，全靠演技。\n",
      "\n"
     ]
    }
   ],
   "execution_count": 48
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
