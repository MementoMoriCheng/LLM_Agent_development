{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4856b90-f977-4cbb-8373-42ca3872f8a3",
   "metadata": {},
   "source": [
    "# 多模态端侧小模型-GLM-Edge-v-5b 部署流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580c2c88-2061-464e-a080-38d8397246c7",
   "metadata": {},
   "source": [
    ">本内容包括GLM-Edge系列模型的快速介绍以及本地部署的流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870584a0-855d-4df1-a3ea-50cff701aff8",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241203115131325.png\" width=70%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f377c6c0-2e97-4f3b-81e0-5c0f8efd010f",
   "metadata": {},
   "source": [
    "## 模型简介"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7204c68-74eb-4888-8822-8284702ca029",
   "metadata": {},
   "source": [
    "GLM-Edge 是清华大学（智谱轻言）推出的一系列专为端侧设备设计的大语言模型和多模态理解模型。这些模型包括 GLM-Edge-1.5B-Chat、GLM-Edge-4B-Chat、GLM-Edge-V-2B 和 GLM-Edge-V-5B。其中，1.5B和2B模型主要针对手机、车机等轻量化设备平台，而4B和5B模型则更适用于PC等高性能平台。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd99e50d-1ad1-4bcb-aeae-1303027d7440",
   "metadata": {},
   "source": [
    "\n",
    "GLM-Edge系列模型在追求高效性能的同时，特别注重实际部署的便捷性与推理速度优化，在高通骁龙和Intel平台上的表现尤为出色，展现了卓越的适配能力与运行效率。并支持多种推理后端（如 transformers、OpenVINO、vLLM）进行模型推理，同时官方提供微调教程和配置文件，支持用户根据具体需求进行模型微调。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad416c48-bb87-4ef6-9f99-74b3d320bb54",
   "metadata": {},
   "source": [
    "例如，在高通骁龙8 Elite平台上，GLM-Edge凭借其强大的NPU算力，通过混合量化方案使1.5B对话模型和2B多模态模型的解码速度达到每秒60 tokens以上。在引入投机采样技术后，这两款模型的解码速度峰值可超过每秒100 tokens。这些高效推理方案将在后续由GLM团队或其合作伙伴陆续发布。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c01549-ca9b-44e8-99ea-06bbd5e9c5b7",
   "metadata": {},
   "source": [
    "**部署流程细节可以扫描下放二维码领取完整课件同步进行学习**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f511666f-ab03-4cfd-8b05-b5a8b55b0602",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/bc6d74d18490f68600356f4d68927d7.jpg\" width=70%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6053801f-eb4a-445b-b618-b8daca2d2b8d",
   "metadata": {},
   "source": [
    "# 本地部署流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9374fedf-8a35-4e31-9443-0486dc0c96b7",
   "metadata": {},
   "source": [
    "> 本流程是在Linux环境下通过命令行进行部署的，推理图象识别多模态模型GLM-Edge-v-5b需要至少19G显存。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0025fd7f-c1ec-4fcf-884f-df083a92f9e3",
   "metadata": {},
   "source": [
    "### 本地部署硬件推荐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbe2c95-ead7-4763-85b7-0f0674932480",
   "metadata": {},
   "source": [
    "Linux系统：\n",
    "1. 操作系统：推荐Ubuntu 22.04或更高版本，或其他支持的Linux发行版。\n",
    "2. 显卡:推荐使用 NVIDIA GPU（如 T4、V100、A10 等），或 AMD GPU，在本流程中至少需要 22GB 的显存。\n",
    "3. 内存：至少 16GB 的 RAM，在运行更大的模型的时候需要更多内存。\r",
    "4. 硬盘空间：在每个模型的支持列表中会显示安装所需的空间大小，在本流程中最少10GB用于模型下载。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f434ecec-7542-4c10-972d-d0da20ae393c",
   "metadata": {},
   "source": [
    "- **Step 1. 创建conda虚拟环境**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a717361f-22f5-4381-b5d2-1fe2a11e77d9",
   "metadata": {},
   "source": [
    "&emsp;&emsp;Conda创建虚拟环境的意义在于提供了一个隔离的、独立的环境，用于Python项目和其依赖包的管理。每个虚拟环境都有自己的Python运行时和一组库。这意味着我们可以在不同的环境中安装不同版本的库而互不影响。根据官方文档信息建议Python版本3.10以上。创建虚拟环境的办法可以通过使用以下命令创建：\n",
    "\n",
    "```bash\n",
    "# GLM4 是你想要给环境的名称，python=3.11 指定了要安装的Python版本。你可以根据需要选择不同的名称和/或Python版本。\n",
    "\n",
    "conda create -n glm4 python=3.11\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dffe4e3-ee03-4dcf-807b-94574d467ae1",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20240924162412814.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f663ade-99a2-43d6-878f-3ad85b737736",
   "metadata": {},
   "source": [
    "&emsp;&emsp;创建虚拟环境后，需要激活它。使用以下命令来激活刚刚创建的环境。如果成功激活，可以看到在命令行的最前方的括号中，就标识了当前的虚拟环境。虚拟环境创建完成后接下来安装torch。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1691850e-32b2-4188-8ac4-0c3bcc7fc13c",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20240924162442522.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a54104-59a0-4379-aa42-ee6622ae85aa",
   "metadata": {},
   "source": [
    "&emsp;&emsp;如果忘记或者想要管理自己建立的虚拟环境，可以通过conda env list命令来查看所有已创建的环境名称。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1d5508-4726-46b2-b3cf-d8d84fffe2a2",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20240928143512354.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15305f6d-005a-4afd-a9c8-3f6563569f75",
   "metadata": {},
   "source": [
    "&emsp;&emsp;如果需要卸载指定的虚拟环境则通过以下指令实现：\n",
    "```\n",
    "conda env remove --name envname\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ba71b3-33f1-498e-92dc-1a46ad9bc0d8",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20240928143643575.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3523b2d3-26cb-4b9d-8bc4-3ac639599ab3",
   "metadata": {},
   "source": [
    "- 需要注意的是无法卸载当前激活的环境，建议卸载时先切换到base环境中再执行操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d762ee76-9406-4119-b772-ed574e5432cc",
   "metadata": {},
   "source": [
    "- **Step 2. 查看当前驱动最高支持的CUDA版本**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8366b7a6-cab7-438b-a17d-30467c6b1dfb",
   "metadata": {},
   "source": [
    "&emsp;&emsp;我们需要根据CUDA版本选择Pytorch框架，先看下当前的CUDA版本：\n",
    "```\n",
    "nvidia -smi\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d29e95-f8f2-4d24-8a76-b24b67c9a1c1",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20240924161818464.png\" width=70%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd685c86-f34e-430d-b4a9-e9d11d1c24b1",
   "metadata": {},
   "source": [
    "- **Step 3. 在虚拟环境中安装Pytorch**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fb2cad-fa53-483a-92f2-70ada2812b5b",
   "metadata": {},
   "source": [
    "&emsp;&emsp;进入Pytorch官网：https://pytorch.org/get-started/previous-versions/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52288e1-c438-4bb5-bee8-404d6b6b0e5a",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu001.oss-cn-beijing.aliyuncs.com/img/image-20240103163206436.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96827b4-e600-4439-a174-1f80814e6a63",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当前的电脑CUDA的最高版本要求是12.2，所以需要找到不大于12.2版本的Pytorch。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf09ce72-c297-43b6-add5-17733abaa35a",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://snowball101.oss-cn-beijing.aliyuncs.com/img/202401041455184.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f70d80-439e-4309-8ac8-21a84c3d7d55",
   "metadata": {},
   "source": [
    "&emsp;&emsp;直接复制对应的命令，进入终端执行即可。这实际上安装的是为 CUDA 12.1 优化的 PyTorch 版本。这个 PyTorch 版本预编译并打包了与 CUDA 12.1 版本相对应的二进制文件和库。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4fb42a-9bbb-42a3-bdd1-e55fe9958bcc",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20240924163535040.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b19f133-f612-4ad5-8711-66a995fdd0ca",
   "metadata": {},
   "source": [
    "- **Step 4. 安装Pytorch验证**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88bbed7-f21f-4fa6-bd3a-8384f4a931a8",
   "metadata": {},
   "source": [
    "&emsp;&emsp;待安装完成后，如果想要检查是否成功安装了GPU版本的PyTorch，可以通过几个简单的步骤在Python环境中进行验证：\n",
    "```bash\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d52c6a-209b-4d1e-b066-5b314610d6ef",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20240924164006735.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f820983a-7519-4a01-8204-fdef3194d71b",
   "metadata": {},
   "source": [
    "&emsp;&emsp;如果输出是版本号数字，则表示GPU版本的PyTorch已经安装成功并且可以使用CUDA，如果显示ModelNotFoundError，则表明没有安装GPU版本的PyTorch，或者CUDA环境没有正确配置，此时根据教程，重新检查自己的执行过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4434c2e9-f8e2-4806-9032-2805a107e73e",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20240924164131600.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63bff35-73df-4f0b-ab9d-ce70fd0504d4",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当然通过pip show的方式可以很简洁的查看已安装包的详细信息。pip show <package_name> 可以展示出包的版本、依赖关系（展示一个包依赖哪些其他包）、定位包安装位置、验证安装确实包是否正确安装及详情。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1953314-54dc-4837-84d0-edf53d8c8037",
   "metadata": {},
   "source": [
    "- **Step 5. 创建文件夹**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46c2845-9191-4b9f-8583-5c57816e391e",
   "metadata": {},
   "source": [
    "可以通过下图的方式创建新的文件夹`mkdir glm-edge`,其中，glm-edge为自定义的文件夹名称。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8a7474-fe76-4f23-a17c-c8b4d32bd71d",
   "metadata": {},
   "source": [
    "创建好文件后通过`cd glm-edge`的命令进入到指定的文件地址中。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706e3346-e818-4389-96d2-ce43d0e0461a",
   "metadata": {},
   "source": [
    "通过指令`pwd`可以展示当前文件夹的绝对路径，稍后我们需要该信息指定我们的下载地址。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429c8a65-bac3-4c82-9124-99af1a53897a",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241203111553941.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac261d7b-5a5d-4ca8-b37c-ef83ba94fa3d",
   "metadata": {},
   "source": [
    "- **Step 6. 从Model Scope下载GLM-Edge-v-5b模型**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2aa62a-57e2-4634-9342-7fe9c60695d8",
   "metadata": {},
   "source": [
    "&emsp;&emsp;本次介绍的是 Model Scope 下载方法。Model Scope 是一个国内平台的资源丰富的模型库，开发者可以上传和共享他们训练好的机器学习模型。这些模型通常是经过大量数据训练的，并且很大，因此需要特殊的存储和托管服务。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbe8ea3-0ee2-41c0-8562-178bfc2684b2",
   "metadata": {},
   "source": [
    "&emsp;&emsp;Model Scope下载路径如下：\n",
    "https://www.modelscope.cn/models/ZhipuAI/glm-edge-v-5b/files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806a976d-ae5d-4b7d-a74d-efbe24ab5a7a",
   "metadata": {},
   "source": [
    "&emsp;&emsp;Model Scope支持多种下载模式：SDK下载、Git下载、命令行下载（下载完整模型、下载单个文件 后直接加文件名即可）、手动下载"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2538f08d-6f8a-4832-acb1-e9e0261dd06c",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241203111000355.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f535f1-2dfc-4afd-aafc-4a3cb6b8b264",
   "metadata": {},
   "source": [
    "- **Step 7. 命令行方式下载**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1e184c-b3c5-4fae-a269-4bbe67770974",
   "metadata": {},
   "source": [
    "这是一种快捷的本机下载方式，首先通过命令`pip install modelscope`安装好达摩社区的安装包，然后通过以下指令可以下载模型的权重文件，这种方法无需翻墙，无需下载额外的插件。\n",
    "```\n",
    "pip install modelscope\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d98425c-80e1-4adc-8657-075fe0f8b200",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20240924184742785.png\" width=70%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089f22ef-b4ad-4a38-b767-9b67c03780fe",
   "metadata": {},
   "source": [
    "通过以下命令实现指定下载路径安装完整的文件，需要注意的是`./dir`需要替换成你本地想要储存的文件路径。\n",
    "```\n",
    "modelscope download --model ZhipuAI/glm-edge-v-5b  --local_dir ./dir\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe3e863-fdf5-4deb-8836-11bd0fa38fac",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241202135920636.png\" width=70%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fa23b0-6040-48bc-a5df-d46582404226",
   "metadata": {},
   "source": [
    "下载完成后全部的权重文件的内容如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930da343-42d5-4246-bc54-a667addf58c7",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241202135931314.png\" width=70%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59137662-1b1f-423c-abe2-9b63d5fe8a51",
   "metadata": {},
   "source": [
    "- **Step 8. 模型使用测试**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022678d0-0640-445b-8bed-5f52a18a089b",
   "metadata": {},
   "source": [
    "我们可以在安装模型的对应文件夹内创建一个新的脚本进行模型推理测试，通过`vim run.py`来创建一个名为run的python文件。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a57eab-0822-4e8d-99a8-8947b5a0d952",
   "metadata": {},
   "source": [
    "随后在新建的文件中复制以下代码，需要注意的是，要对代码中图像输入的部分修改成你在本地保存的图像文件的绝对路径，并将model_dir后的信息修改成模型存储的绝对路径。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bbf675-3297-48a5-9aa1-8e94de548039",
   "metadata": {},
   "source": [
    "```python\n",
    "import torch\n",
    "from PIL import Image\n",
    "from modelscope import snapshot_download\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoImageProcessor,\n",
    "    AutoModelForCausalLM,\n",
    ")\n",
    "\n",
    "url = \"/home/data/LLM/glm-edge/tb.png\" # 这里需要修改成你在本地保存的图像文件的绝对路径\n",
    "messages = [{\"role\": \"user\", \"content\": [{\"type\": \"image\"}, {\"type\": \"text\", \"text\": \"describe this image\"}]}]\n",
    "image = Image.open(url)\n",
    "\n",
    "model_dir = \"/home/data/LLM/glm-edge\" # 这里需要修改成模型所在文件夹的绝对路径\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(model_dir, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_dir,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages, add_generation_prompt=True, return_dict=True, tokenize=True, return_tensors=\"pt\"\n",
    ").to(next(model.parameters()).device)\n",
    "\n",
    "generate_kwargs = {\n",
    "    **inputs,\n",
    "    \"pixel_values\": torch.tensor(processor(image).pixel_values).to(next(model.parameters()).device),\n",
    "}\n",
    "output = model.generate(**generate_kwargs, max_new_tokens=100)\n",
    "print(tokenizer.decode(output[0][len(inputs[\"input_ids\"][0]):], skip_special_tokens=True))\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac2f204-5946-4dc5-ae77-b0c5b4c1930a",
   "metadata": {},
   "source": [
    "完成好修改后，保存并退出。通过`python run.py`命令启动该文件，实现模型的多模态图像识别推理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3353551a-7f8a-463d-b43a-165b03723c92",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241202165059946.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c27755-eff4-4222-9a42-43e40f7c0bbc",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241203114909038.png\" width=100%></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
