{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dff3a91c-9811-46c1-8e9e-918babe3b13a",
   "metadata": {},
   "source": [
    "# Ollama v0.4最新发布，支持多模态模型应用推理！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7d0b87-c4d3-4726-874f-79a7e8a41209",
   "metadata": {},
   "source": [
    ">文章主要内容：介绍 Ollama 最新版本对多模态模型推理的支持，并以 Llama3.2vision 为例，详细讲解其使用方法。此外，还涵盖了分别在 Windows 和 Ubuntu 环境下部署 Ollama 并调用模型的具体操作步骤。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e047332b-e201-48c8-8d60-79277cfe3b67",
   "metadata": {},
   "source": [
    "本次跟新包括了：\n",
    "- 支持 Llama 3.2 Vision（即 Llama）架构，即 Llama 最新的视觉模型。\n",
    "- 向视觉模型发送后续请求将显著加快速度。\n",
    "- 修复了停止序列无法正确检测的问题\n",
    "- 现在可以在运行 ollama create my-model 时从 Safetensors 导入模型，而不需要 Modelfile 文件\n",
    "- 解决了在 Windows 下重定向输出到文件会导致写入无效字符的问题\n",
    "- 解决了导致 Ollama 出错的不合法模型数据问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d4691c-8185-431b-bd0c-72286104cbca",
   "metadata": {},
   "source": [
    "## 1.Ollama 快速入门"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10685362-37b9-428d-80d4-eeb39e1c123b",
   "metadata": {},
   "source": [
    "####  1.1 Ollama基本信息介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80a8feb-8ade-439e-9ce9-dea6da287257",
   "metadata": {},
   "source": [
    "Ollama 是一个**开源**的大语言模型服务工具，专注于简化本地模型的创建、管理和部署流程。它允许用户轻松部署和管理多种流行的**开源模型**，如 Llama、Mistral 和 Code Llama。以下是 Ollama 的一些主要特点和功能："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef39801f-9bbd-4e08-a1cc-07b3e1bfc02d",
   "metadata": {},
   "source": [
    "主要特点：\n",
    "\n",
    "\n",
    "- 简化部署：\n",
    "Ollama 通过将模型权重、配置和数据捆绑到一个称为 Modelfile 的包中，简化了模型的安装和配置过程，使得用户可以更方便地管理和运行这些模型。\n",
    "\n",
    "- 跨平台支持：\n",
    "Ollama 支持多种操作系统，包括 macOS、Linux 和 Windows。用户只需下载相应平台的安装包即可快速安装和使用。\n",
    "\n",
    "- 命令行操作：\n",
    "用户可以通过简单的命令行指令来启动和运行模型。例如，运行一个模型只需执行类似 ollama run model_name 的命令。\n",
    "\n",
    "- 资源要求：\n",
    "相较于传统部署调用模型的方法，Ollama模型支持推理的均为量化后的模型，这种方式对硬件资源的需求更低，更适合开发者快速上手。\n",
    "\n",
    "- API 接口：\n",
    "Ollama 提供了类似 OpenAI 的 API 接口，用户可以通过这些接口与模型进行交互，支持热加载模型文件，无需重新启动即可切换不同的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef610e8-d569-4768-8b16-d8dccc4753d1",
   "metadata": {},
   "source": [
    "Ollama 非常适合需要在本地运行大语言模型的开发者和企业，如：\n",
    "\n",
    "- 开发和测试：在本地快速创建和测试新的语言模型。\n",
    "- 隐私保护：在本地部署模型，适用于有严格隐私需求的企业。\n",
    "- 多模型管理：轻松管理和部署多个模型，适合有大量模型管理需求的团队。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acf1837-b823-44ca-bee2-82ce38b5c64d",
   "metadata": {},
   "source": [
    "Ollama 适用于学术研究、个人项目开发以及企业知识库问答等多种场景，帮助用户在本地环境中快速实验和部署大型语言模型。\n",
    "\n",
    "总的来说，Ollama 为希望在本地运行和实验大型语言模型的用户提供了一个方便且高效的解决方案。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93edc5dd-6908-4333-8cb6-8958dfcf0d72",
   "metadata": {},
   "source": [
    "### 1.2 硬件支持"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080ad6c7-0197-4a03-b146-4e90034f8076",
   "metadata": {},
   "source": [
    "下列表格是Ollama支持的全部显卡的列表，大家可以参考来确定自己的设备是否可以使用该推理框架。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8ce81a-376c-4c86-9531-5a98e07c1c16",
   "metadata": {},
   "source": [
    "Nvidia英伟达系列显卡："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb201f7c-4b3e-4641-8d7a-38d4a82e4667",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241120141639247.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b52a96-2f81-41be-9e5b-69875a805c48",
   "metadata": {},
   "source": [
    "AMD系列显卡："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e73b79-d178-4349-b3f2-90bc92fce562",
   "metadata": {},
   "source": [
    "- Linux环境："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2142a57-c543-4079-af17-dff108bd1b6d",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241120141932701.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4de432-ff57-43de-bc05-b99506caf970",
   "metadata": {},
   "source": [
    "- Windows环境："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da7cdc9-fc24-4b1a-a7f9-b5bd2f0825b0",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241120141954677.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e0656a-734a-4243-8a69-a8ab657eded8",
   "metadata": {},
   "source": [
    "### 1.3 如何快速使用Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6907a2-e76f-43c5-92c5-02220bfcb118",
   "metadata": {},
   "source": [
    ">不同环境下载和安装Ollama请参考后面小节关于Windows和Linux系统部署流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da05d22c-67e8-4c08-be52-5cebce0cd0bb",
   "metadata": {},
   "source": [
    ">Ollama在国内就可以便捷登录，在官网可以看到Ollama支持的模型列表： https://ollama.com/library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c33b3f-80b0-4002-aef2-c5ff7548725a",
   "metadata": {},
   "source": [
    "本小节快速介绍如果上手使用Ollama并完成一次模型的部署、启动。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0930f5e9-5791-4baa-aace-a3de952fb3d2",
   "metadata": {},
   "source": [
    "在搜索栏（Search models）中输入你想要的模型的名称，在下方界面便会显示平台上支持的模型列表："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c970d428-cfe8-434a-b4b7-db3435815bb8",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241120143523889.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8858e2-1da3-4f9a-8de3-81f8d719776a",
   "metadata": {},
   "source": [
    "这里以qwen2.5为例进行部署演示："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93201999-9455-4bd7-b070-c5ee7d318b5a",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241023151401629.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d427d77-cdb4-4bd2-8a2f-204a64ac226c",
   "metadata": {},
   "source": [
    "每个模型下面有支持的功能和参数型号以及基本的模型描述，点击进入对应模型可以看到下载所需占用的内存大小。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a502e6cd-809a-4ab3-bd89-e37f2b3573f3",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241023151317687.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a510531-fa35-4d72-b5bc-143c2ba81eaa",
   "metadata": {},
   "source": [
    "点击左边下拉列表可以选择不同参数的模型，大家可以根据自己的硬件条件和使用需要来选择对应的模型，在右侧会显示对应模型的启动代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adb0f57-e7cd-4128-bb7a-2f8f73ee8e29",
   "metadata": {},
   "source": [
    "**使用7b模型需要6G左右的显存，14b模型需要12G左右的显存，72b模型需要60G的显存进行推理。**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83123cf-4bd7-476f-b7e4-cff1a63055a4",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241120145032308.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e66c6ff-0950-460c-8d5b-8918d0a2f7b1",
   "metadata": {},
   "source": [
    "**下载模型**\r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02907032-183f-4175-8b47-6e6319621827",
   "metadata": {},
   "source": [
    "在终端中执行命令 `ollama run qwen2.5：72b` ，即可下载 qwen2.5：72b 模型。模型下载完成后，会自动启动大模型，进入命令行交互模式，直接输入指令，就可以和模型进行对话了对应参数的模型的下载方式可以通过在Ollama官网查看到下载指令。当出现`success`字样的时候说明下载成功，当出现`>>>`图标的时候可以进行对话交互了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9780d39f-46a4-482f-9c23-9f97e45b7c14",
   "metadata": {},
   "source": [
    "```\n",
    "ollama run qwen2.5:72b\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88fb275-ddfa-4959-adc3-eaf1fab3187f",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241022112005646.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee7f6dd-884e-4e50-ac0b-beff9673a7f1",
   "metadata": {},
   "source": [
    "完成下载后会直接进入模型启动状态，如果退出或刷新界面，再次输入指令`ollama run qwen2.5:72b`即可启动对应模型。\n",
    "可以看到推理所需的计算资源相对均匀的分布在每张工作显卡上。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bc4952-89fe-46f4-89ce-75efae688d75",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241022112658854.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755af7c6-aacd-43bf-bef9-e1bddfa3ce34",
   "metadata": {},
   "source": [
    "如果想结束对话，直接在对话栏中输入`/bye`即可结束进程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a7d421-ed03-428c-b19d-7b8f16d1f7e2",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241120151107260.png\" width=40%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7496dc08-9eeb-4f59-ac98-3b56eb020712",
   "metadata": {},
   "source": [
    "### 1.4 使用ModelScope平台上的GGUF格式的大模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a867070b-ffdd-41b5-9f6e-eb6ddb86c46a",
   "metadata": {},
   "source": [
    ">Ollama现已支持modelscope上托管的GGUF格式的大模型部署推理。（需要Ollama版本不小于0.3.12）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544e1fef-aecf-4e68-9bd9-51f45387d5fe",
   "metadata": {},
   "source": [
    "如果要使用的模型不在 Ollama 模型库，可以通过选择GGUF (GPT-Generated Unified Format)模型来实现部署、使用。\r\n",
    "GGUF 是由 llama.cpp 定义的一种高效存储和交换大模型预训练结果的二进制格式。\r\n",
    "\r\n",
    "Ollama 支持采用 Modelfile 文件中导入 GGUF 模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6866438c-7a9e-4d70-b521-a5b483275d4a",
   "metadata": {},
   "source": [
    "- Ollama 是一个基于开源推理引擎 llama.cpp 构建的大模型推理工具框架。借助底层引擎的高效推理能力以及对多种硬件的适配支持，Ollama 可以在包括 CPU 和 GPU 在内的多种硬件环境上运行各种精度的 GGUF 格式大模型。通过简单的命令行操作，即可快速启动 LLM 模型服务。\n",
    "\n",
    "- ModelScope 社区托管了数千个高质量的 GGUF 格式大模型，并支持与 Ollama 框架和 ModelScope 平台的无缝对接。用户只需使用简单的 ollama run 命令，即可直接加载并运行 ModelScope 模型库中的 GGUF 模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f164c35-b95c-4fea-bf39-8426decb6f26",
   "metadata": {},
   "source": [
    "ModelScope官网链接如下：https://www.modelscope.cn/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b02f287-da0b-4f4f-ae6f-b9d14b0fd720",
   "metadata": {},
   "source": [
    "使用Ollama下载和使用GGUF格式的模型在方法上没有变化，依旧是在命令行中输入以下命令即可实现："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbe6f41-cf56-46f6-802a-7220aaefbae7",
   "metadata": {},
   "source": [
    "```\n",
    "ollama run modelscope.cn/{model-id}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1f13e5-0818-4199-ba18-50306d11ed9f",
   "metadata": {},
   "source": [
    "其中model-id的具体格式为{username}/{model},这个信息可以在modelscope上每个模型自己的标签页上查看并复制。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cacc633-ce4c-4398-a394-523e1af8baf2",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241119105609120.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604b6841-0e1f-4c2c-8f9a-5476ca053727",
   "metadata": {},
   "source": [
    "以下用Qwen2.5-3B-Instruct-GGUF做例子进行部署、使用实例。执行以下代码即可实现在魔搭社区上部署启动对应的GGUF格式模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8863796d-c2bd-4280-8d9c-2c8c5220334e",
   "metadata": {},
   "source": [
    "```\n",
    "ollama run modelscope.cn/Qwen/Qwen2.5-3B-Instruct-GGUF\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc74e06-0dbe-46a5-bf13-53bce7b67c8b",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241119104626308.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5ebb66-5b98-48bc-b401-849117b32b13",
   "metadata": {},
   "source": [
    "全部下载完成后便会自动开启对话任务，如下图所示："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e73b92-3501-46ed-9bad-2fb1f379829c",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241119105205417.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373a125c-8efd-4594-953e-153542fd3c3c",
   "metadata": {},
   "source": [
    "通过在命令行输入指令`ollama list`可以查看ollama全部可支持的模型列表，当下载完成后可以看到`modelscope.cn/Qwen/Qwen2.5-3B-Instruct-GGUF`的名称在列，并显示其占据磁盘信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649665af-2a70-4a32-aa92-1cc9fc3cf8d3",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241119105425144.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6e23f3-0fb7-4a7e-9eb9-052809cb7e98",
   "metadata": {},
   "source": [
    "如果需要进行版本管理，通过指令`ollama rm 模型名称`即可删除对应模型，如上图所示，完成移除后在模型列表里不再有`modelscope.cn/Qwen/Qwen2.5-3B-Instruct-GGUF`模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3112f30e-0f1a-48ad-8f3f-5ace7212ed00",
   "metadata": {},
   "source": [
    "此外Ollama支持加载不同精度的GGUF模型，同时在一个GGUF模型库中，一般也会有不同精度的模型文件存在。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca45edb6-4cf8-4cc6-be3b-3e0ecb782a43",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241120160644517.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cec70f8-1fba-47e7-8379-da520a6603ec",
   "metadata": {},
   "source": [
    "这里如如Q3_K_M,Q4_K_M, Q5_K等对应的是不同量化精度与量化方法。默认情况下，如果模型repo里有Q4_K_M版本的话，执行命令会自动拉取并使用该版本，这个格式是量化版本中可以做到在推理精度以及推理速度，资源消耗之间做一个较好的均衡。如果没有Q4_K_M版本且没有指定，则会选择合适的其他的版本。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241473c2-461b-412b-a525-076aad809dec",
   "metadata": {},
   "source": [
    "通过以下方式也可以选择指定的使用版本，如："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f2212b-12f0-4cbe-a7a3-bd4bcfda9ca3",
   "metadata": {},
   "source": [
    "```\n",
    "ollama run modelscope.cn/Qwen/Qwen2.5-3B-Instruct-GGUF:Q3_K_M\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f198cc4f-0133-4e02-97dd-877620a92388",
   "metadata": {},
   "source": [
    "这里命令行最后的:Q3_K_M选项，就指定了使用Q3_K_M精度的GGUF模型版本，这个选项大小写不敏感，也就是说，无论是:Q3_K_M，还是:q3_k_m，都是使用模型repo里的\"qwen2.5-3b-instruct-q3_k_m.gguf\" 这个模型文件。\n",
    "\n",
    "另外，也可以直接指定模型文件的全称，这同样是支持的："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0862392-72bd-47ab-8b8c-ab27a535d15d",
   "metadata": {},
   "source": [
    "```\n",
    "ollama run modelscope.cn/Qwen/Qwen2.5-3B-Instruct-GGUF:qwen2.5-3b-instruct-q3_k_m.gguf\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7616696e-56e4-4eff-a6c0-79bd9285a00c",
   "metadata": {},
   "source": [
    "### 1.5 如何实现版本更新"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bc69be-e352-46cd-9bfd-d0120c56e2e4",
   "metadata": {},
   "source": [
    "- 在Windows和macOS环境中，Ollama都会自动下载和更新版本，单击任务栏或菜单栏项，然后单击“重新启动以更新”以应用更新。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1ca866-e38d-4d9f-8ad5-8f17e662c4d0",
   "metadata": {},
   "source": [
    "- 在Linux环境中，需要在命令行执行以下命令运行安装脚本重新安装实现更新："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa3e0c9-7734-4ec4-98ca-e166ff533a78",
   "metadata": {},
   "source": [
    "```\n",
    "curl -fsSL https://ollama.com/install.sh | sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53895d25-e4bd-4b24-95df-80f688a22aa7",
   "metadata": {},
   "source": [
    "### 1.6 Ollama常用命令"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23d88f3-e1d7-446f-bf1e-cefabce8e952",
   "metadata": {},
   "source": [
    "#### 1.6.1 对话"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b14ce56-16fe-4c99-a92b-93066f02ded0",
   "metadata": {},
   "source": [
    "- 多行输入：用\"\"\"包裹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9657635a-8121-4453-a3b6-71369a99cb2f",
   "metadata": {},
   "source": [
    "```\n",
    "ollama run my-model \"\"\"第一行\n",
    "第二行\n",
    "第三行\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a62f2ce-f45c-4aa2-b412-b8dbb33cf970",
   "metadata": {},
   "source": [
    "- 多模态模型：文本 + 图片地址"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91729320-35af-4963-bfdd-aef616211088",
   "metadata": {},
   "source": [
    "ollama run my-multimodal-model \"这张图片上是什么？ /path/to/image.png\"\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d289a2-d73b-4157-a1b5-10ecd48a14b5",
   "metadata": {},
   "source": [
    "- 将提示作为参数传入："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbe649b-96f4-4866-a41d-6d89822fc244",
   "metadata": {},
   "source": [
    "ollama run my-model \"请总结这个文件：$(cat README.md)\"\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7eb1741-1ab6-434b-aa57-47bbe8f1f9e9",
   "metadata": {},
   "source": [
    "#### 1.6.2 全部指令功能"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ccc045-a091-4042-ae0c-d96ea58c6245",
   "metadata": {},
   "source": [
    "通过命令`ollama help`可以查看全部的可支持的指令。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fffca5c-c8e5-4922-a16d-52d5df4e83c2",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241011144419942.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4ec85f-3c32-4bdb-90e6-c6e7a3612fc8",
   "metadata": {},
   "source": [
    "#### 1.6.3 可使用模型查看"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebee4c6-11e2-487b-85ac-505f9069e892",
   "metadata": {},
   "source": [
    "通过命令`ollama list`即可查看全部的可启动模型列表。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4489112d-f543-40de-8262-88531d5abd9d",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241011115126172.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de54a55-02f4-421d-856d-06927158966d",
   "metadata": {},
   "source": [
    "#### 1.6.4 管理模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec5c4c5-3a6b-46c2-9956-2a56efcb8e3c",
   "metadata": {},
   "source": [
    "通过命令`ollama rm 模型名称`可移除对应模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b800d7d-cd0c-4fc0-91b2-eb4371d75f38",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241119105425144.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764d3035-522f-44f9-9788-01aca8714386",
   "metadata": {},
   "source": [
    "### 1.7 应用进阶：Ollama实现API调用模型办法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42952f61-9ea1-4794-9956-b12ef03a8cb3",
   "metadata": {},
   "source": [
    "同时Ollama还支持进行API调用，通过这种方式可以实现服务器-主机终端的方式进行模型推理，通过这种方式更适合开发者进行对应模型的功能开发。\n",
    "\n",
    "以下是使用RestFul API办法快速启动Ollama进行推理的流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3435f05b-130c-4416-984a-531d7a437da7",
   "metadata": {},
   "source": [
    "在部署好ollama以及需要的大模型的服务器上通过指令`OLLAMA_HOST=0.0.0.0 ollama serve`启动ollama的远端推理服务。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2f2b519-15e9-48a2-b766-b1702f8b40bc",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/5e2353f7465697ea24d7417fb518ce4.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282cf7b4-46a8-46fa-9655-d9227370f819",
   "metadata": {},
   "source": [
    "模型启动之后可以通过指令`lsof -i -P | grep ollama`来进行进程监测，需要住哟的是TCP后面的信息须有*号才能在局域网中进行部署，而11434是Ollama默认的端口地址。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d48b002-8a08-43f9-ba6b-5115b9c6ec4b",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/353f98d429b98d63b6d118ff1ba9896.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8342c9-28c5-4d64-a8bf-35232c658292",
   "metadata": {},
   "source": [
    "在完成Ollama服务端启动之后，通过`ollama run qwen2.5-coder:32b`便可启动模型的API的推理服务，首次执行该指令会下载模型，之后便会直接启动推理流程。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "460faeb9-aa32-443c-b9ee-9073981fac7c",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241113101311118.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02314449-fc36-49d1-a6f6-400009941a76",
   "metadata": {},
   "source": [
    "- 接下来的操作在需要调用API的终端上进行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6948e808-ed1e-4229-ae10-b720c3f9099a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-ollama\n",
      "  Downloading langchain_ollama-0.2.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in c:\\users\\86130\\anaconda3\\lib\\site-packages (from langchain-ollama) (0.3.1)\n",
      "Requirement already satisfied: ollama<1,>=0.3.0 in c:\\users\\86130\\anaconda3\\lib\\site-packages (from langchain-ollama) (0.3.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\86130\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-ollama) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\86130\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-ollama) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.117 in c:\\users\\86130\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-ollama) (0.1.123)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\86130\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-ollama) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\86130\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-ollama) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\86130\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-ollama) (8.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\86130\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-ollama) (4.12.2)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in c:\\users\\86130\\anaconda3\\lib\\site-packages (from ollama<1,>=0.3.0->langchain-ollama) (0.27.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\86130\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\86130\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\86130\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\86130\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\86130\\anaconda3\\lib\\site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\86130\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\86130\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain-ollama) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\86130\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.117->langchain-core<0.4.0,>=0.3.0->langchain-ollama) (3.10.7)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\86130\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.117->langchain-core<0.4.0,>=0.3.0->langchain-ollama) (2.31.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\86130\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.0->langchain-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\86130\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.0->langchain-ollama) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\86130\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.117->langchain-core<0.4.0,>=0.3.0->langchain-ollama) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\86130\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.117->langchain-core<0.4.0,>=0.3.0->langchain-ollama) (2.0.7)\n",
      "Downloading langchain_ollama-0.2.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: langchain-ollama\n",
      "Successfully installed langchain-ollama-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1dea977-a33a-4884-842c-669069b5ae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2e636b7-34a8-47cf-a69d-ec90612aaeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "coder_llm= ChatOllama(\n",
    "    base_url =\"http://192.168.110.131:11434\", # 注意:这里需要替换成自己本地启动的endpoint地址\n",
    "    model=\"qwen2.5-coder:32b\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af141b99-9f69-45d5-94be-4b7ea1d230ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46589635-42f3-48a1-8d49-ffce770aedf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "# Definition for singly-linked list.\n",
      "class ListNode:\n",
      "    def __init__(self, val=0, next=None):\n",
      "        self.val = val\n",
      "        self.next = next\n",
      "\n",
      "def addTwoNumbers(l1: ListNode, l2: ListNode) -> ListNode:\n",
      "    dummy_head = ListNode(0)\n",
      "    current = dummy_head\n",
      "    carry = 0\n",
      "    \n",
      "    while l1 is not None or l2 is not None:\n",
      "        x = l1.val if l1 is not None else 0\n",
      "        y = l2.val if l2 is not None else 0\n",
      "        total = carry + x + y\n",
      "        carry = total // 10\n",
      "        current.next = ListNode(total % 10)\n",
      "        current = current.next\n",
      "        \n",
      "        if l1 is not None:\n",
      "            l1 = l1.next\n",
      "        if l2 is not None:\n",
      "            l2 = l2.next\n",
      "    \n",
      "    if carry > 0:\n",
      "        current.next = ListNode(carry)\n",
      "    \n",
      "    return dummy_head.next\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(coder_llm.invoke(\"帮我写一个用python语言实现以下的代码，直接输出代码内容即可，在理解文本内容后进行输出：给你两个非空的链表，表示两个非负的整数。它们每位数字都是按照逆序的方式存储的，并且每个节点只能存储一位数字。请你将两个数相加，并以相同形式返回一个表示和的链表。你可以假设除了数字 0 之外，这两个数都不会以 0 开头。\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a735922-f9bb-408a-947a-efad9e23d42f",
   "metadata": {},
   "source": [
    "通过这种方式，用户可以在终端中便捷地使用 Ollama 进行推理，尤其适合在机房等需要服务器支持的环境中进行开发和测试。借助 Ollama 框架的轻量化部署优势，即使在高负载或硬件资源有限的场景下，也能实现大模型的高效推理。这种方式不仅简化了开发者在服务器环境下的模型调用流程，还提升了工作效率，使得在数据中心、实验室和远程服务器上进行模型推理和调试变得更加便捷和高效。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f735c2fd-c3f7-4e1a-9c93-ed126242f952",
   "metadata": {},
   "source": [
    ">更多Ollama的API参数和使用方法，可参考 API 文档https://github.com/ollama/ollama/blob/main/docs/api.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6a9607-303a-44ac-b2d3-b850691d2b85",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4738933-81f3-47c0-9ca0-cf3441cda252",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c144a3-8d19-4858-b3a1-4dd804db2aa2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1368991-3662-46c3-bbb9-0f5dd4525877",
   "metadata": {},
   "source": [
    "## 2. Ollama在Windows环境部署和启动多模态模型llama3.2Vision全流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba68868-ed09-40d6-a76d-2e93c7b62d46",
   "metadata": {},
   "source": [
    "### 2.1 配置推荐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b93bbdf-62af-493f-8ae0-06ef0b528326",
   "metadata": {},
   "source": [
    "1. 操作系统：推荐Windows 10 22H2或更新版本，或Windows 11.\n",
    "2. 显卡：推荐NVIDIA RTX 30系列或更高版本，或 AMD Radeon 显卡。一般来讲一张24G的显卡是可以运行Ollama量化的70B模型的。\n",
    "3. 内存：至少16GB的RAM，在运行更大的模型的时候需要更多内存。\n",
    "4. 硬盘空间：在每个模型的支持列表中会显示安装所需的空间大小，以本次介绍的两个模型的参数为例：11b大小的模型需要7.9GB的空间、90b的模型需要55GB的空间。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486205b7-a22a-4781-bd45-60845a333d2c",
   "metadata": {},
   "source": [
    "- 如何查看自己的显卡性能"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dafab49-f787-4c19-a61f-fda9b59c2f01",
   "metadata": {},
   "source": [
    "1. 打开任务管理器：\r\n",
    "   - 按下 `Ctrl + Shift + Esc` 或右键单击任务栏选择 **任务管理器**。\r\n",
    "2. 查看显卡信息：\r\n",
    "   - 点击 **性能** 选项卡。\r\n",
    "   - 在左侧找到 **GPU 0** 或 **GPU 1**（如果有多块显卡）。\r\n",
    "   - 右侧会显示显卡的详细信息，包括型号、GPU 使用率、显存、驱动版本等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c5b243-a45f-4c50-bed2-48a27a5c24ae",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241120110903937.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cce170-a4ec-4f71-9eb8-3a671cd102ff",
   "metadata": {},
   "source": [
    "### 2.2 在Windows环境下进行Ollama部署使用多模态大模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fa4f71-1749-423c-82cf-89f6eb24f490",
   "metadata": {},
   "source": [
    "#### 2.2.1 Ollama的下载&安装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da75351-2353-4479-93ee-6eef1e1f23f0",
   "metadata": {},
   "source": [
    "Ollama同样支持在Windows环境下进行部署下载，使用此方法下载意味着你可以无需调整任何硬件设备直接在你的主机上实现Llama 3.2模型的安装部署和推理使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df698362-60b1-47b6-9016-942e1b9d7009",
   "metadata": {},
   "source": [
    "首先要下载Windows版的Ollama文件，进入官网选择下图的内容进行下载："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db435e8-adf9-48b6-b70f-57b573299c44",
   "metadata": {},
   "source": [
    "https://ollama.com/download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a0bf75-2c16-41dc-8bba-f07069d9060e",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241122103650614.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa7f906-c2fc-476e-a3d3-289edd0e1e7d",
   "metadata": {},
   "source": [
    "当然，你也可以直接在浏览器中搜索关键词`ollama`,按照图中的实例点击进入官网亦可。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58a6b0a-3215-4e25-bab9-3530665a6c6b",
   "metadata": {},
   "source": [
    "进入官网后点击正下方的Download按钮，进入下载页面。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5399f2-7de9-48cd-9f6e-a8eeb8c1e9ad",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241122103750688.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d7d2cc-1de1-4693-a0cb-8e78b9b632f2",
   "metadata": {},
   "source": [
    "确保是在Windows环境的下载方式，即可点击Download for Windows开始下载。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358ee613-0463-469b-bc0f-e8205de5918c",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241122104025801.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56acad12-6d5a-45d4-ad0e-77d8d22485fd",
   "metadata": {},
   "source": [
    "开始下载后便会在右上角下载/安装栏出现下图图标，安装完成后可以在下载栏或下载文件夹（你的默认下载路径）找到该文件。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9990b8-e3ba-4d54-852a-97565b7f93e6",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241122104054625.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2011475-9d7d-4320-9eb3-6db2928ac77e",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241122104247946.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdab06e-c061-4aaa-b13e-13f5122ae1b1",
   "metadata": {},
   "source": [
    "下载完成后在对应文件夹双击打开安装包完成安装流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf439b0-2dde-4c28-a6eb-18cbbadc9bf6",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241122104458527.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae61354-a166-4d5d-9fd7-c069494d1a74",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241122104617955.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf315234-0a2a-41eb-8e3f-882606593f2a",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241122104633268.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84521cda-6f2c-4f87-8b64-634fabe84571",
   "metadata": {},
   "source": [
    "安装完成后会有如下提示："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f9f22e-e4f3-45bb-8312-e60686509824",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241122104722058.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67fd0b6-3021-43ed-817d-a730ee4f1f6a",
   "metadata": {},
   "source": [
    "#### 2.2.2 Ollama下载模型路径修改"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3aa17d-83d2-4858-b2b2-5e089b80a8b0",
   "metadata": {},
   "source": [
    "框架和模型默认路径都是C盘，为了主机内存管理方便，可以通过以下步骤来实现模型下载地址的切换。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ea3a0b-3fb2-4d70-a3d4-b4b18199e4e0",
   "metadata": {},
   "source": [
    "1.在桌面下方搜索栏输入高级系统设置并进入。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f674233-bda8-4af7-90c0-fa8679ee06b9",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241016103219333.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ca377d-a0a1-4357-b6d9-d8de97ebb26d",
   "metadata": {},
   "source": [
    "在系统设置中找到`高级`的标签，点击下方的环境变量选项。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabacd61-ad5a-48d3-aad7-7eb5c520a239",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241016103304360.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac86760-e3fe-46b9-81e9-446b66a411e4",
   "metadata": {},
   "source": [
    "在系统变量栏点击新建，变量名设置为OLLAMA_MODELS,变量值设置为你想要的路径位置，这里设置为D:\\Ollama\\models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1557a489-ef83-4872-91c8-54682bacf02e",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241016103947874.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0f937d-e332-4e77-ac61-953b93ae7d2d",
   "metadata": {},
   "source": [
    "设置好路径之后可以在命令行中进行检查，通过以下命令实现："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2481dfa-3278-4947-9672-ac1453fd804e",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241016104050213.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6223b19d-e804-486b-8b7c-2d33d17c7044",
   "metadata": {},
   "source": [
    "#### 2.2.3 使用Ollama实现多模态模型Llama3.2Vision安装启动全流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37318c8-0a8e-452b-a06e-875dd95ba472",
   "metadata": {},
   "source": [
    "启动Ollama可以直接在Windows的命令行中实现，通过win+R键启动cmd命令，打开命令行终端。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b35c139-ffb2-487f-9215-457d8c429e79",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241122104853825.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3914b362-d217-4c08-aed5-2e7a3708c837",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241122104932627.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3418ab25-a94a-41bb-99b7-4e5285ef4e80",
   "metadata": {},
   "source": [
    "可以通过输入指令`ollama -v`来检查是否成功部署，如果通过返回版本号信息则成功。Ollama支持以下的命令操作，关于这些指令的具体含义可以查看第一节Ollama快速入门的内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b72377-8ba9-4556-91ee-f9d48aec3470",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241122105107446.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b480090-1797-4cf3-bcb0-13b965dff473",
   "metadata": {},
   "source": [
    "- llama3.2Vision多模态模型的部署和使用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9a8013-efd7-403c-9241-d15f6497f0b0",
   "metadata": {},
   "source": [
    "首先还是回到Ollama的官网，搜索关键词`llama3.2-vision`可以找到对应模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6261d94-1497-445f-8602-fcd22932d5d6",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241122105449949.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776754fe-7173-4c92-8536-3cdee7a76100",
   "metadata": {},
   "source": [
    "点击进入模型信息页面，在下图左侧部分选择你想要下载的具体参数，并在右侧将下载/启动代码进行复制。（本例用11b参数模型进行演示）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f0a0fd-f7c1-4a8d-bf8a-3f5fe784ba6d",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241122105740297.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde19e1c-d14c-4be0-b811-afbff168bd52",
   "metadata": {},
   "source": [
    "随后回到命令行终端，将刚刚复制的代码输入，便可执行模型的下载。需要注意的是，模型的下载和启动命令都是一样的，也就是说如果下载完成，之后再次输入该命令会直接启动本地的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36785515-29a3-47cd-8450-d13f5c3f4357",
   "metadata": {},
   "source": [
    "ollama run llama3.2-vision:11b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f867f06-e257-4a70-99b9-267376e38582",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241122113553734.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6013e2b-25f5-40e9-af97-d0a3bcb68c95",
   "metadata": {},
   "source": [
    "当显示success并出现>>>图案的时候说明安装成功，可以进行推理使用了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f965cf9f-301b-49cf-9ef7-15d39f7da6b9",
   "metadata": {},
   "source": [
    "### 2.3 Ollama框架启动llama3.2-vision:11b效果简单评测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21569bc3-ee5b-4503-b5e8-03247638194f",
   "metadata": {},
   "source": [
    "- 简单对话"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1ea8fb-63b3-4b0c-9c9a-73770339459f",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241122113639436.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3717d7f5-41e9-4aa9-a576-4e0c7aeb008d",
   "metadata": {},
   "source": [
    "- 中英双语对话"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7d2fd1-782e-4579-be81-272037004ea5",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241122113733950.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38d5789-874f-4510-b572-0960c9c4d35d",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241122113822815.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09372dd-4a7f-4472-9bef-c9fe7272dd19",
   "metadata": {},
   "source": [
    "- 识别图像--jpg格式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c185f146-4b4f-4a9d-a119-baec771ff2ca",
   "metadata": {},
   "source": [
    "llama3.2-vision:11b支持识别图像信息，并以文字类信息进行返回，具体的识别方法：通过读取本地图像文件的路径，并根据输入的文字提示词进行推理并返回结果。如下图，可以先对需要进行分析的图像进行`复制文件地址`操作，然后将对应信息输入到对话框中。llama3.2-vision:11b识别信息的方式是文件地址信息+空格+文本信息。信息前后的顺序不影响模型推理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dded69c-dbc9-422b-a0d4-77359557629e",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241122114356572.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99c3176-0e13-4391-a73e-13a7ab171597",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241122114240606.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cf1085-bdeb-4a38-b1ce-434ab275fd5b",
   "metadata": {},
   "source": [
    "我先选择了一的.jpg的表情包图像进行推理，在不加提示词的情况下可见模型的回复是比较随意的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3df8f8-abbe-4947-b62a-fdb1faff5b84",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241122114031745.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3c6c93-9ecc-480d-ac12-1f1d22b7c6cc",
   "metadata": {},
   "source": [
    "当适当添加提示词的时候，模型回复的信息按照要求变得详细，但llama系列的模型都是以英文为主要语料进行训练的，所以不免会倾向回复英语信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baba3f9f-6a12-4671-8a24-7128b42c5176",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241122114210606.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fef59f8-f021-4c53-b338-f015be2d8d9b",
   "metadata": {},
   "source": [
    "当我再次修改提示词的时候，可见已经可以按照要求用中文详细的描述信息了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1ce609-6292-44e8-bec3-9e1c5d68f872",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241122114220872.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad96ab96-3afa-4c02-94fc-0a23a69e7333",
   "metadata": {},
   "source": [
    "- 识别pgn文件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c536574-54bc-4f67-a85b-af1baa09c319",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241122114255630.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107141e4-4595-4cc3-8897-b53e1f471826",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241122132044641.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc55818-e9bd-414b-b4f9-31ea0bd6db56",
   "metadata": {},
   "source": [
    "该推理方法同样支持.png格式的图片分析，在这个测试中，我输入了一个流程图并让其识别其中的关键词，返回结果十分准确，可见其OCR能力足够优秀。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5d1069-634e-4f27-8e59-37e17ba64629",
   "metadata": {},
   "source": [
    "- 显存消耗"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54041a66-98d3-43da-9f73-d1664ea37baf",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241122113614718.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880297e7-b688-47cb-872f-dc3c231cb3c9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da0f5794-cf5b-467a-b131-fe49c3dcef1a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d15c1cc-b6bb-409b-bfa4-0a1a1df58c11",
   "metadata": {},
   "source": [
    "## 3. Ollama在linux环境部署和启动多模态模型llama3.2Vision全流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccc1e4a-7b08-4217-bfb6-b79323524352",
   "metadata": {},
   "source": [
    "### 3.1 配置推荐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49158010-6cd1-4375-aa49-f92d70d339b2",
   "metadata": {},
   "source": [
    "Linux系统：\n",
    "1. 操作系统：推荐Ubuntu 22.04或更高版本，或其他支持的Linux发行版。\n",
    "2. 显卡:推荐使用 NVIDIA GPU（如 T4、V100、A10 等），或 AMD GPU，至少需要 8GB 的显存。但具体的显存需要随模型参数增大而增大。\n",
    "3. 内存：至少 16GB 的 RAM，在运行更大的模型的时候需要更多内存。\r",
    "4. \n",
    "硬盘空间：在每个模型的支持列表中会显示安装所需的空间大小，举个例子：11b大小的模型需7.98GB的空间、90b的模型需要55GB的空间。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240b5524-f11c-4896-a633-5fc9b10f52f0",
   "metadata": {},
   "source": [
    "> 本次介绍使用Ollama启动`Llama3.2-vision`的两个参数的版本需要的显存如下：`Llama3.2-vision:11b`需要8G的显存，`Llama3.2-vision:90b`的模型需要64G的显存。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73883d1d-2b02-45d1-bed1-7d0213f46ee6",
   "metadata": {},
   "source": [
    "### 3.2 具体流程：使用Ollama实现llama3.2Vision下载和启动"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb79a48a-ad6c-4a03-bc31-b06c029cd9b5",
   "metadata": {},
   "source": [
    "首先我们在命令行中输入以下信息实现进行Ollama的安装（如已经按照执行该命令会实现软件更新）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95f954f-e180-4d00-a24b-0316a67346d8",
   "metadata": {},
   "source": [
    "下载Ollama的指令如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a65dc5-875c-4b9f-8eea-13c7c398759d",
   "metadata": {},
   "source": [
    "```\n",
    "curl -fsSL https://ollama.com/install.sh | sh\r\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf5d35e-78a7-4a34-aecb-f7b4a8a26f1e",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241111104241685.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cdaab2-7a0f-4fc2-bc5d-c12ef5d4255a",
   "metadata": {},
   "source": [
    "下载完成后检测,如果返回版本号则说明成功下载：\n",
    "```\n",
    "ollama -v\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedc109d-11fa-46b0-8b01-8d17abc6cd22",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241120173953653.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3567fa6f-c935-4927-8fc4-613b5b46bc9b",
   "metadata": {},
   "source": [
    "**下载模型**\r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17b33d0-8647-4a02-8716-bc4ca99e0bce",
   "metadata": {},
   "source": [
    ">以下是进行Llama3.2-vision:90b模型进行下载&运行演示。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc732277-4f22-49e2-815e-857b0f1b859a",
   "metadata": {},
   "source": [
    "在终端中执行命令 `ollama run llama3.2-vision:90b` ，即可下载该模型。模型下载完成后，会自动启动大模型，进入命令行交互模式，直接输入指令，就可以和模型进行对话了对应参数的模型的下载方式可以通过在Ollama官网查看到下载指令。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45653c04-8447-44a3-8463-d7d6b51a60f9",
   "metadata": {},
   "source": [
    "官网模型挂载地址：https://ollama.com/library/llama3.2-vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c13d14-cd54-416a-b570-6b684786e079",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241119170956032.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340f7961-5b45-4ea7-adae-843f52f79edb",
   "metadata": {},
   "source": [
    "完成下载后会直接进入模型启动状态，如果退出或刷新界面，再次输入指令 `ollama run llama3.2-vision:90b` 即可启动对应模型。\n",
    "可以看到推理所需的计算资源相对均匀的分布在每张工作显卡上。（实际的显存消耗会随着推理复杂度增高而变大）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410fbcf2-bb0a-41a2-a612-e4cb9a09a11c",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241119171042382.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb9353f-4e12-4d34-beb8-6fb22a93432f",
   "metadata": {},
   "source": [
    "通过文字+本地图像路径地址可以实现模型的多模态调用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5ed9a4-f254-42ad-bb47-a6788da9513e",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241119171137493.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572a2fb9-3853-43ac-96e9-330620990772",
   "metadata": {},
   "source": [
    ">使用 /bye 退出正在进行的 Ollama进程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4943c307-668f-4625-b118-7359e073370d",
   "metadata": {},
   "source": [
    "### 3.3 详细评测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6775729-c1f0-4393-9dd2-6ce81ed51f65",
   "metadata": {},
   "source": [
    ">总评：模型支持中英双语的对话，不过尽管Llama3.2系列模型的中文能力已经有了很大的提升，但是对于图像上的中文的理解能力不是很好，但是对于手写文字识别、OCR识别、图像识别能力均达到可用水平。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af91d773-485e-4c9d-87e7-4258e7383ace",
   "metadata": {},
   "source": [
    "下面是全部的测评展示："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba52bab5-ea52-43cd-be3b-e51d91c73765",
   "metadata": {},
   "source": [
    "- 图像识别："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e9512e-3697-4e07-aa62-bbe3cef5ae01",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241120182031825.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e62902-083d-459b-83fa-98ff639911a3",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241111131133679.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042d6ff2-6cf4-4d62-ba5f-781c547b263f",
   "metadata": {},
   "source": [
    "llama3.2-vision模型可以很好的识别动物图像，并且识别出其中的细节，支持中英文双语的回答。经过测试，模型支持.png , .jpg 格式的图片输入。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d1251b-9f37-43d6-9e9c-bc5d1d922a2f",
   "metadata": {},
   "source": [
    "- 手写文字识别"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20372f4-490e-4162-88b3-49ed75577aa9",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241120182237737.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c782212a-9263-4bf0-8a5a-6232171f5496",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241119172544258.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae82a24e-e80e-4b93-919c-2fe1fe483f8d",
   "metadata": {},
   "source": [
    "llama3.2-vision模型可以识别手写文字（英文）的信息并给出准确描述，未来支持更多语言的版本也许会随着Llama系列模型的更新而逐步得到支持。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370f8ec8-5c82-439a-8be6-22e07267fea1",
   "metadata": {},
   "source": [
    "- OCR(Optical Character Recognition)光学字符识别"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e675e64-6272-434d-b10f-18f9318e38df",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241120182922372.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f53fa1-280e-4ffd-95c1-2d3414f7e32e",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241119173109235.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f419b599-b9d8-4bf6-bf6e-c0e48bd584d4",
   "metadata": {},
   "source": [
    "对于文本截图等信息，llama3.2-vision模型可以准确的识别，并完成详细准确的描述。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac473b3-da17-4d96-a517-c0ba1407cf6c",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241120183236463.png\" width=60%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01df7b0-76ec-4469-8622-2784dbbb624a",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241111130748887.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f6dd3c-f1c3-4854-9302-9b3645123465",
   "metadata": {},
   "source": [
    "经过测试，虽然llama3.2-vision对于简体中文的理解能力不佳（常识别成Chinese Characters），但是对于繁体中文的信息有一点识别能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fb34f5-2ebd-4f42-b91b-0f433e97e2b5",
   "metadata": {},
   "source": [
    "- 图表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ccfb55-6ddb-4514-b584-b78e4f3fefb3",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241120184216273.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eec063-d474-42a7-afb0-2e8b69af0cea",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241120184207239.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52faf5c4-b73e-42cc-93a4-92f3d7a76c1d",
   "metadata": {},
   "source": [
    "llama3.2-vision可以很好的识别出图表、表格截图中的信息，只要图像尺寸、清晰度合适便可以很好的识别出图表中的数字信息，但是过于复杂的表格应当增加prompt来强化指引，使其输出更符合要求。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d2a0ec-32b9-46fc-bb19-e029082588ee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f429d8af-ef45-453a-86ef-108d1d4ffa23",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "515e4aa3-0d84-4e80-a4ae-05f262a063c7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d1c07c3-62fa-424f-b155-b1269233e7be",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc22dfd3-e362-4c4d-82e8-cdff8818f655",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd014f1d-1a9f-40b7-9501-fb57ed55ad64",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96c29e8f-10bd-4c12-82c5-828c65abec28",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
