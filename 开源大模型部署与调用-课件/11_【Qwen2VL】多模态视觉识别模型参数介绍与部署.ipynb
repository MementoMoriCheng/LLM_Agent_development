{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9873922-be7c-4da1-bff6-1de3e422a4eb",
   "metadata": {},
   "source": [
    "# <center> 多模态大模型Qwen2VL安装部署与调用教程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f027d3-e147-4082-a77a-95388d8bd6d0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c172f8ae-0c96-4fc7-9d83-8045bccb742e",
   "metadata": {},
   "source": [
    "## 模型介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c499bc-978b-4a1d-a6e3-9954f6dc2514",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241218161824567.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff08af8-1351-495c-a080-27cd0bedc88f",
   "metadata": {},
   "source": [
    "Qwen2VL是由阿里团队开源的最新图像、视频识别的多模态大模型。该模型支持对各种分辨率和比例的图像的理解并返回文本对话，并具有基本的结合视觉的文本理解能力、数学推理能力、多语言能力。Qwen2VL可以理解 20 分钟以上的视频，以进行高质量的基于视频的问答、对话、内容创建等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f41901-2ea0-468e-a400-04c6163f2931",
   "metadata": {},
   "source": [
    "除了英文和中文外，Qwen2-VL 现在还支持理解图像中不同语言的文本，包括大多数欧洲语言、日语、韩语、阿拉伯语、越南语等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ccece1-1845-4cf1-930c-96a9a03ced5d",
   "metadata": {},
   "source": [
    "本次开源的模型包括2B、7B、72B参数的模型，运行对应模型大致需要的显存分别至少为6G、34G、144G。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b163c82-c4b7-4cca-ad3b-8aee2ab61fee",
   "metadata": {},
   "source": [
    "- 图像能力测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebd141d-6e80-4bbc-a0f8-57cc36535369",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241218161622902.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c5c3ae-cd25-4140-9410-2fd3330e20f4",
   "metadata": {},
   "source": [
    "- 视频能力测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a2aa3e-7c65-48af-bef8-0d9aabb7e344",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241218161714876.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b976a60c-81a2-42fb-8601-51e4e2100fb3",
   "metadata": {},
   "source": [
    "## 本地部署流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5915c55d-0a39-41ed-9c1c-abc0073a82a9",
   "metadata": {},
   "source": [
    "- **Step 1. 创建conda虚拟环境**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4061c302-f6f0-48d3-90a6-d80ca4d4aa5e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;Conda创建虚拟环境的意义在于提供了一个隔离的、独立的环境，用于Python项目和其依赖包的管理。每个虚拟环境都有自己的Python运行时和一组库。这意味着我们可以在不同的环境中安装不同版本的库而互不影响。根据官方文档信息建议Python版本3.10以上。创建虚拟环境的办法可以通过使用以下命令创建：\n",
    "\n",
    "```bash\n",
    "# qwen2_5 是你想要给环境的名称，python=3.11 指定了要安装的Python版本。你可以根据需要选择不同的名称和/或Python版本。\n",
    "\n",
    "conda create -n qwen2_5 python=3.11\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d2d6ad-4c38-4f23-b84b-02eff93a52a7",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241022152113279.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a981d7-54d7-41b3-8deb-89442665ea2c",
   "metadata": {},
   "source": [
    "&emsp;&emsp;创建虚拟环境后，需要激活它。使用以下命令来激活刚刚创建的环境。如果成功激活，可以看到在命令行的最前方的括号中，就标识了当前的虚拟环境。虚拟环境创建完成后接下来安装torch。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d8c887-59b1-4f05-80f6-166945ff4e99",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241023112135370.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02d756e-1c1f-49ae-95a5-47728569368c",
   "metadata": {},
   "source": [
    "&emsp;&emsp;如果忘记或者想要管理自己建立的虚拟环境，可以通过conda env list命令来查看所有已创建的环境名称。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811d02b6-dd54-428c-8502-84483b311908",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20240928143512354.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd24ebf-340b-4fb6-9c5e-3c53410bbb88",
   "metadata": {},
   "source": [
    "&emsp;&emsp;如果需要卸载指定的虚拟环境则通过以下指令实现：\n",
    "```\n",
    "conda env remove --name envname\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281d4823-85be-45c4-b0b3-a4f86686707f",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20240928143643575.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fb192c-0dfb-43fb-91bc-09d26144d062",
   "metadata": {},
   "source": [
    "- 需要注意的是无法卸载当前激活的环境，建议卸载时先切换到base环境中再执行操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc618ee5-946f-431f-a9d7-29561eb09d6f",
   "metadata": {},
   "source": [
    "- **Step 2. 查看当前驱动最高支持的CUDA版本**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5787170d-2b19-47c2-bd2a-314636740e2f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;我们需要根据CUDA版本选择Pytorch框架，先看下当前的CUDA版本：\n",
    "```\n",
    "nvidia -smi\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37924ed6-c400-4eef-8da6-4f740947ded7",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20240924161818464.png\" width=70%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02969ec-1f08-4ef1-9aa1-2bf4e6ca22e1",
   "metadata": {},
   "source": [
    "- **Step 3. 在虚拟环境中安装Pytorch**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae2311c-e95c-4ecd-ab8d-d30a7d2deb87",
   "metadata": {},
   "source": [
    "&emsp;&emsp;进入Pytorch官网：https://pytorch.org/get-started/previous-versions/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcf5151-f8fc-43a2-9549-bbd1b3277526",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://muyu001.oss-cn-beijing.aliyuncs.com/img/image-20240103163206436.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f816e428-8404-4523-82a1-3f60c80e420e",
   "metadata": {},
   "source": [
    "&emsp;&emsp;当前的电脑CUDA的最高版本要求是12.2，所以需要找到不大于12.2版本的Pytorch。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2678bbb7-91ed-40b1-b8ea-35a7ebf8683f",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://snowball101.oss-cn-beijing.aliyuncs.com/img/202401041455184.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e1278a-572c-4ba2-a24e-6cb5301c8ac4",
   "metadata": {},
   "source": [
    "&emsp;&emsp;直接复制对应的命令，进入终端执行即可。这实际上安装的是为 CUDA 12.1 优化的 PyTorch 版本。这个 PyTorch 版本预编译并打包了与 CUDA 12.1 版本相对应的二进制文件和库。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c183fc-66f5-4812-907e-9b01691f5a1f",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241022153422264.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6abab1-ad0f-4640-b82e-523300aea33b",
   "metadata": {},
   "source": [
    "- **Step 4. 安装必要的依赖**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d28c8a3-9beb-4f95-bba2-89710ffb628d",
   "metadata": {},
   "source": [
    "Transfomers是大模型推理时所需要使用的框架，通过以下指令可以下载最新版本的Transfomers："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4307eaf0-9987-410e-8f6e-3bcaf16db33d",
   "metadata": {},
   "source": [
    "pip install transformers -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feabadf-e80d-405e-b4a8-92a3c7b8eade",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241022154907510.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0157f4b8-8d79-4eca-b9ee-2f96af9e49be",
   "metadata": {},
   "source": [
    "安装完成后可以通过以下命令检查是否安装：\n",
    "```\n",
    "pip show transformers\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097ec0de-91b2-4938-b709-5bf82074a82b",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241022154927444.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d855bc-f6f3-4e14-9c19-50fbc0004272",
   "metadata": {},
   "source": [
    "接下来需要安装下载工具modelscope以及接下来要下载脚本的依赖accelerate，通过以下代码进行对应工具的部署："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf4f4e3-237e-43d0-ae9c-c5c3da30cd51",
   "metadata": {},
   "source": [
    "pip install modelscope\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f142088-fba4-4206-8096-4f45de33dded",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241022160253024.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d2fad9-d157-4638-8216-fa5ecf4bb888",
   "metadata": {},
   "source": [
    "pip install accelerate>=0.26.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe1b0bc-1a5a-40e3-b5f4-d43fe7103392",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241022162830644.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39a1a8b-edfc-481a-8848-a9d28119ff6a",
   "metadata": {},
   "source": [
    "安装qwen_vl_utils库来加速模型推理："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8a2fde-e9ae-4b10-aa38-ab8e560fd476",
   "metadata": {},
   "source": [
    "pip install qwen-vl-utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee286993-d65f-4928-9105-fc171243924f",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241212102932796.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b563fb-d7c4-4ce2-9427-47e59232fbd9",
   "metadata": {},
   "source": [
    "- **Step 5. 下载模型权重**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b497ad9-14ad-4bc2-90b4-75a6a66bdbb0",
   "metadata": {},
   "source": [
    "在下载模型权重之前，先为之创建合适的文件夹。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af94624-1a32-4f30-9881-989937475092",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241212102738540.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2434df0a-6c1a-4aa6-b619-7108a671d691",
   "metadata": {},
   "source": [
    "本流程选择在modelscope平台下载Qwen2VL模型，这种方式在国内安装部署大模型非常便捷。通过以下命令开始下载，需注意最后的一个参数要修改成你要存放模型的文件夹。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5747e6f2-0fa9-4fc3-a0d5-83980f392eb3",
   "metadata": {},
   "source": [
    "modelscope download --model Qwen/Qwen2-VL-7B-Instruct  --local_dir ./dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16e4d80-a20b-4e65-a6b1-f334c440811c",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241212102749310.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c150d515-cd52-41e3-a77d-fd604ca065d7",
   "metadata": {},
   "source": [
    "## 本地调用测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1d9495-20ad-403a-b012-e285c4ca440c",
   "metadata": {},
   "source": [
    "#### 单图推理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d453650-8e7a-4a3f-a544-d40c12b87140",
   "metadata": {},
   "source": [
    "- 导入相关库"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c61bd45-d456-4df9-b599-94bdb7fadb4c",
   "metadata": {},
   "source": [
    "``` python\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from modelscope import snapshot_download\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f14f75-37dc-4320-87b4-ed9f297aa6ca",
   "metadata": {},
   "source": [
    "- 设置模型路径"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e4f9e0-a173-4109-9aac-626641fd4d48",
   "metadata": {},
   "source": [
    "```python\n",
    "model_dir = './model/dir'\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f91582a-c741-4b47-a278-0e0c14fe6818",
   "metadata": {},
   "source": [
    "- 实例化模型对象"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a11faf5-7772-4b12-adee-226a5a98ecb3",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\r\n",
    "    model_dir, torch_dtype=\"auto\", device_map=\"auto\"\r\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_dir)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e5b3c1-6a83-4337-b2cf-7318745ba007",
   "metadata": {},
   "source": [
    "- 创建消息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01af519c-b403-452d-a8b9-7be57b0a9b7d",
   "metadata": {},
   "source": [
    "```python\n",
    "messages = [\r\n",
    "    {\r\n",
    "        \"role\": \"user\",\r\n",
    "        \"content\": [\r\n",
    "            {\r\n",
    "                \"type\": \"image\",\r\n",
    "                \"image\": \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg\",\r\n",
    "            },\r\n",
    "            {\"type\": \"text\", \"text\": \"Describe this image.\"},\r\n",
    "        ],\r\n",
    "    }\r\n",
    "]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f843c4b4-3d54-4777-9f03-30cd476b6de1",
   "metadata": {},
   "source": [
    "- 进行推理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cd5bc1-53dd-4fe1-9e5f-f33950fa4caa",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=128)\r\n",
    "generated_ids_trimmed = [\r\n",
    "    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\r\n",
    "]\r\n",
    "output_text = processor.batch_decode(\r\n",
    "    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\r\n",
    ")\r\n",
    "print(output_text)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e885660-9c5a-47bd-8a9b-60862457f7fb",
   "metadata": {},
   "source": [
    "demo中进行测试的图片内容如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea31fe8-46b3-4996-8d23-4ca42fdf0ed2",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241217160156373.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9f9d12-fbf3-4763-8f4c-78cbfe9ddc80",
   "metadata": {},
   "source": [
    "执行完返回的结果会如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb88ae3-7df6-4072-a4f7-9346067d05d8",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241212103459661.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44853591-72f9-4fc0-8d10-9f5cf7c8e670",
   "metadata": {},
   "source": [
    "进行推理Qwen2VL：7B识别官方给出的demo图像消耗将近34G显存。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88887f6-b242-4282-a90e-55854584b221",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241212103934714.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d731d55a-aaf0-4c7b-8eee-b02561cd50b4",
   "metadata": {},
   "source": [
    "对于其他的信息源测试：无论是云平台挂载的图片还是本地图片识别，消耗的显存都不超过16G。以下图为例，这是一个展示模型性能的图表，将之用上述方法交付给Qwen2VL进行推理："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30af012e-b367-49a8-b1bd-89be9754a94a",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241219110535137.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c915b4-2632-488a-b1df-796c2a430cd9",
   "metadata": {},
   "source": [
    "推理返回结果如下"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccf1a93-9c18-4348-a8dc-625e5fe793b1",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241219111034020.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acaa2d9-452d-496f-b388-515d67afeddd",
   "metadata": {},
   "source": [
    "显存消耗情况如下，大约消耗16G。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183d0fea-7792-4dae-9113-71abe8f6ee25",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241219111235748.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57e8309-3945-4715-8168-65cc1f57d250",
   "metadata": {},
   "source": [
    "#### 多图推理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a021b8fd-382a-4f8e-9d70-54d9c2c07537",
   "metadata": {},
   "source": [
    "多图推理的代码如下，需注意修改本地启动模型路径和传入信息中的图像信息路径，其中，传入进行推理的图像支持本地.jpg / .png /.jpeg 格式的文件，也支持线上url格式的文件。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6793574d-71bf-4d97-b826-3b931403e795",
   "metadata": {},
   "source": [
    "- 多图推理的代码如下"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535580e3-a27e-4e0c-81c5-ddbf25784e02",
   "metadata": {},
   "source": [
    "```python\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from modelscope import snapshot_download\n",
    "model_dir = '/home/LLM/qwen2VL'\n",
    "\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "    model_dir, torch_dtype=\"auto\", device_map=\"auto\"\n",
    ")\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_dir)\n",
    "\n",
    "# Messages containing multiple images and a text query\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"image\": \"/home/LLM/llama3_2_v/mao.png\"},\n",
    "            {\"type\": \"image\", \"image\": \"/home/LLM/llama3_2_v/fm.png\"},\n",
    "            {\"type\": \"text\", \"text\": \"Identify the similarities between these images.\"},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Preparation for inference\n",
    "text = processor.apply_chat_template(\n",
    "    messages, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "image_inputs, video_inputs = process_vision_info(messages)\n",
    "inputs = processor(\n",
    "    text=[text],\n",
    "    images=image_inputs,\n",
    "    videos=video_inputs,\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "inputs = inputs.to(\"cuda\")\n",
    "\n",
    "# Inference\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=128)\n",
    "generated_ids_trimmed = [\n",
    "    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "]\n",
    "output_text = processor.batch_decode(\n",
    "    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    ")\n",
    "print(output_text)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9841c118-bda2-4af1-9226-b8f588456a64",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241120182031825.png\" width=40%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8db0f9-3fb7-45bf-b5b0-2c0d9e4432d3",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241120182922372.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad32650e-a98a-4d8a-8a37-e0ae12a81ee4",
   "metadata": {},
   "source": [
    "传入的图片一个是.jpg的，一个是.png的，返回内容如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67057b70-07f5-4c68-80f8-a020c45a4615",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241216151416494.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dd5310-bacc-42aa-a93b-251da4979b9c",
   "metadata": {},
   "source": [
    "Qwen2VL也支持中文问答."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50764721-a2bf-497a-96e8-21f1d9d7136d",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241216151838939.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1547af8-a0b2-44b3-b567-e9eabb461814",
   "metadata": {},
   "source": [
    "#### 视频推理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdb46a2-9bf7-4e7d-8dc7-b6d1c9aa4f1d",
   "metadata": {},
   "source": [
    "```python\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoTokenizer, AutoProcessor\r\n",
    "from qwen_vl_utils import process_vision_info\r\n",
    "from modelscope import snapshot_download\r\n",
    "model_dir = '/home/LLM/qwen2VL'\r\n",
    "\r\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\r\n",
    "    model_dir, torch_dtype=\"auto\", device_map=\"auto\"\r\n",
    ")\r\n",
    "\r\n",
    "processor = AutoProcessor.from_pretrained(model_dir)\r\n",
    "\r\n",
    "\r\n",
    "messages = [\r\n",
    "    {\r\n",
    "        \"role\": \"user\",\r\n",
    "        \"content\": [\r\n",
    "            {\r\n",
    "                \"type\": \"video\",\r\n",
    "                \"video\": \"/home/LLM/llama3_2_v/可灵-小老虎.mp4\",\r\n",
    "                \"max_pixels\": 360 * 420,\r\n",
    "                \"fps\": 1.0,\r\n",
    "            },\r\n",
    "            {\"type\": \"text\", \"text\": \"Describe this video.\"},\r\n",
    "        ],\r\n",
    "    }\r\n",
    "]\r\n",
    "\r\n",
    "# Preparation for inference\r\n",
    "text = processor.apply_chat_template(\r\n",
    "    messages, tokenize=False, add_generation_prompt=True\r\n",
    ")\r\n",
    "image_inputs, video_inputs = process_vision_info(messages)\r\n",
    "inputs = processor(\r\n",
    "    text=[text],\r\n",
    "    images=image_inputs,\r\n",
    "    videos=video_inputs,\r\n",
    "    padding=True,\r\n",
    "    return_tensors=\"pt\",\r\n",
    ")\r\n",
    "inputs = inputs.to(\"cuda\")\r\n",
    "\r\n",
    "# Inference\r\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=128)\r\n",
    "generated_ids_trimmed = [\r\n",
    "    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\r\n",
    "]\r\n",
    "output_text = processor.batch_decode(\r\n",
    "    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\r\n",
    ")\r\n",
    "print(output_text)\r\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f12cfce-ed72-4da3-b4c6-eba758662b1e",
   "metadata": {},
   "source": [
    "推理效果如下："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e70f081-33d9-4abf-a31c-24d7456627b1",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241216154755095.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d11d89-2356-4c3a-874f-d71719ff7cb2",
   "metadata": {},
   "source": [
    "返回中文推理结果："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2011f301-8c81-431c-b44f-e73d9f527b92",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241216154845653.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ade042-9434-4994-8ffb-0fdd416b314d",
   "metadata": {},
   "source": [
    "需要注意的是，视频仅支持输入本地路径的文件进行推理。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552f3753-0f3e-44fa-b12a-710a1aa19496",
   "metadata": {},
   "source": [
    "尽管 Qwen2-VL 在视觉任务中表现出色，但从第三方的视角来看，它仍然存在一些值得注意的局限性，这些限制对其在特定场景中的适用性提出了挑战。以下是一些主要的观察点：\n",
    "\n",
    "- 音频支持缺失\n",
    "Qwen2-VL 目前无法处理视频中的音频信息，因此在需要综合视觉与听觉的任务中，其表现可能受限。\n",
    "\n",
    "- 数据覆盖的时效性\n",
    "模型的图像训练数据更新至 2023 年 6 月，之后的事件或变化可能未被纳入，这限制了其在时效性要求较高场景中的应用能力。\n",
    "\n",
    "- 个人与知识产权识别能力的局限\n",
    "在识别特定人物或品牌方面，模型可能存在盲点，尤其是对于较少曝光的个人或冷门知识产权的识别，准确率仍需提升。\n",
    "\n",
    "- 复杂指令的理解能力\n",
    "当用户提出涉及多个步骤或需要复杂逻辑的指令时，Qwen2-VL 的理解与执行能力表现出一定不足，难以高效完成复杂任务。\n",
    "\n",
    "- 计数能力不足\n",
    "特别是在包含大量物体或复杂背景的场景中，模型对物体数量的识别往往不够精准，这可能对特定应用场景（如物流或物品清点）产生影响。\n",
    "\n",
    "- 空间推理能力的短板\n",
    "模型在推断 3D 空间中物体的相对位置时表现较弱，对于需要精确空间理解的任务（如建筑设计或机器人导航）仍有较大改进空间。\n",
    "\n",
    "这些局限性表明，尽管 Qwen2-VL 展现出强大的视觉能力，但其性能在某些特定领域仍有优化空间。未来若能针对这些短板进行持续改进，模型的应用范围和实用性将进一步拓宽。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be1c5ab-cc7b-42fb-9139-ce328e550708",
   "metadata": {},
   "source": [
    "### 推理Qwen2vl：2b模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e959bd-7da6-49b9-85fc-ef41fbc975c0",
   "metadata": {},
   "source": [
    "``` python\n",
    "\n",
    "import torch\r\n",
    "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor\r\n",
    "from qwen_vl_utils import process_vision_info\r\n",
    "\r\n",
    "model_dir = '/home/LLM/qwen2vl-2b'\r\n",
    "\r\n",
    "# 加载模型到 GPU0\r\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\r\n",
    "    model_dir, torch_dtype=\"auto\"\r\n",
    ")\r\n",
    "device = torch.device(\"cuda:0\")\r\n",
    "model = model.to(device)\r\n",
    "\r\n",
    "# 加载处理器\r\n",
    "processor = AutoProcessor.from_pretrained(model_dir)\r\n",
    "\r\n",
    "messages = [\r\n",
    "    {\r\n",
    "        \"role\": \"user\",\r\n",
    "        \"content\": [\r\n",
    "            {\r\n",
    "                \"type\": \"image\",\r\n",
    "                \"image\": \"https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg\",\r\n",
    "            },\r\n",
    "            {\"type\": \"text\", \"text\": \"Describe this image.\"},\r\n",
    "        ],\r\n",
    "    }\r\n",
    "]\r\n",
    "\r\n",
    "# 准备文本和视觉输入\r\n",
    "text = processor.apply_chat_template(\r\n",
    "    messages, tokenize=False, add_generation_prompt=True\r\n",
    ")\r\n",
    "image_inputs, video_inputs = process_vision_info(messages)\r\n",
    "\r\n",
    "inputs = processor(\r\n",
    "    text=[text],\r\n",
    "    images=image_inputs,\r\n",
    "    videos=video_inputs,\r\n",
    "    padding=True,\r\n",
    "    return_tensors=\"pt\",\r\n",
    ")\r\n",
    "\r\n",
    "# 确保 inputs 在 GPU0 上\r\n",
    "inputs = inputs.to(device)\r\n",
    "\r\n",
    "# 推理：生成输出\r\n",
    "generated_ids = model.generate(**inputs, max_new_tokens=128)\r\n",
    "generated_ids_trimmed = [\r\n",
    "    out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\r\n",
    "]\r\n",
    "output_text = processor.batch_decode(\r\n",
    "    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\r\n",
    ")\r\n",
    "print(output_text)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc9733c-3dec-42ed-9eb5-ad4c0b81e607",
   "metadata": {},
   "source": [
    "- 官方demo演示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cf0262-12fc-4ca4-b49f-160927723f69",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241217160156373.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f64173-0c92-4d90-989c-a67847445f77",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241217120519534.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c847fd5b-d0b7-4670-bb6c-cff5b0c9f37a",
   "metadata": {},
   "source": [
    "推理线上图片需要将近19G显存。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4204d1fc-be30-4a75-853c-2d88d1e0144a",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241217120509388.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2260edbe-2d75-4736-ac55-8f0ec56b57d2",
   "metadata": {},
   "source": [
    "- 本地图片识别测试"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3641f344-b36d-44a8-9c2f-c06798fb971e",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241217162631162.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a28d29e-ecab-4c84-b329-158056bdcb02",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241217141717498.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcacb0c-9b60-4c4c-8223-6da8a05f7abc",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241217141823162.png\" width=80%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1e161e-cc00-433c-afbf-13f094f86385",
   "metadata": {},
   "source": [
    "推理大概需要6G的显存消耗。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dab8ab6-7ddc-4ee6-9dc3-2de3446aee26",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/LingYu/image-20241217141841044.png\" width=100%></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
